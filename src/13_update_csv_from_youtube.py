"""
ìœ íŠœë¸Œ ì±„ë„ì— ì—…ë¡œë“œëœ ì±…ë“¤ì˜ ì •ë³´ë¥¼ ildangbaek_books.csvì— ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import csv
import re
from pathlib import Path
from typing import Dict, List, Optional, Set
from datetime import datetime
from dotenv import load_dotenv

try:
    from google.oauth2.credentials import Credentials
    from google.auth.transport.requests import Request
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    GOOGLE_API_AVAILABLE = True
except ImportError:
    GOOGLE_API_AVAILABLE = False

load_dotenv()

SCOPES = ['https://www.googleapis.com/auth/youtube.readonly']


class YouTubeChannelUpdater:
    """ìœ íŠœë¸Œ ì±„ë„ì—ì„œ ì—…ë¡œë“œëœ ì±… ì •ë³´ë¥¼ CSVì— ì—…ë°ì´íŠ¸í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì±… ì œëª© ë³„ì¹­ ë§¤í•‘ (ë¹„ë””ì˜¤ ì œëª©ì— ë‚˜ì˜¤ëŠ” ì´ë¦„ -> CSVì— ë“±ë¡ëœ ì´ë¦„)
    BOOK_ALIASES = {
        'ë…¸ë¥´ì›¨ì´ì˜ ìˆ²': 'ìƒì‹¤ì˜ ì‹œëŒ€',
        'norwegian wood': 'ìƒì‹¤ì˜ ì‹œëŒ€',
        'the age of loss': 'ìƒì‹¤ì˜ ì‹œëŒ€',
    }
    
    def __init__(self):
        if not GOOGLE_API_AVAILABLE:
            raise ImportError("google-api-python-clientê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        self.client_id = os.getenv("YOUTUBE_CLIENT_ID")
        self.client_secret = os.getenv("YOUTUBE_CLIENT_SECRET")
        self.refresh_token = os.getenv("YOUTUBE_REFRESH_TOKEN")
        
        if not all([self.client_id, self.client_secret, self.refresh_token]):
            raise ValueError("YouTube API ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.youtube = None
        self._authenticate()
    
    def _authenticate(self):
        """OAuth2 ì¸ì¦"""
        try:
            credentials = Credentials(
                token=None,
                refresh_token=self.refresh_token,
                token_uri="https://oauth2.googleapis.com/token",
                client_id=self.client_id,
                client_secret=self.client_secret,
                scopes=SCOPES
            )
            credentials.refresh(Request())
            self.youtube = build('youtube', 'v3', credentials=credentials)
            print("âœ… YouTube API ì¸ì¦ ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def get_my_channel_id(self) -> Optional[str]:
        """í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ìì˜ ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.youtube.channels().list(
                part='id',
                mine=True
            ).execute()
            
            if response.get('items'):
                channel_id = response['items'][0]['id']
                print(f"âœ… ì±„ë„ ID: {channel_id}")
                return channel_id
            return None
        except Exception as e:
            print(f"âŒ ì±„ë„ ID ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def get_channel_videos(self, channel_id: str, max_results: int = 50) -> List[Dict]:
        """ì±„ë„ì˜ ëª¨ë“  ë¹„ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°"""
        videos = []
        next_page_token = None
        
        print(f"ğŸ“¹ ì±„ë„ì˜ ë¹„ë””ì˜¤ ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        while len(videos) < max_results:
            try:
                # ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
                if not hasattr(self, '_upload_playlist_id'):
                    channel_response = self.youtube.channels().list(
                        part='contentDetails',
                        id=channel_id
                    ).execute()
                    
                    if not channel_response.get('items'):
                        print("âŒ ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        break
                    
                    self._upload_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
                
                # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°
                request_params = {
                    'part': 'snippet,contentDetails',
                    'playlistId': self._upload_playlist_id,
                    'maxResults': min(50, max_results - len(videos))
                }
                
                if next_page_token:
                    request_params['pageToken'] = next_page_token
                
                response = self.youtube.playlistItems().list(**request_params).execute()
                
                for item in response.get('items', []):
                    video_info = {
                        'video_id': item['contentDetails']['videoId'],
                        'title': item['snippet']['title'],
                        'published_at': item['snippet']['publishedAt'],
                        'description': item['snippet'].get('description', ''),
                        'url': f"https://www.youtube.com/watch?v={item['contentDetails']['videoId']}"
                    }
                    videos.append(video_info)
                
                next_page_token = response.get('nextPageToken')
                if not next_page_token:
                    break
                
                print(f"   ì§„í–‰ ì¤‘... {len(videos)}ê°œ ë¹„ë””ì˜¤ ìˆ˜ì§‘ë¨")
                
            except HttpError as e:
                print(f"âŒ ë¹„ë””ì˜¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
        
        print(f"âœ… ì´ {len(videos)}ê°œì˜ ë¹„ë””ì˜¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
        return videos
    
    def is_shorts_video(self, video_title: str, video_description: str = '') -> bool:
        """ë¹„ë””ì˜¤ê°€ Shortsì¸ì§€ í™•ì¸"""
        text = f"{video_title} {video_description}".lower()
        shorts_keywords = ['#shorts', 'shorts', '#short']
        return any(keyword in text for keyword in shorts_keywords)
    
    def is_book_review_video(self, video_title: str, video_description: str = '') -> bool:
        """ë¹„ë””ì˜¤ê°€ ì±… ë¦¬ë·°ì¸ì§€ í™•ì¸"""
        # Shorts ë¹„ë””ì˜¤ëŠ” ì œì™¸
        if self.is_shorts_video(video_title, video_description):
            return False
        
        text = f"{video_title} {video_description}".lower()
        # ì±… ë¦¬ë·° ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        review_keywords = [
            'ì±… ë¦¬ë·°', 'book review', 'ë¦¬ë·°', 'review',
            '[í•œêµ­ì–´]', '[korean]', '[english]', '[ì˜ì–´]'
        ]
        return any(keyword in text for keyword in review_keywords)
    
    def extract_book_title_from_video_title(self, video_title: str) -> Optional[str]:
        """ë¹„ë””ì˜¤ ì œëª©ì—ì„œ ì±… ì œëª© ì¶”ì¶œ"""
        # ì±… ë¦¬ë·°ê°€ ì•„ë‹Œ ë¹„ë””ì˜¤ëŠ” ì œì™¸
        if not self.is_book_review_video(video_title):
            return None
        
        # ì¼ë°˜ì ì¸ íŒ¨í„´ë“¤ (ë” ì—„ê²©í•˜ê²Œ)
        patterns = [
            r'\[í•œêµ­ì–´\]\s*(.+?)\s*ì±…\s*ë¦¬ë·°',  # "[í•œêµ­ì–´] ì±… ì œëª© ì±… ë¦¬ë·°"
            r'\[Korean\]\s*(.+?)\s*Book\s*Review',  # "[Korean] Book Title Book Review"
            r'\[English\]\s*(.+?)\s*Book\s*Review',  # "[English] Book Title Book Review"
            r'\[ì˜ì–´\]\s*(.+?)\s*ì±…\s*ë¦¬ë·°',  # "[ì˜ì–´] ì±… ì œëª© ì±… ë¦¬ë·°"
            r'^(.+?)\s*ì±…\s*ë¦¬ë·°',  # "ì±… ì œëª© ì±… ë¦¬ë·°"
            r'^(.+?)\s*Book\s*Review',  # "Book Title Book Review"
            r'^(.+?)\s*\|\s*ì±…\s*ë¦¬ë·°',  # "ì±… ì œëª© | ì±… ë¦¬ë·°"
            r'^(.+?)\s*\|\s*Book\s*Review',  # "Book Title | Book Review"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, video_title, re.IGNORECASE)
            if match:
                book_title = match.group(1).strip()
                # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                book_title = re.sub(r'\s+', ' ', book_title)
                # ê´„í˜¸ ë‚´ìš© ì œê±° (ì˜ˆ: [Korean], [í•œêµ­ì–´] ë“±)
                book_title = re.sub(r'\[.*?\]', '', book_title).strip()
                if book_title and len(book_title) > 1:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                    return book_title
        
        return None
    
    def normalize_title(self, title: str) -> str:
        """ì œëª© ì •ê·œí™” (ë¹„êµë¥¼ ìœ„í•´)"""
        # ê³µë°±, ì–¸ë”ìŠ¤ì½”ì–´, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        normalized = re.sub(r'[\s_\-|]', '', title.lower())
        # ê´„í˜¸ì™€ ë‚´ìš© ì œê±°
        normalized = re.sub(r'\([^)]*\)', '', normalized)
        normalized = re.sub(r'\[[^\]]*\]', '', normalized)
        return normalized
    
    def _check_alias_match(self, title1: str, title2: str) -> bool:
        """ë³„ì¹­ ë§¤ì¹­ í™•ì¸"""
        title1_lower = title1.lower()
        title2_lower = title2.lower()
        
        for alias, real_title in self.BOOK_ALIASES.items():
            alias_lower = alias.lower()
            real_lower = real_title.lower()
            
            # title1ì´ ë³„ì¹­ì´ê³  title2ê°€ ì‹¤ì œ ì œëª©ì¸ ê²½ìš°
            if alias_lower in title1_lower and real_lower in title2_lower:
                return True
            # title2ê°€ ë³„ì¹­ì´ê³  title1ì´ ì‹¤ì œ ì œëª©ì¸ ê²½ìš°
            if alias_lower in title2_lower and real_lower in title1_lower:
                return True
        
        return False
    
    def match_book_to_video(self, book_title: str, video_title: str, video_description: str = '') -> bool:
        """ì±… ì œëª©ê³¼ ë¹„ë””ì˜¤ ì œëª©/ì„¤ëª…ì´ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸"""
        # ì±… ë¦¬ë·° ë¹„ë””ì˜¤ê°€ ì•„ë‹ˆë©´ ë§¤ì¹­í•˜ì§€ ì•ŠìŒ
        if not self.is_book_review_video(video_title, video_description):
            return False
        
        # ì •ê·œí™”ëœ ì œëª© ë¹„êµ
        book_normalized = self.normalize_title(book_title)
        video_text = f"{video_title} {video_description}"
        video_normalized = self.normalize_title(video_text)
        
        # ë„ˆë¬´ ì§§ì€ ì œëª©ì€ ì œì™¸ (1-2ê¸€ìëŠ” ì œì™¸)
        if len(book_normalized) < 3:
            return False
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨ ê´€ê³„ í™•ì¸
        if book_normalized in video_normalized or video_normalized in book_normalized:
            return True
        
        # ë¶€ë¶„ ì¼ì¹˜ í™•ì¸ (ìµœì†Œ 3ê¸€ì ì´ìƒ)
        if len(book_normalized) >= 3:
            # ì±… ì œëª©ì˜ ì£¼ìš” ë‹¨ì–´ë“¤ì´ ë¹„ë””ì˜¤ ì œëª©ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            book_words = [w for w in book_normalized.split() if len(w) >= 2]
            if book_words:
                matched_words = sum(1 for word in book_words if word in video_normalized)
                # 70% ì´ìƒ ì¼ì¹˜í•˜ë©´ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼ (ë” ì—„ê²©í•˜ê²Œ)
                if matched_words >= len(book_words) * 0.7:
                    return True
        
        return False
    
    def load_books_csv(self, csv_path: str) -> List[Dict]:
        """CSV íŒŒì¼ ë¡œë“œ"""
        books = []
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            fieldnames = reader.fieldnames
            for row in reader:
                books.append(row)
        return books, fieldnames
    
    def update_csv(self, csv_path: str, videos: List[Dict], dry_run: bool = False) -> Dict:
        """CSV íŒŒì¼ ì—…ë°ì´íŠ¸"""
        print(f"ğŸ“š CSV íŒŒì¼ ì½ëŠ” ì¤‘: {csv_path}")
        books, fieldnames = self.load_books_csv(csv_path)
        
        print(f"   ì´ {len(books)}ê°œì˜ ì±… ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
        
        # ì—…ë°ì´íŠ¸ í†µê³„
        stats = {
            'matched': [],
            'updated': [],
            'already_uploaded': [],
            'not_found': []
        }
        
        # ê° ë¹„ë””ì˜¤ì— ëŒ€í•´ ë§¤ì¹­ë˜ëŠ” ì±… ì°¾ê¸°
        print("ğŸ” ë¹„ë””ì˜¤ì™€ ì±… ë§¤ì¹­ ì¤‘...\n")
        
        for video in videos:
            video_title = video['title']
            video_description = video.get('description', '')
            published_at = video['published_at']
            video_url = video['url']
            
            # Shorts ë¹„ë””ì˜¤ëŠ” ê±´ë„ˆë›°ê¸°
            if self.is_shorts_video(video_title, video_description):
                continue
            
            # ì±… ë¦¬ë·° ë¹„ë””ì˜¤ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
            if not self.is_book_review_video(video_title, video_description):
                stats['not_found'].append({
                    'video': video_title,
                    'url': video_url,
                    'extracted_title': None,
                    'reason': 'not_book_review'
                })
                continue
            
            # ë¹„ë””ì˜¤ ì œëª©ì—ì„œ ì±… ì œëª© ì¶”ì¶œ ì‹œë„
            extracted_title = self.extract_book_title_from_video_title(video_title)
            
            # ë³„ì¹­ ë§¤í•‘ í™•ì¸ (ì¶”ì¶œëœ ì œëª©ì´ ë³„ì¹­ì´ë©´ ì‹¤ì œ ì œëª©ìœ¼ë¡œ ë³€í™˜)
            original_extracted = extracted_title
            if extracted_title:
                extracted_lower = extracted_title.lower()
                for alias, real_title in self.BOOK_ALIASES.items():
                    alias_lower = alias.lower()
                    # ë³„ì¹­ì´ ì¶”ì¶œëœ ì œëª©ì— í¬í•¨ë˜ì–´ ìˆê±°ë‚˜, ì¶”ì¶œëœ ì œëª©ì´ ë³„ì¹­ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´
                    if alias_lower in extracted_lower or extracted_lower in alias_lower:
                        extracted_title = real_title
                        print(f"      ğŸ”„ ë³„ì¹­ ë§¤í•‘: '{original_extracted}' -> '{real_title}'")
                        break
            
            matched_book = None
            for book in books:
                book_title = book.get('title', '').strip()
                if not book_title:
                    continue
                
                # ë³„ì¹­ ë§¤í•‘ì´ ì ìš©ëœ ê²½ìš°, ì‹¤ì œ ì œëª©ê³¼ë§Œ ë¹„êµ
                if extracted_title and original_extracted != extracted_title:
                    # ë³„ì¹­ì´ ì ìš©ëœ ê²½ìš°, ì‹¤ì œ ì œëª©ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                    if self.normalize_title(extracted_title) == self.normalize_title(book_title):
                        matched_book = book
                        break
                # ì¶”ì¶œëœ ì œëª©ê³¼ ë¹„êµ
                elif extracted_title:
                    if self.normalize_title(extracted_title) == self.normalize_title(book_title):
                        matched_book = book
                        break
                    # ë³„ì¹­ ë§¤í•‘ë„ í™•ì¸
                    if self._check_alias_match(extracted_title, book_title):
                        matched_book = book
                        break
                
                # ì§ì ‘ ë§¤ì¹­ ì‹œë„
                if self.match_book_to_video(book_title, video_title, video_description):
                    matched_book = book
                    break
            
            if matched_book:
                book_title = matched_book.get('title', '')
                current_status = matched_book.get('status', '')
                current_uploaded = matched_book.get('youtube_uploaded', '')
                
                # ì—…ë¡œë“œ ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
                upload_date = published_at[:10] if published_at else datetime.now().strftime('%Y-%m-%d')
                
                if current_status == 'uploaded' and current_uploaded:
                    stats['already_uploaded'].append({
                        'book': book_title,
                        'video': video_title,
                        'url': video_url,
                        'current_date': current_uploaded,
                        'new_date': upload_date
                    })
                    print(f"   â­ï¸ {book_title}")
                    print(f"      ì´ë¯¸ ì—…ë¡œë“œë¨: {current_uploaded}")
                    print(f"      ë¹„ë””ì˜¤: {video_title[:50]}...")
                else:
                    stats['matched'].append({
                        'book': book_title,
                        'video': video_title,
                        'url': video_url,
                        'date': upload_date
                    })
                    
                    if not dry_run:
                        matched_book['status'] = 'uploaded'
                        matched_book['youtube_uploaded'] = upload_date
                        if not matched_book.get('video_created'):
                            matched_book['video_created'] = upload_date
                    
                    stats['updated'].append({
                        'book': book_title,
                        'video': video_title,
                        'url': video_url,
                        'date': upload_date
                    })
                    
                    print(f"   âœ… {book_title}")
                    print(f"      ì—…ë¡œë“œ ë‚ ì§œ: {upload_date}")
                    print(f"      ë¹„ë””ì˜¤: {video_title[:50]}...")
                    print(f"      URL: {video_url}")
            else:
                stats['not_found'].append({
                    'video': video_title,
                    'url': video_url,
                    'extracted_title': extracted_title
                })
                print(f"   â“ ë§¤ì¹­ ì‹¤íŒ¨: {video_title[:50]}...")
                if extracted_title:
                    print(f"      ì¶”ì¶œëœ ì œëª©: {extracted_title}")
            
            print()
        
        # CSV íŒŒì¼ ì €ì¥
        if not dry_run and stats['updated']:
            with open(csv_path, 'w', encoding='utf-8', newline='') as f:
                if fieldnames:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(books)
            print(f"ğŸ’¾ CSV íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {csv_path}\n")
        
        return stats


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ìœ íŠœë¸Œ ì±„ë„ì—ì„œ ì—…ë¡œë“œëœ ì±… ì •ë³´ë¥¼ CSVì— ì—…ë°ì´íŠ¸')
    parser.add_argument('--csv', type=str, default='data/ildangbaek_books.csv', help='CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--max-videos', type=int, default=100, help='ìµœëŒ€ ê°€ì ¸ì˜¬ ë¹„ë””ì˜¤ ìˆ˜')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    
    args = parser.parse_args()
    
    if not GOOGLE_API_AVAILABLE:
        print("âŒ google-api-python-clientê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    print("=" * 60)
    print("ğŸ“º ìœ íŠœë¸Œ ì±„ë„ì—ì„œ ì±… ì •ë³´ ì—…ë°ì´íŠ¸")
    print("=" * 60)
    print()
    
    if args.dry_run:
        print("ğŸ” DRY RUN ëª¨ë“œ: ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n")
    
    try:
        updater = YouTubeChannelUpdater()
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
    channel_id = updater.get_my_channel_id()
    if not channel_id:
        print("âŒ ì±„ë„ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print()
    
    # ì±„ë„ì˜ ë¹„ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°
    videos = updater.get_channel_videos(channel_id, max_results=args.max_videos)
    
    if not videos:
        print("âŒ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # CSV íŒŒì¼ í™•ì¸
    csv_path = Path(args.csv)
    if not csv_path.exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return
    
    # CSV ì—…ë°ì´íŠ¸
    stats = updater.update_csv(str(csv_path), videos, dry_run=args.dry_run)
    
    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("ğŸ“Š ì—…ë°ì´íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"âœ… ìƒˆë¡œ ì—…ë°ì´íŠ¸ëœ ì±…: {len(stats['updated'])}ê°œ")
    print(f"â­ï¸ ì´ë¯¸ ì—…ë¡œë“œëœ ì±…: {len(stats['already_uploaded'])}ê°œ")
    print(f"â“ ë§¤ì¹­ ì‹¤íŒ¨í•œ ë¹„ë””ì˜¤: {len(stats['not_found'])}ê°œ")
    print()
    
    if stats['updated']:
        print("ğŸ“ ì—…ë°ì´íŠ¸ëœ ì±… ëª©ë¡:")
        for item in stats['updated']:
            print(f"   â€¢ {item['book']} ({item['date']})")
            print(f"     {item['url']}")
        print()
    
    if stats['not_found']:
        print("â“ ë§¤ì¹­ ì‹¤íŒ¨í•œ ë¹„ë””ì˜¤:")
        for item in stats['not_found'][:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            print(f"   â€¢ {item['video'][:60]}...")
            if item['extracted_title']:
                print(f"     ì¶”ì¶œëœ ì œëª©: {item['extracted_title']}")
        if len(stats['not_found']) > 10:
            print(f"   ... ì™¸ {len(stats['not_found']) - 10}ê°œ")
        print()
    
    if args.dry_run:
        print("ğŸ’¡ ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸í•˜ë ¤ë©´ --dry-run ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")
    else:
        print("âœ… ì™„ë£Œ!")


if __name__ == "__main__":
    main()

