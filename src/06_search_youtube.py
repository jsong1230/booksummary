"""
GPT/Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ YouTube ì˜ìƒ ê²€ìƒ‰ ë° URL ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
from typing import List, Dict
from pathlib import Path
from dotenv import load_dotenv

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from googleapiclient.discovery import build
    from google.oauth2.credentials import Credentials
    from google.auth.transport.requests import Request
    YOUTUBE_API_AVAILABLE = True
except ImportError:
    YOUTUBE_API_AVAILABLE = False

load_dotenv()


class YouTubeSearcher:
    """GPT/Claude APIë¥¼ ì‚¬ìš©í•œ YouTube ì˜ìƒ ê²€ìƒ‰ í´ë˜ìŠ¤"""
    
    def __init__(self, use_claude: bool = True):
        """
        Args:
            use_claude: Claude API ì‚¬ìš© ì—¬ë¶€ (Falseë©´ OpenAI GPT ì‚¬ìš©)
        """
        self.use_claude = use_claude
        
        # API í‚¤ ë¡œë“œ
        if use_claude and ANTHROPIC_AVAILABLE:
            self.claude_api_key = os.getenv("CLAUDE_API_KEY")
            if self.claude_api_key:
                self.claude_client = anthropic.Anthropic(api_key=self.claude_api_key)
            else:
                self.claude_client = None
        else:
            self.claude_client = None
        
        if not use_claude and OPENAI_AVAILABLE:
            self.openai_api_key = os.getenv("OPENAI_API_KEY")
            if self.openai_api_key:
                openai.api_key = self.openai_api_key
            else:
                self.openai_api_key = None
        else:
            self.openai_api_key = None
        
        # YouTube API ì„¤ì •
        # YouTube Data API v3 í‚¤ í•„ìš” (Google Cloud Consoleì—ì„œ ë°œê¸‰)
        # ì°¸ê³ : YOUTUBE_CLIENT_IDëŠ” OAuthìš©ì´ê³ , YOUTUBE_API_KEYëŠ” Data APIìš©ì…ë‹ˆë‹¤
        self.youtube_api_key = os.getenv("YOUTUBE_API_KEY") or os.getenv("GOOGLE_BOOKS_API_KEY")  # ì„ì‹œë¡œ Google Books API í‚¤ ì‚¬ìš© ê°€ëŠ¥
        
        self.youtube = None
        if YOUTUBE_API_AVAILABLE and self.youtube_api_key:
            try:
                self.youtube = build('youtube', 'v3', developerKey=self.youtube_api_key)
            except Exception as e:
                print(f"âš ï¸ YouTube API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def generate_search_queries(self, book_title: str, author: str = None) -> List[str]:
        """
        GPT/Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ YouTube ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        
        Args:
            book_title: ì±… ì œëª©
            author: ì €ì ì´ë¦„
            
        Returns:
            ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        query_info = f"ì±… ì œëª©: {book_title}"
        if author:
            query_info += f", ì €ì: {author}"
        
        prompt = f"""ë‹¤ìŒ ì±…ì— ëŒ€í•œ YouTube ì˜ìƒ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

{query_info}

ë‹¤ìŒê³¼ ê°™ì€ ìœ í˜•ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ 15-20ê°œ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ì±… ë¦¬ë·°/ì„œí‰
2. ì‘ê°€ ì¸í„°ë·°
3. ì±… í•´ì„/ë¶„ì„
4. ë…ì„œ í›„ê¸°/ê°ìƒí‰
5. ì¤„ê±°ë¦¬ ìš”ì•½
6. ì£¼ìš” ì¥ë©´/ëª…ëŒ€ì‚¬
7. íŒŸìºìŠ¤íŠ¸/ê°•ì˜
8. ê´€ë ¨ ì˜í™”/ë“œë¼ë§ˆ (ìˆëŠ” ê²½ìš°)

ê° ê²€ìƒ‰ ì¿¼ë¦¬ëŠ” í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , YouTubeì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ í•œ ì¤„ì— í•˜ë‚˜ì”© ë‚˜ì—´í•´ì£¼ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë²ˆí˜¸ëŠ” í•„ìš” ì—†ìŠµë‹ˆë‹¤."""

        try:
            if self.use_claude and self.claude_client:
                response = self.claude_client.messages.create(
                    model="claude-3-5-sonnet-20240620",
                    max_tokens=1000,
                    messages=[{
                        "role": "user",
                        "content": prompt
                    }]
                )
                queries_text = response.content[0].text
            elif self.openai_api_key:
                response = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant that generates YouTube search queries."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000
                )
                queries_text = response.choices[0].message.content
            else:
                print("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._default_search_queries(book_title, author)
            
            # ì¿¼ë¦¬ íŒŒì‹±
            queries = []
            for line in queries_text.strip().split('\n'):
                line = line.strip()
                # ë²ˆí˜¸ë‚˜ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                if line and not line.startswith('#') and not line.startswith('-'):
                    # ë²ˆí˜¸ ì œê±° (1. 2. ë“±)
                    line = line.lstrip('0123456789. ')
                    if line:
                        queries.append(line)
            
            if not queries:
                return self._default_search_queries(book_title, author)
            
            print(f"âœ… {len(queries)}ê°œì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n")
            return queries[:20]  # ìµœëŒ€ 20ê°œ
            
        except Exception as e:
            print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            print("ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n")
            return self._default_search_queries(book_title, author)
    
    def _default_search_queries(self, book_title: str, author: str = None) -> List[str]:
        """ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        queries = [
            f"{book_title} ë¦¬ë·°",
            f"{book_title} ì„œí‰",
            f"{book_title} í•´ì„",
            f"{book_title} ë¶„ì„",
            f"{book_title} ë…ì„œ í›„ê¸°",
            f"{book_title} ì¤„ê±°ë¦¬",
            f"{book_title} ëª…ëŒ€ì‚¬",
            f"{book_title} íŒŸìºìŠ¤íŠ¸",
            f"{book_title} ê°•ì˜",
        ]
        
        if author:
            queries.extend([
                f"{author} ì¸í„°ë·°",
                f"{author} {book_title}",
                f"{book_title} {author} ë¦¬ë·°",
            ])
        
        return queries
    
    def is_related_to_book(self, title: str, description: str, book_title: str, author: str = None) -> bool:
        """
        ì˜ìƒì´ í•´ë‹¹ ì±…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸
        
        Args:
            title: ì˜ìƒ ì œëª©
            description: ì˜ìƒ ì„¤ëª…
            book_title: ì±… ì œëª©
            author: ì €ì ì´ë¦„
            
        Returns:
            ê´€ë ¨ ì—¬ë¶€
        """
        text = (title + " " + description).lower()
        book_title_lower = book_title.lower()
        
        # ì±… ì œëª©ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if book_title_lower in text:
            return True
        
        # ì €ìê°€ ìˆìœ¼ë©´ ì €ì ì´ë¦„ë„ í™•ì¸
        if author:
            author_lower = author.lower()
            # ì €ì ì´ë¦„ì˜ ì£¼ìš” ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: "ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤" -> "ë¬´ë¼ì¹´ë¯¸", "í•˜ë£¨í‚¤")
            author_parts = author_lower.split()
            if len(author_parts) > 0 and any(part in text for part in author_parts if len(part) > 2):
                return True
        
        return False
    
    def search_youtube_videos(self, queries: List[str], book_title: str, author: str = None, max_results_per_query: int = 3) -> List[Dict]:
        """
        YouTube Data APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ê²€ìƒ‰
        
        Args:
            queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
            book_title: ì±… ì œëª© (ê´€ë ¨ì„± ê²€ì¦ìš©)
            author: ì €ì ì´ë¦„ (ê´€ë ¨ì„± ê²€ì¦ìš©)
            max_results_per_query: ì¿¼ë¦¬ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if not self.youtube:
            print("âš ï¸ YouTube APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
            return []
        
        all_videos = []
        seen_video_ids = set()
        
        print(f"ğŸ” YouTube ì˜ìƒ ê²€ìƒ‰ ì¤‘... (ì´ {len(queries)}ê°œ ì¿¼ë¦¬)\n")
        
        for i, query in enumerate(queries, 1):
            try:
                print(f"  [{i}/{len(queries)}] ê²€ìƒ‰: {query}")
                
                # YouTube API ê²€ìƒ‰
                search_response = self.youtube.search().list(
                    q=query,
                    part='id,snippet',
                    type='video',
                    maxResults=max_results_per_query,
                    order='relevance',
                    regionCode='KR'
                ).execute()
                
                for item in search_response.get('items', []):
                    video_id = item['id']['videoId']
                    
                    if video_id not in seen_video_ids:
                        seen_video_ids.add(video_id)
                        
                        video_title = item['snippet']['title']
                        video_description = item['snippet']['description']
                        
                        # ì±…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸
                        if not self.is_related_to_book(video_title, video_description, book_title, author):
                            print(f"    â­ï¸ ê´€ë ¨ ì—†ìŒ: {video_title[:50]}...")
                            continue
                        
                        video_info = {
                            'video_id': video_id,
                            'url': f"https://www.youtube.com/watch?v={video_id}",
                            'title': video_title,
                            'channel': item['snippet']['channelTitle'],
                            'published_at': item['snippet']['publishedAt'],
                            'description': video_description[:200] + '...' if len(video_description) > 200 else video_description,
                            'search_query': query
                        }
                        
                        all_videos.append(video_info)
                        print(f"    âœ“ {video_info['title'][:50]}...")
                
            except Exception as e:
                print(f"    âš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"\nâœ… ì´ {len(all_videos)}ê°œì˜ ê´€ë ¨ YouTube ì˜ìƒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
        return all_videos
    
    def validate_web_url(self, url: str, book_title: str) -> bool:
        """
        ì›¹ì‚¬ì´íŠ¸ URLì´ í•´ë‹¹ ì±…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸
        
        Args:
            url: URL
            book_title: ì±… ì œëª©
            
        Returns:
            ê´€ë ¨ ì—¬ë¶€
        """
        # ë‹¤ë¥¸ ì±… ì œëª©ì´ í¬í•¨ëœ URL ì œì™¸
        # ì˜ˆ: "82ë…„ìƒ ê¹€ì§€ì˜"ì´ "ë…¸ë¥´ì›¨ì´ì˜ ìˆ²" íŒŒì¼ì— ë“¤ì–´ì˜¤ë©´ ì•ˆ ë¨
        unrelated_books = [
            "82ë…„ìƒ ê¹€ì§€ì˜", "ê¹€ì§€ì˜", "ì¡°ë‚¨ì£¼",
            # ë‹¤ë¥¸ ì±… ì œëª©ë“¤ë„ ì¶”ê°€ ê°€ëŠ¥
        ]
        
        url_lower = url.lower()
        book_title_lower = book_title.lower()
        
        # ë‹¤ë¥¸ ì±… ì œëª©ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸
        for unrelated in unrelated_books:
            if unrelated.lower() in url_lower and unrelated.lower() not in book_title_lower:
                return False
        
        return True
    
    def save_video_urls(self, book_title: str, videos: List[Dict], output_file: str = None) -> str:
        """
        YouTube ì˜ìƒ URLì„ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì— ì¶”ê°€
        
        Args:
            book_title: ì±… ì œëª©
            videos: ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if output_file is None:
            safe_title = "".join(c for c in book_title if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_title = safe_title.replace(' ', '_')
            output_file = f"assets/urls/{safe_title}_notebooklm.md"
        
        output_path = Path(output_file)
        
        # ê¸°ì¡´ íŒŒì¼ ì½ê¸°
        existing_urls = []
        if output_path.exists():
            with open(output_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # ê¸°ì¡´ URL ì¶”ì¶œ ë° ê²€ì¦
                for line in content.split('\n'):
                    if line.startswith('https://'):
                        url = line.strip()
                        # í•´ë‹¹ ì±…ê³¼ ê´€ë ¨ì´ ìˆëŠ” URLë§Œ ìœ ì§€
                        if self.validate_web_url(url, book_title):
                            existing_urls.append(url)
                        else:
                            print(f"  âš ï¸ ê´€ë ¨ ì—†ëŠ” URL ì œê±°: {url[:60]}...")
        
        # ìƒˆ YouTube URL ì¶”ê°€
        new_urls = [video['url'] for video in videos]
        all_urls = existing_urls + new_urls
        
        # ì¤‘ë³µ ì œê±°
        unique_urls = []
        seen = set()
        for url in all_urls:
            if url not in seen:
                seen.add(url)
                unique_urls.append(url)
        
        # íŒŒì¼ ì—…ë°ì´íŠ¸
        if output_path.exists():
            # ê¸°ì¡´ íŒŒì¼ì˜ URL ë¸”ë¡ ì°¾ì•„ì„œ êµì²´
            with open(output_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # URL ë¸”ë¡ ì‹œì‘/ë ì°¾ê¸°
            start_idx = None
            end_idx = None
            
            for i, line in enumerate(lines):
                if '```' in line and start_idx is None:
                    start_idx = i + 1
                elif start_idx is not None and '```' in line:
                    end_idx = i
                    break
            
            if start_idx is not None and end_idx is not None:
                # URL ë¸”ë¡ êµì²´
                new_lines = lines[:start_idx] + [url + '\n' for url in unique_urls] + lines[end_idx:]
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
            else:
                # URL ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì¶”ê°€
                with open(output_path, 'a', encoding='utf-8') as f:
                    f.write('\n')
                    for url in new_urls:
                        f.write(f"{url}\n")
        else:
            # ìƒˆ íŒŒì¼ ìƒì„±
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"# {book_title} - NotebookLM ì†ŒìŠ¤ URL\n\n")
                f.write("## ğŸ“‹ URL ë¦¬ìŠ¤íŠ¸\n\n```\n")
                for url in unique_urls:
                    f.write(f"{url}\n")
                f.write("```\n")
        
        print(f"ğŸ’¾ YouTube ì˜ìƒ URLì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {output_path}")
        print(f"   - ìƒˆë¡œ ì¶”ê°€ëœ ì˜ìƒ: {len(new_urls)}ê°œ")
        print(f"   - ì´ URL: {len(unique_urls)}ê°œ\n")
        
        return str(output_path)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='GPT/Claude APIë¥¼ ì‚¬ìš©í•œ YouTube ì˜ìƒ ê²€ìƒ‰')
    parser.add_argument('--title', type=str, required=True, help='ì±… ì œëª©')
    parser.add_argument('--author', type=str, help='ì €ì ì´ë¦„')
    parser.add_argument('--use-openai', action='store_true', help='OpenAI GPT ì‚¬ìš© (ê¸°ë³¸ê°’: Claude)')
    parser.add_argument('--max-results', type=int, default=3, help='ì¿¼ë¦¬ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜')
    parser.add_argument('--output', type=str, help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ¬ GPT/Claude APIë¥¼ ì‚¬ìš©í•œ YouTube ì˜ìƒ ê²€ìƒ‰")
    print("=" * 60)
    print()
    
    searcher = YouTubeSearcher(use_claude=not args.use_openai)
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    print("ğŸ¤– AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...")
    queries = searcher.generate_search_queries(args.title, args.author)
    
    if not queries:
        print("âŒ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ({len(queries)}ê°œ):")
    for i, query in enumerate(queries, 1):
        print(f"  {i}. {query}")
    print()
    
    # YouTube ì˜ìƒ ê²€ìƒ‰
    videos = searcher.search_youtube_videos(queries, args.title, args.author, max_results_per_query=args.max_results)
    
    if not videos:
        print("âŒ YouTube ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— YOUTUBE_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    # URL ì €ì¥
    output_file = searcher.save_video_urls(args.title, videos, args.output)
    
    print("=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)
    print(f"\nğŸ“„ ì €ì¥ëœ íŒŒì¼: {output_file}")
    print(f"ğŸ“º ì°¾ì€ ì˜ìƒ: {len(videos)}ê°œ")
    print("\nğŸ’¡ ì´ì œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ URLì„ NotebookLMì— ë³µì‚¬í•˜ì„¸ìš”!")


if __name__ == "__main__":
    main()

