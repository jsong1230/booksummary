#!/usr/bin/env python3
"""
YouTube Shorts ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

Summary íŒŒì¼ì˜ HOOK ì„¹ì…˜ ë° í•µì‹¬ ì¸ìš©êµ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
9:16 ì„¸ë¡œ í¬ë§·(1080x1920) YouTube Shorts ì˜ìƒì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

ìƒì„±ë˜ëŠ” Shorts ìœ í˜•:
  Short 1: HOOK ì„¹ì…˜ ê¸°ë°˜ (ìš”ì•½ ì²« 30ì´ˆ)
  Short 2: í•µì‹¬ ì¸ìš©êµ¬ + ë¬´ë“œ ì´ë¯¸ì§€
  Short 3: í•œ ì¤„ ìš”ì•½ + ë°°ê²½ ì´ë¯¸ì§€

ì‚¬ìš©ë²•:
  python src/26_generate_shorts.py --book-title "ì±… ì œëª©" --language ko
  python src/26_generate_shorts.py --book-title "Book Title" --language en --author "Author Name"
"""

import argparse
import os
import re
import sys
import random
from pathlib import Path
from typing import Optional, List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

try:
    from src.utils.logger import get_logger
except ImportError:
    from utils.logger import get_logger

try:
    from src.utils.file_utils import get_standard_safe_title
except ImportError:
    from utils.file_utils import get_standard_safe_title

try:
    from src.utils.translations import (
        translate_book_title,
        translate_book_title_to_korean,
        translate_author_name,
        translate_author_name_to_korean,
        is_english_title,
    )
except ImportError:
    from utils.translations import (
        translate_book_title,
        translate_book_title_to_korean,
        translate_author_name,
        translate_author_name_to_korean,
        is_english_title,
    )

SHORTS_RESOLUTION = (1080, 1920)  # 9:16 ì„¸ë¡œ í¬ë§·
SHORTS_FPS = 30
SHORTS_MAX_DURATION = 59  # YouTube Shorts ìµœëŒ€ 59ì´ˆ


def _parse_hook_section(summary_text: str) -> str:
    """Summary íŒŒì¼ì—ì„œ [HOOK] ì„¹ì…˜ ì¶”ì¶œ"""
    hook_match = re.search(r'\[HOOK\]\s*(.*?)(?=\[SUMMARY\]|\[BRIDGE\]|\Z)', summary_text, re.DOTALL)
    if hook_match:
        return hook_match.group(1).strip()
    # HOOK íƒœê·¸ ì—†ìœ¼ë©´ ì²˜ìŒ 300ì
    return summary_text[:300].strip()


def _parse_summary_section(summary_text: str) -> str:
    """Summary íŒŒì¼ì—ì„œ [SUMMARY] ì„¹ì…˜ ì¶”ì¶œ"""
    summary_match = re.search(r'\[SUMMARY\]\s*(.*?)(?=\[BRIDGE\]|\Z)', summary_text, re.DOTALL)
    if summary_match:
        return summary_match.group(1).strip()
    return summary_text.strip()


def _extract_key_quotes(summary_text: str, language: str = "ko", count: int = 3) -> List[str]:
    """Summary ë³¸ë¬¸ì—ì„œ í•µì‹¬ ì¸ìš©êµ¬ ì¶”ì¶œ (ë¬¸ì¥ ë‹¨ìœ„)"""
    body = _parse_summary_section(summary_text)
    # ë¬¸ì¥ ë¶„ë¦¬
    if language == "ko":
        sentences = re.split(r'(?<=[ë‹¤ìŠµë‹ˆì—ˆ])\.?\s+', body)
    else:
        sentences = re.split(r'(?<=[.!?])\s+', body)

    # 30~100ì ë²”ìœ„ ë¬¸ì¥ í•„í„°ë§
    candidates = [s.strip() for s in sentences if 30 <= len(s.strip()) <= 150]

    if len(candidates) <= count:
        return candidates

    # ê· ë“± ë¶„í¬ë¡œ ì„ íƒ (ì²«/ì¤‘ê°„/ë)
    step = len(candidates) // count
    selected = [candidates[i * step] for i in range(count)]
    return selected


def _find_summary_file(book_title: str, language: str) -> Optional[Path]:
    """Summary MD íŒŒì¼ ê²½ë¡œ íƒìƒ‰"""
    safe_title = get_standard_safe_title(book_title)
    lang_suffix = "ko" if language == "ko" else "en"
    candidates = [
        Path(f"assets/summaries/{safe_title}_summary_{lang_suffix}.md"),
        Path(f"assets/summaries/{safe_title}_summary_{language}.md"),
        Path(f"output/{safe_title}_summary_{lang_suffix}.md"),
    ]
    for c in candidates:
        if c.exists():
            return c
    return None


def _find_mood_images(book_title: str, count: int = 5) -> List[Path]:
    """ë¬´ë“œ ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰"""
    safe_title = get_standard_safe_title(book_title)
    image_dir = Path(f"assets/images/{safe_title}")
    if not image_dir.exists():
        return []
    images = sorted(image_dir.glob("mood_*.jpg"))
    if not images:
        images = sorted(image_dir.glob("*.jpg"))
    if len(images) > count:
        images = random.sample(images, count)
    return images[:count]


def _generate_short_tts(text: str, language: str, output_path: Path, provider: str = "openai") -> bool:
    """Shortsìš© TTS ì˜¤ë””ì˜¤ ìƒì„±"""
    try:
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "text_to_speech_multi",
            Path(__file__).parent / "09_text_to_speech_multi.py"
        )
        tts_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(tts_module)
        engine = tts_module.MultiTTSEngine(provider=provider)

        voice = "nova" if language == "ko" else "alloy"
        result = engine.text_to_speech(
            text=text,
            output_path=str(output_path),
            language=language,
            voice=voice
        )
        return bool(result)
    except Exception as e:
        print(f"  âš ï¸ TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def _create_short_video(
    images: List[Path],
    audio_path: Optional[Path],
    output_path: Path,
    text_overlay: Optional[str],
    language: str,
    duration: float = SHORTS_MAX_DURATION,
    cta_text: Optional[str] = None,
) -> bool:
    """Shorts ì˜ìƒ ìƒì„± (9:16 í¬ë§·)"""
    try:
        from moviepy.editor import (
            ImageClip, AudioFileClip, CompositeVideoClip,
            concatenate_videoclips, TextClip, ColorClip
        )
        import numpy as np
        from PIL import Image as PILImage

        target_w, target_h = SHORTS_RESOLUTION

        # ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì‹¤ì œ ì¬ìƒ ê¸¸ì´ ê²°ì •
        audio_clip = None
        actual_duration = duration
        if audio_path and audio_path.exists():
            audio_clip = AudioFileClip(str(audio_path))
            actual_duration = min(audio_clip.duration, SHORTS_MAX_DURATION)

        # ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë“œì‡¼ ìƒì„±
        if not images:
            # ì´ë¯¸ì§€ ì—†ìœ¼ë©´ ê²€ì€ ë°°ê²½
            bg = ColorClip(size=(target_w, target_h), color=(20, 20, 20), duration=actual_duration)
            video = bg
        else:
            per_img = actual_duration / len(images)
            clips = []
            for img_path in images:
                img = PILImage.open(img_path).convert("RGB")
                # 9:16 í¬ë¡­: ì¤‘ì•™ í¬ë¡­
                iw, ih = img.size
                aspect = target_w / target_h
                img_aspect = iw / ih
                if img_aspect > aspect:
                    # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ â†’ ì¢Œìš° í¬ë¡­
                    new_w = int(ih * aspect)
                    left = (iw - new_w) // 2
                    img = img.crop((left, 0, left + new_w, ih))
                else:
                    # ì´ë¯¸ì§€ê°€ ë” ì¢ìŒ â†’ ìƒí•˜ í¬ë¡­
                    new_h = int(iw / aspect)
                    top = (ih - new_h) // 2
                    img = img.crop((0, top, iw, top + new_h))
                img = img.resize((target_w, target_h), PILImage.Resampling.LANCZOS)
                clip = ImageClip(np.array(img), duration=per_img)
                clips.append(clip)
            video = concatenate_videoclips(clips, method="compose")

        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì¶”ê°€
        composite_clips = [video]
        if text_overlay:
            try:
                font = "NanumGothic" if language == "ko" else "Arial"
                # ìƒë‹¨ ì œëª© ë°°ë„ˆ
                txt_clip = (
                    TextClip(
                        text_overlay,
                        fontsize=52,
                        color="white",
                        font=font,
                        method="caption",
                        size=(target_w - 80, None),
                        align="center",
                    )
                    .with_position(("center", 120))
                    .with_duration(actual_duration)
                )
                composite_clips.append(txt_clip)
            except Exception as e:
                print(f"  âš ï¸ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")

        # CTA ì˜¤ë²„ë ˆì´ (ë§ˆì§€ë§‰ 10ì´ˆ ë™ì•ˆ í•˜ë‹¨ í‘œì‹œ)
        cta_duration = min(10.0, actual_duration * 0.25)  # ìµœëŒ€ 10ì´ˆ ë˜ëŠ” ì „ì²´ì˜ 25%
        cta_start = max(0.0, actual_duration - cta_duration)
        if cta_text and actual_duration > 5:
            try:
                font_cta = "NanumGothic" if language == "ko" else "Arial"
                # ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½ + CTA í…ìŠ¤íŠ¸
                cta_bg = (
                    ColorClip(size=(target_w, 120), color=(0, 0, 0))
                    .with_opacity(0.6)
                    .with_start(cta_start)
                    .with_duration(cta_duration)
                    .with_position(("center", target_h - 200))
                )
                cta_clip = (
                    TextClip(
                        cta_text,
                        fontsize=44,
                        color="white",
                        font=font_cta,
                        method="caption",
                        size=(target_w - 80, None),
                        align="center",
                    )
                    .with_start(cta_start)
                    .with_duration(cta_duration)
                    .with_position(("center", target_h - 190))
                )
                composite_clips.extend([cta_bg, cta_clip])
            except Exception as e:
                print(f"  âš ï¸ CTA ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")

        # Shorts ì›Œí„°ë§ˆí¬ (#Shorts í•´ì‹œíƒœê·¸)
        try:
            hashtag_clip = (
                TextClip(
                    "#Shorts",
                    fontsize=40,
                    color="rgba(255,255,255,180)",
                    font="Arial",
                )
                .with_position(("center", target_h - 160))
                .with_duration(actual_duration)
            )
            composite_clips.append(hashtag_clip)
        except Exception:
            pass

        final = CompositeVideoClip(composite_clips, size=(target_w, target_h))

        if audio_clip:
            final = final.with_audio(audio_clip.subclip(0, actual_duration))

        output_path.parent.mkdir(parents=True, exist_ok=True)
        final.write_videofile(
            str(output_path),
            fps=SHORTS_FPS,
            codec="libx264",
            audio_codec="aac",
            preset="medium",
            logger=None,
        )
        print(f"  âœ… Shorts ìƒì„± ì™„ë£Œ: {output_path.name} ({actual_duration:.1f}ì´ˆ)")
        return True

    except Exception as e:
        print(f"  âŒ Shorts ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def generate_shorts(
    book_title: str,
    language: str = "ko",
    author: Optional[str] = None,
    tts_provider: str = "openai",
    output_dir: Optional[str] = None,
) -> List[Path]:
    """
    ì±… 1ê¶Œì—ì„œ YouTube Shorts 3ê°œ ìë™ ìƒì„±

    Args:
        book_title: ì±… ì œëª©
        language: ì–¸ì–´ ('ko' ë˜ëŠ” 'en')
        author: ì €ì ì´ë¦„ (ì„ íƒ)
        tts_provider: TTS ì œê³µì ('openai' ë˜ëŠ” 'google')
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: output/shorts/)

    Returns:
        ìƒì„±ëœ Shorts íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    logger = get_logger(__name__)
    safe_title = get_standard_safe_title(book_title)
    lang_suffix = "ko" if language == "ko" else "en"

    if output_dir:
        out_dir = Path(output_dir)
    else:
        out_dir = Path(f"output/shorts/{safe_title}")
    out_dir.mkdir(parents=True, exist_ok=True)

    # í•œê¸€/ì˜ë¬¸ ì œëª© ê²°ì •
    if is_english_title(book_title):
        en_title = book_title
        ko_title = translate_book_title_to_korean(book_title) or book_title
    else:
        ko_title = book_title
        en_title = translate_book_title(book_title) or book_title

    display_title = ko_title if language == "ko" else en_title

    logger.info(f"ğŸ“± YouTube Shorts ìƒì„± ì‹œì‘: {display_title} ({language})")

    # Summary íŒŒì¼ ë¡œë“œ
    summary_path = _find_summary_file(book_title, language)
    if not summary_path:
        logger.warning(f"âš ï¸ Summary íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HOOK/ì¸ìš©êµ¬ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        summary_text = ""
    else:
        logger.info(f"  ğŸ“„ Summary íŒŒì¼: {summary_path}")
        summary_text = summary_path.read_text(encoding="utf-8")
        # HTML ì£¼ì„ ì œê±°
        summary_text = re.sub(r'<!--.*?-->', '', summary_text, flags=re.DOTALL).strip()

    # ë¬´ë“œ ì´ë¯¸ì§€ ë¡œë“œ
    mood_images = _find_mood_images(book_title, count=9)
    if not mood_images:
        logger.warning("âš ï¸ ë¬´ë“œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # CTA í…ìŠ¤íŠ¸ (ëª¨ë“  Shorts í•˜ë‹¨ì— ë§ˆì§€ë§‰ 10ì´ˆê°„ í‘œì‹œ)
    cta = "ì „ì²´ ë¦¬ë·°ëŠ” ì±„ë„ì—ì„œ â†‘" if language == "ko" else "Full Review on the Channel â†‘"

    generated = []

    # â”€â”€â”€ Short 1: HOOK ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("ğŸ¬ Short 1: HOOK ì„¹ì…˜ ê¸°ë°˜ Shorts ìƒì„±")
    hook_text = _parse_hook_section(summary_text) if summary_text else ""
    if not hook_text:
        if language == "ko":
            hook_text = f"{display_title}ì˜ í•µì‹¬ì„ ì§€ê¸ˆ í™•ì¸í•˜ì„¸ìš”!"
        else:
            hook_text = f"Discover the key insights of {display_title}!"

    short1_audio = out_dir / f"short1_hook_{lang_suffix}.mp3"
    short1_video = out_dir / f"short1_hook_{lang_suffix}.mp4"

    logger.info(f"  ğŸ¤ Hook TTS ìƒì„± ì¤‘...")
    has_audio = _generate_short_tts(hook_text, language, short1_audio, tts_provider)

    images_for_s1 = mood_images[:3] if mood_images else []
    success = _create_short_video(
        images=images_for_s1,
        audio_path=short1_audio if has_audio else None,
        output_path=short1_video,
        text_overlay=display_title,
        language=language,
        duration=30.0,
        cta_text=cta,
    )
    if success:
        generated.append(short1_video)

    # â”€â”€â”€ Short 2: í•µì‹¬ ì¸ìš©êµ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("ğŸ¬ Short 2: í•µì‹¬ ì¸ìš©êµ¬ Shorts ìƒì„±")
    quotes = _extract_key_quotes(summary_text, language, count=3) if summary_text else []
    if not quotes:
        if language == "ko":
            quotes = [f"{display_title}ì—ì„œ ë°°ìš´ ê°€ì¥ ì¤‘ìš”í•œ êµí›ˆ"]
        else:
            quotes = [f"The most important lesson from {display_title}"]

    quote_text = "\n\n".join(f'"{q}"' for q in quotes[:2])

    short2_audio = out_dir / f"short2_quotes_{lang_suffix}.mp3"
    short2_video = out_dir / f"short2_quotes_{lang_suffix}.mp4"

    logger.info(f"  ğŸ¤ ì¸ìš©êµ¬ TTS ìƒì„± ì¤‘...")
    has_audio2 = _generate_short_tts(quote_text, language, short2_audio, tts_provider)

    images_for_s2 = mood_images[3:6] if len(mood_images) > 3 else mood_images[:3]
    success2 = _create_short_video(
        images=images_for_s2,
        audio_path=short2_audio if has_audio2 else None,
        output_path=short2_video,
        text_overlay=f'"{display_title}"',
        language=language,
        duration=45.0,
        cta_text=cta,
    )
    if success2:
        generated.append(short2_video)

    # â”€â”€â”€ Short 3: í•œ ì¤„ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("ğŸ¬ Short 3: í•œ ì¤„ ìš”ì•½ Shorts ìƒì„±")
    if language == "ko":
        oneliner = f"ğŸ“š {display_title}ì„(ë¥¼) í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ë©´: ì´ ì±…ì€ ìš°ë¦¬ ì‚¶ì˜ ë³¸ì§ˆì ì¸ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤."
    else:
        oneliner = f"ğŸ“š {display_title} in one sentence: This book answers the most essential questions of our lives."

    short3_audio = out_dir / f"short3_oneliner_{lang_suffix}.mp3"
    short3_video = out_dir / f"short3_oneliner_{lang_suffix}.mp4"

    logger.info(f"  ğŸ¤ í•œ ì¤„ ìš”ì•½ TTS ìƒì„± ì¤‘...")
    has_audio3 = _generate_short_tts(oneliner, language, short3_audio, tts_provider)

    images_for_s3 = mood_images[6:9] if len(mood_images) > 6 else mood_images[:3]
    success3 = _create_short_video(
        images=images_for_s3,
        audio_path=short3_audio if has_audio3 else None,
        output_path=short3_video,
        text_overlay=display_title,
        language=language,
        duration=20.0,
        cta_text=cta,
    )
    if success3:
        generated.append(short3_video)

    # â”€â”€â”€ ê²°ê³¼ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info(f"\nâœ… Shorts ìƒì„± ì™„ë£Œ: {len(generated)}/3ê°œ")
    for p in generated:
        logger.info(f"  ğŸ“± {p}")

    return generated


def _generate_shorts_hook_ko(ko_title: str, author: Optional[str] = None, book_info: Optional[dict] = None) -> str:
    """í•œê¸€ Shortsìš© í›… ì¹´í”¼ ìƒì„± (ì±…ë³„ ë§ì¶¤, ê¶ê¸ˆì¦ ìœ ë°œ)"""
    # ì¥ë¥´ ê°ì§€
    genre = "general"
    if book_info:
        cats = book_info.get("categories") or []
        if isinstance(cats, str):
            cats = [cats]
        desc = (book_info.get("description") or "").lower()
        text = (" ".join(cats) + " " + desc).lower()
        if any(k in text for k in ["philosophy", "ì² í•™"]):
            genre = "philosophy"
        elif any(k in text for k in ["psychology", "self-help", "ìê¸°ê³„ë°œ", "ì‹¬ë¦¬"]):
            genre = "psychology"
        elif any(k in text for k in ["business", "economics", "ê²½ì œ", "ê²½ì˜"]):
            genre = "business"
        elif any(k in text for k in ["history", "ì—­ì‚¬"]):
            genre = "history"
        elif any(k in text for k in ["fiction", "novel", "ì†Œì„¤"]):
            genre = "fiction"

    # ì¡°ì‚¬ ì²˜ë¦¬: ë°›ì¹¨ ì—†ìœ¼ë©´ "ê°€", ìˆìœ¼ë©´ "ì´"
    def _i_ga(word: str) -> str:
        if not word:
            return "ì´"
        last = word[-1]
        code = ord(last) - 0xAC00
        if 0 <= code < 11172 and code % 28 == 0:
            return "ê°€"
        return "ì´"

    hooks = {
        "philosophy": f"{ko_title}ì´ ì•Œë ¤ì¤€ ì‚¶ì˜ ì§„ì‹¤",
        "psychology": f"{ko_title}ìœ¼ë¡œ ë³¸ ì¸ê°„ì˜ ì‹¬ë¦¬",
        "business":   f"{ko_title}ì˜ í•µì‹¬ ì „ëµ í•œ ê°€ì§€",
        "history":    f"{ko_title}ì—ì„œ ë°œê²¬í•œ ì—­ì‚¬ì˜ êµí›ˆ",
        "fiction":    f"{ko_title}ì´ ë³´ì—¬ì¤€ ì¸ê°„ì˜ ë¯¼ë‚¯",
        "general":    f"{ko_title}ì—ì„œ ê°€ì¥ ì¶©ê²©ì ì¸ í•œ ë¬¸ì¥",
    }
    hook = hooks.get(genre, hooks["general"])
    if author:
        # ì¡°ì‚¬ ì²˜ë¦¬ ì ìš©, "{ì €ì}ì´/ê°€ ë§í•œ {ì±…ì œëª©}ì˜ í•µì‹¬" í¬ë§· ì‚¬ìš©
        particle = _i_ga(author)
        hook = f"{author}{particle} ë§í•œ {ko_title}ì˜ í•µì‹¬"
    return hook


def _generate_shorts_hook_en(en_title: str, author: Optional[str] = None, book_info: Optional[dict] = None) -> str:
    """ì˜ë¬¸ Shortsìš© í›… ì¹´í”¼ ìƒì„± (ì±…ë³„ ë§ì¶¤, ê¶ê¸ˆì¦ ìœ ë°œ)"""
    genre = "general"
    if book_info:
        cats = book_info.get("categories") or []
        if isinstance(cats, str):
            cats = [cats]
        desc = (book_info.get("description") or "").lower()
        text = (" ".join(cats) + " " + desc).lower()
        if any(k in text for k in ["philosophy", "ì² í•™"]):
            genre = "philosophy"
        elif any(k in text for k in ["psychology", "self-help"]):
            genre = "psychology"
        elif any(k in text for k in ["business", "economics"]):
            genre = "business"
        elif any(k in text for k in ["history"]):
            genre = "history"
        elif any(k in text for k in ["fiction", "novel"]):
            genre = "fiction"

    hooks = {
        "philosophy": f"The Truth {en_title} Reveals About Life",
        "psychology": f"What {en_title} Tells Us About Human Nature",
        "business":   f"One Strategy That Makes {en_title} a Must-Read",
        "history":    f"The History Lesson Hidden in {en_title}",
        "fiction":    f"The Human Truth {en_title} Exposes",
        "general":    f"The Most Shocking Line in {en_title}",
    }
    hook = hooks.get(genre, hooks["general"])
    if author:
        hook = f"What {author} Really Wanted Us to Know"
    return hook


def generate_shorts_metadata(
    book_title: str,
    language: str = "ko",
    author: Optional[str] = None,
    output_dir: Optional[str] = None,
    book_info: Optional[dict] = None,
) -> List[dict]:
    """
    Shorts ë©”íƒ€ë°ì´í„°(ì œëª©/ì„¤ëª…/íƒœê·¸) ìƒì„±

    Args:
        book_title: ì±… ì œëª©
        language: 'ko' ë˜ëŠ” 'en'
        author: ì €ì ì´ë¦„ (ì„ íƒ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒ)
        book_info: Google Books ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì„ íƒ, ì¥ë¥´ ê°ì§€ì— ì‚¬ìš©)

    Returns:
        Shortsë³„ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if is_english_title(book_title):
        en_title = book_title
        ko_title = translate_book_title_to_korean(book_title) or book_title
    else:
        ko_title = book_title
        en_title = translate_book_title(book_title) or book_title

    display_title = ko_title if language == "ko" else en_title  # noqa: F841

    try:
        from src.utils.title_generator import generate_hashtags
        hashtags = generate_hashtags(language, book_title, author=author, content_type="summary_video")
    except Exception:
        hashtags = "#Shorts #ì±…ë¦¬ë·° #BookReview" if language == "ko" else "#Shorts #BookReview #BookSummary"

    # ì¡°ì‚¬ ì²˜ë¦¬: "ì„" vs "ë¥¼"
    def _eul_reul(word: str) -> str:
        if not word:
            return "ì„"
        last = word[-1]
        code = ord(last) - 0xAC00
        if 0 <= code < 11172 and code % 28 != 0:
            return "ì„"
        return "ë¥¼"

    metadatas = []
    if language == "ko":
        hook_copy = _generate_shorts_hook_ko(ko_title, author, book_info)
        eul = _eul_reul(ko_title)
        metadatas = [
            {
                "type": "hook",
                "title": f"{hook_copy} #Shorts",
                "description": f"ğŸ“š {ko_title} í•µì‹¬ í¬ì¸íŠ¸\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "ì±…ë¦¬ë·°", "ë…ì„œ", ko_title, "ë¶íŠœë¸Œ", "ì±…ì¶”ì²œ"],
            },
            {
                "type": "quotes",
                "title": f"{ko_title}ì˜ í•µì‹¬ ëª…ì–¸ #Shorts",
                "description": f"ğŸ“– {ko_title} í•µì‹¬ ì¸ìš©êµ¬\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "ëª…ì–¸", "ë…ì„œ", ko_title, "ì¸ìƒëª…ì–¸", "ì±…ì¶”ì²œ"],
            },
            {
                "type": "oneliner",
                "title": f"{ko_title}{eul} í•œ ë¬¸ì¥ìœ¼ë¡œ #Shorts",
                "description": f"ğŸ“š {ko_title} í•œ ì¤„ ìš”ì•½\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "ì±…ìš”ì•½", "ë…ì„œ", ko_title, "í•µì‹¬ìš”ì•½", "ë¶ë¦¬ë·°"],
            },
        ]
    else:
        hook_copy = _generate_shorts_hook_en(en_title, author, book_info)
        metadatas = [
            {
                "type": "hook",
                "title": f"{hook_copy} #Shorts",
                "description": f"ğŸ“š Key points from {en_title}\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "BookReview", "Reading", en_title, "BookTube", "BookRecommendation"],
            },
            {
                "type": "quotes",
                "title": f"Best Quotes from {en_title} #Shorts",
                "description": f"ğŸ“– Key quotes from {en_title}\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "Quotes", "Reading", en_title, "LifeQuotes", "BookRecommendation"],
            },
            {
                "type": "oneliner",
                "title": f"{en_title} in One Sentence #Shorts",
                "description": f"ğŸ“š {en_title} one-line summary\n\n{hashtags} #Shorts",
                "tags": ["Shorts", "BookSummary", "Reading", en_title, "CoreSummary", "BookReview"],
            },
        ]

    # ë©”íƒ€ë°ì´í„° JSON ì €ì¥
    safe_title = get_standard_safe_title(book_title)
    lang_suffix = "ko" if language == "ko" else "en"
    if output_dir:
        out_dir = Path(output_dir)
    else:
        out_dir = Path(f"output/shorts/{safe_title}")
    out_dir.mkdir(parents=True, exist_ok=True)

    import json
    meta_path = out_dir / f"shorts_metadata_{lang_suffix}.json"
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(metadatas, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: {meta_path}")

    return metadatas


def main():
    parser = argparse.ArgumentParser(
        description="YouTube Shorts ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--book-title", required=True, help="ì±… ì œëª©")
    parser.add_argument("--author", help="ì €ì ì´ë¦„ (ì„ íƒ)")
    parser.add_argument("--language", default="ko", choices=["ko", "en"], help="ì–¸ì–´ (ê¸°ë³¸ê°’: ko)")
    parser.add_argument("--tts-provider", default="openai", choices=["openai", "google"], help="TTS ì œê³µì")
    parser.add_argument("--output-dir", help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: output/shorts/{book_title}/)")
    parser.add_argument("--metadata-only", action="store_true", help="ì˜ìƒ ìƒì„± ì—†ì´ ë©”íƒ€ë°ì´í„°ë§Œ ìƒì„±")
    parser.add_argument("--both-languages", action="store_true", help="í•œê¸€+ì˜ë¬¸ ëª¨ë‘ ìƒì„±")

    args = parser.parse_args()

    if args.both_languages:
        for lang in ["ko", "en"]:
            print(f"\n{'='*60}")
            print(f"ğŸŒ ì–¸ì–´: {lang}")
            print(f"{'='*60}")
            if not args.metadata_only:
                generate_shorts(
                    book_title=args.book_title,
                    language=lang,
                    author=args.author,
                    tts_provider=args.tts_provider,
                    output_dir=args.output_dir,
                )
            generate_shorts_metadata(
                book_title=args.book_title,
                language=lang,
                author=args.author,
                output_dir=args.output_dir,
            )
    else:
        if not args.metadata_only:
            generate_shorts(
                book_title=args.book_title,
                language=args.language,
                author=args.author,
                tts_provider=args.tts_provider,
                output_dir=args.output_dir,
            )
        generate_shorts_metadata(
            book_title=args.book_title,
            language=args.language,
            author=args.author,
            output_dir=args.output_dir,
        )


if __name__ == "__main__":
    main()
