"""
TTS (Text-to-Speech) ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸
OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤
"""

import os
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv
from utils.retry_utils import retry_with_backoff

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

load_dotenv()


class TTSEngine:
    """TTS ì—”ì§„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not OPENAI_AVAILABLE:
            raise ImportError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=self.openai_api_key)
    
    @retry_with_backoff(retries=3, backoff_in_seconds=1.0)
    def generate_speech(
        self,
        text: str,
        output_path: str,
        voice: str = "alloy",
        language: str = "ko",
        model: str = "tts-1"
    ) -> str:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            voice: ìŒì„± ì¢…ë¥˜ ('alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer')
            language: ì–¸ì–´ ('ko' ë˜ëŠ” 'en')
            model: TTS ëª¨ë¸ ('tts-1' ë˜ëŠ” 'tts-1-hd')
            
        Returns:
            ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        # ì–¸ì–´ì— ë”°ë¥¸ ìŒì„± ì„ íƒ
        if language == "ko":
            # í•œêµ­ì–´ì— ì í•©í•œ ìŒì„± ì¶”ì²œ:
            # - nova: ë” ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì—¬ì„± ìŒì„± (ì¶”ì²œ)
            # - shimmer: ë¶€ë“œëŸ½ê³  ëª…í™•í•œ ì—¬ì„± ìŒì„±
            # - alloy: ì¤‘ì„±ì ì´ê³  ê· í˜•ì¡íŒ ìŒì„±
            if voice not in ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']:
                voice = "nova"  # í•œêµ­ì–´ì— ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± (ê¸°ë³¸ê°’)
        else:
            # ì˜ì–´ì— ì í•©í•œ ìŒì„±
            if voice not in ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']:
                voice = "alloy"
        
        print(f"ğŸ¤ TTS ìŒì„± ìƒì„± ì¤‘...")
        print(f"   ìŒì„±: {voice}")
        print(f"   ëª¨ë¸: {model}")
        print(f"   ì–¸ì–´: {language}")
        print()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        # OpenAI TTS APIëŠ” ìµœëŒ€ 4096ìê¹Œì§€ë§Œ í—ˆìš©
        MAX_CHARS = 4096
        
        try:
            # í…ìŠ¤íŠ¸ê°€ ê¸¸ë©´ ë¶„í• í•˜ì—¬ ì²˜ë¦¬
            if len(text) <= MAX_CHARS:
                # ì§§ì€ ê²½ìš° í•œ ë²ˆì— ì²˜ë¦¬
                response = self.client.audio.speech.create(
                    model=model,
                    voice=voice,
                    input=text
                )
                
                with open(output_path, 'wb') as f:
                    for chunk in response.iter_bytes():
                        f.write(chunk)
                
                print(f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ: {output_path}")
            else:
                # ê¸´ ê²½ìš° ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ìƒì„± í›„ ì—°ê²°
                print(f"   âš ï¸ í…ìŠ¤íŠ¸ê°€ {len(text)}ìë¡œ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
                import re
                sentences = re.split(r'([.!?]\s+)', text)
                
                # ë¬¸ì¥ë“¤ì„ ì¬ì¡°í•©í•˜ì—¬ ìµœëŒ€ ê¸¸ì´ ì´í•˜ë¡œ ì²­í¬ ìƒì„±
                chunks = []
                current_chunk = ""
                
                for i in range(0, len(sentences), 2):
                    sentence = sentences[i] + (sentences[i+1] if i+1 < len(sentences) else "")
                    
                    if len(current_chunk) + len(sentence) <= MAX_CHARS:
                        current_chunk += sentence
                    else:
                        if current_chunk:
                            chunks.append(current_chunk)
                        # ìƒˆ ì²­í¬ê°€ MAX_CHARSë³´ë‹¤ ê¸¸ë©´ ê°•ì œë¡œ ìë¥´ê¸°
                        if len(sentence) > MAX_CHARS:
                            # ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
                            words = sentence.split()
                            temp_chunk = ""
                            for word in words:
                                if len(temp_chunk) + len(word) + 1 <= MAX_CHARS:
                                    temp_chunk += word + " "
                                else:
                                    if temp_chunk:
                                        chunks.append(temp_chunk.strip())
                                    temp_chunk = word + " "
                            current_chunk = temp_chunk
                        else:
                            current_chunk = sentence
                
                if current_chunk:
                    chunks.append(current_chunk)
                
                print(f"   ğŸ“¦ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë¨")
                
                # ê° ì²­í¬ë¥¼ TTSë¡œ ë³€í™˜
                audio_files = []
                for i, chunk in enumerate(chunks):
                    print(f"   [{i+1}/{len(chunks)}] ì²­í¬ ìƒì„± ì¤‘... ({len(chunk)}ì)")
                    temp_audio_path = output_path.replace('.mp3', f'_temp_{i}.mp3')
                    
                    response = self.client.audio.speech.create(
                        model=model,
                        voice=voice,
                        input=chunk
                    )
                    
                    with open(temp_audio_path, 'wb') as f:
                        for chunk_bytes in response.iter_bytes():
                            f.write(chunk_bytes)
                    
                    audio_files.append(temp_audio_path)
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì„ ì—°ê²°
                print(f"   ğŸ”— {len(audio_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ì—°ê²° ì¤‘...")
                try:
                    from moviepy.editor import AudioFileClip, concatenate_audioclips
                    
                    audio_clips = [AudioFileClip(f) for f in audio_files]
                    final_audio = concatenate_audioclips(audio_clips)
                    final_audio.write_audiofile(output_path, codec='mp3', bitrate='192k')
                    
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    for f in audio_files:
                        Path(f).unlink()
                    
                    # í´ë¦½ ë‹«ê¸°
                    for clip in audio_clips:
                        clip.close()
                    final_audio.close()
                    
                except ImportError:
                    # moviepyê°€ ì—†ìœ¼ë©´ ffmpegë¡œ ì—°ê²°
                    import subprocess
                    temp_list_file = output_path.replace('.mp3', '_temp_list.txt')
                    with open(temp_list_file, 'w') as f:
                        for audio_file in audio_files:
                            f.write(f"file '{Path(audio_file).absolute()}'\n")
                    
                    subprocess.run([
                        'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                        '-i', temp_list_file,
                        '-c', 'copy', output_path
                    ], check=True, capture_output=True)
                    
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    Path(temp_list_file).unlink()
                    for f in audio_files:
                        Path(f).unlink()
                
                print(f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ TTS ìƒì„± ì˜¤ë¥˜: {e}")
            raise
    
    def generate_from_file(
        self,
        text_file_path: str,
        output_path: str = None,
        voice: str = "alloy",
        language: str = "ko",
        model: str = "tts-1"
    ) -> str:
        """
        í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì½ì–´ì„œ ìŒì„± ìƒì„±
        
        Args:
            text_file_path: í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            voice: ìŒì„± ì¢…ë¥˜
            language: ì–¸ì–´
            model: TTS ëª¨ë¸
            
        Returns:
            ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        text_path = Path(text_file_path)
        if not text_path.exists():
            raise FileNotFoundError(f"í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {text_file_path}")
        
        # í…ìŠ¤íŠ¸ ì½ê¸°
        with open(text_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        # ì¶œë ¥ ê²½ë¡œ ìë™ ìƒì„±
        if output_path is None:
            lang_suffix = "ko" if language == "ko" else "en"
            output_path = text_path.parent / f"{text_path.stem}_tts_{lang_suffix}.mp3"
            output_path = str(output_path)
        
        return self.generate_speech(
            text=text,
            output_path=output_path,
            voice=voice,
            language=language,
            model=model
        )


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TTS ìŒì„± ìƒì„±')
    parser.add_argument('--text', type=str, help='ë³€í™˜í•  í…ìŠ¤íŠ¸')
    parser.add_argument('--text-file', type=str, help='í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, required=True, help='ì¶œë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--voice', type=str, default='alloy', choices=['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'], help='ìŒì„± ì¢…ë¥˜ (ê¸°ë³¸ê°’: alloy)')
    parser.add_argument('--language', type=str, default='ko', choices=['ko', 'en'], help='ì–¸ì–´ (ê¸°ë³¸ê°’: ko)')
    parser.add_argument('--model', type=str, default='tts-1', choices=['tts-1', 'tts-1-hd'], help='TTS ëª¨ë¸ (ê¸°ë³¸ê°’: tts-1)')
    
    args = parser.parse_args()
    
    if not args.text and not args.text_file:
        print("âŒ --text ë˜ëŠ” --text-file ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        return 1
    
    try:
        engine = TTSEngine()
        
        if args.text_file:
            output_path = engine.generate_from_file(
                text_file_path=args.text_file,
                output_path=args.output,
                voice=args.voice,
                language=args.language,
                model=args.model
            )
        else:
            output_path = engine.generate_speech(
                text=args.text,
                output_path=args.output,
                voice=args.voice,
                language=args.language,
                model=args.model
            )
        
        print()
        print("=" * 60)
        print("âœ… TTS ìŒì„± ìƒì„± ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1


if __name__ == "__main__":
    exit(main())


