"""
YouTube Analytics APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„ë„ ë° ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

YouTube Analytics API v2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤:
- ì¡°íšŒìˆ˜ (views)
- ì¢‹ì•„ìš” (likes)
- ëŒ“ê¸€ ìˆ˜ (comments)
- êµ¬ë…ì ìˆ˜ (subscribers)
- ì‹œì²­ ì‹œê°„ (watchTime)
- í‰ê·  ì‹œì²­ ì‹œê°„ (averageViewDuration)
"""

import os
import json
import csv
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime, timedelta
from dotenv import load_dotenv

try:
    from google.oauth2.credentials import Credentials
    from google.auth.transport.requests import Request
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    GOOGLE_API_AVAILABLE = True
except ImportError:
    GOOGLE_API_AVAILABLE = False

from utils.logger import get_logger

load_dotenv()

# YouTube Analytics API ìŠ¤ì½”í”„
SCOPES = [
    'https://www.googleapis.com/auth/youtube.readonly',
    'https://www.googleapis.com/auth/yt-analytics.readonly'
]


class YouTubeAnalytics:
    """YouTube Analytics API í´ë˜ìŠ¤"""
    
    def __init__(self):
        if not GOOGLE_API_AVAILABLE:
            raise ImportError("google-api-python-clientê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        self.logger = get_logger(__name__)
        self.client_id = os.getenv("YOUTUBE_CLIENT_ID")
        self.client_secret = os.getenv("YOUTUBE_CLIENT_SECRET")
        self.refresh_token = os.getenv("YOUTUBE_REFRESH_TOKEN")
        self.channel_id = os.getenv("YOUTUBE_CHANNEL_ID")
        
        if not all([self.client_id, self.client_secret, self.refresh_token]):
            raise ValueError("YouTube API ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.youtube = None
        self.youtube_analytics = None
        self._authenticate()
    
    def _authenticate(self):
        """OAuth2 ì¸ì¦"""
        try:
            # ìƒˆë¡œìš´ refresh tokenì€ ëª¨ë“  í•„ìš”í•œ ìŠ¤ì½”í”„ë¥¼ í¬í•¨í•˜ê³  ìˆì„ ê²ƒìœ¼ë¡œ ê°€ì •
            # ë¨¼ì € ì „ì²´ ìŠ¤ì½”í”„ë¡œ ì‹œë„
            try:
                credentials = Credentials(
                    token=None,
                    refresh_token=self.refresh_token,
                    token_uri="https://oauth2.googleapis.com/token",
                    client_id=self.client_id,
                    client_secret=self.client_secret,
                    scopes=SCOPES
                )
                credentials.refresh(Request())
                
                # YouTube Data API v3
                self.youtube = build('youtube', 'v3', credentials=credentials)
                
                # YouTube Analytics API v2
                self.youtube_analytics = build('youtubeAnalytics', 'v2', credentials=credentials)
                
                self.logger.info("âœ… YouTube Data API ë° Analytics API ì¸ì¦ ì„±ê³µ")
            except Exception as full_scope_error:
                # ì „ì²´ ìŠ¤ì½”í”„ ì‹¤íŒ¨ ì‹œ, ê°œë³„ ìŠ¤ì½”í”„ë¡œ ì‹œë„
                self.logger.warning(f"ì „ì²´ ìŠ¤ì½”í”„ ì¸ì¦ ì‹¤íŒ¨, ê°œë³„ ìŠ¤ì½”í”„ë¡œ ì¬ì‹œë„: {full_scope_error}")
                
                # YouTube Data APIìš© (readonly ë˜ëŠ” upload ìŠ¤ì½”í”„)
                data_api_scopes = [
                    'https://www.googleapis.com/auth/youtube.readonly',
                    'https://www.googleapis.com/auth/youtube.upload'
                ]
                
                for scope in data_api_scopes:
                    try:
                        credentials = Credentials(
                            token=None,
                            refresh_token=self.refresh_token,
                            token_uri="https://oauth2.googleapis.com/token",
                            client_id=self.client_id,
                            client_secret=self.client_secret,
                            scopes=[scope]
                        )
                        credentials.refresh(Request())
                        self.youtube = build('youtube', 'v3', credentials=credentials)
                        self.logger.info(f"âœ… YouTube Data API ì¸ì¦ ì„±ê³µ ({scope})")
                        break
                    except Exception:
                        continue
                else:
                    self.logger.error("âŒ YouTube Data API ì¸ì¦ ì‹¤íŒ¨")
                    raise
                
                # Analytics API ì‹œë„
                try:
                    analytics_credentials = Credentials(
                        token=None,
                        refresh_token=self.refresh_token,
                        token_uri="https://oauth2.googleapis.com/token",
                        client_id=self.client_id,
                        client_secret=self.client_secret,
                        scopes=SCOPES
                    )
                    analytics_credentials.refresh(Request())
                    self.youtube_analytics = build('youtubeAnalytics', 'v2', credentials=analytics_credentials)
                    self.logger.info("âœ… YouTube Analytics API ì¸ì¦ ì„±ê³µ")
                except Exception as analytics_error:
                    self.logger.warning(f"âš ï¸ YouTube Analytics API ì¸ì¦ ì‹¤íŒ¨: {analytics_error}")
                    self.logger.warning("   Analytics ìŠ¤ì½”í”„ê°€ í¬í•¨ëœ refresh tokenì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    self.youtube_analytics = None
                
        except Exception as e:
            self.logger.error(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def get_channel_id(self) -> Optional[str]:
        """ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°"""
        if self.channel_id:
            return self.channel_id
        
        try:
            response = self.youtube.channels().list(
                part='id',
                mine=True
            ).execute()
            
            if response.get('items'):
                channel_id = response['items'][0]['id']
                self.logger.info(f"âœ… ì±„ë„ ID: {channel_id}")
                return channel_id
            return None
        except Exception as e:
            self.logger.error(f"âŒ ì±„ë„ ID ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def get_channel_metrics(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        metrics: List[str] = None
    ) -> Optional[Dict]:
        """
        ì±„ë„ ì „ì²´ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: 30ì¼ ì „)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
            metrics: ìˆ˜ì§‘í•  ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: views, likes, comments, subscribers)
        
        Returns:
            ë©”íŠ¸ë¦­ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        channel_id = self.get_channel_id()
        if not channel_id:
            self.logger.error("ì±„ë„ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        
        if metrics is None:
            # subscribersëŠ” ì±„ë„ ë ˆë²¨ ë©”íŠ¸ë¦­ì´ ì•„ë‹ˆë¯€ë¡œ ì œì™¸
            metrics = ['views', 'likes', 'comments', 'estimatedMinutesWatched', 'averageViewDuration']
        
        if not self.youtube_analytics:
            self.logger.error("YouTube Analytics APIê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Analytics ìŠ¤ì½”í”„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None
        
        try:
            response = self.youtube_analytics.reports().query(
                ids=f'channel=={channel_id}',
                startDate=start_date,
                endDate=end_date,
                metrics=','.join(metrics)
            ).execute()
            
            self.logger.info(f"âœ… ì±„ë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ ({start_date} ~ {end_date})")
            return response
        except HttpError as e:
            self.logger.error(f"âŒ ì±„ë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return None
    
    def get_video_metrics(
        self,
        video_id: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        metrics: List[str] = None
    ) -> Optional[Dict]:
        """
        íŠ¹ì • ì˜ìƒì˜ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            video_id: YouTube ì˜ìƒ ID
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: ì˜ìƒ ì—…ë¡œë“œ ë‚ ì§œ)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
            metrics: ìˆ˜ì§‘í•  ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë©”íŠ¸ë¦­ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        channel_id = self.get_channel_id()
        if not channel_id:
            self.logger.error("ì±„ë„ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if start_date is None:
            # ì˜ìƒ ì—…ë¡œë“œ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
            try:
                video_response = self.youtube.videos().list(
                    part='snippet',
                    id=video_id
                ).execute()
                
                if video_response.get('items'):
                    published_at = video_response['items'][0]['snippet']['publishedAt']
                    start_date = published_at[:10]  # YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                else:
                    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            except Exception as e:
                self.logger.warning(f"ì˜ìƒ ì—…ë¡œë“œ ë‚ ì§œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        
        if metrics is None:
            metrics = ['views', 'likes', 'comments', 'estimatedMinutesWatched', 'averageViewDuration']
        
        if not self.youtube_analytics:
            self.logger.error("YouTube Analytics APIê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Analytics ìŠ¤ì½”í”„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None
        
        try:
            response = self.youtube_analytics.reports().query(
                ids=f'channel=={channel_id}',
                filters=f'video=={video_id}',
                startDate=start_date,
                endDate=end_date,
                metrics=','.join(metrics)
            ).execute()
            
            self.logger.info(f"âœ… ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ (video_id: {video_id})")
            return response
        except HttpError as e:
            self.logger.error(f"âŒ ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return None
    
    def get_channel_videos(self, max_results: int = 50) -> List[Dict]:
        """
        ì±„ë„ì˜ ëª¨ë“  ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
        Returns:
            ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        channel_id = self.get_channel_id()
        if not channel_id:
            self.logger.error("ì±„ë„ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            videos = []
            next_page_token = None
            
            # ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
            channel_response = self.youtube.channels().list(
                part='contentDetails',
                id=channel_id
            ).execute()
            
            if not channel_response.get('items'):
                self.logger.error("ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            upload_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            
            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            while len(videos) < max_results:
                request_params = {
                    'part': 'contentDetails',
                    'playlistId': upload_playlist_id,
                    'maxResults': min(50, max_results - len(videos))
                }
                
                if next_page_token:
                    request_params['pageToken'] = next_page_token
                
                playlist_response = self.youtube.playlistItems().list(**request_params).execute()
                
                # ì˜ìƒ ID ëª©ë¡ ìˆ˜ì§‘
                video_ids = []
                for item in playlist_response.get('items', []):
                    video_id = item['contentDetails']['videoId']
                    video_ids.append(video_id)
                
                if not video_ids:
                    break
                
                # ì˜ìƒ ìƒì„¸ ì •ë³´ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°
                video_response = self.youtube.videos().list(
                    part='id,snippet,statistics',
                    id=','.join(video_ids)
                ).execute()
                
                for video_info in video_response.get('items', []):
                    video_id = video_info['id']
                    videos.append({
                        'video_id': video_id,
                        'title': video_info['snippet']['title'],
                        'published_at': video_info['snippet']['publishedAt'],
                        'views': int(video_info['statistics'].get('viewCount', 0)),
                        'likes': int(video_info['statistics'].get('likeCount', 0)),
                        'comments': int(video_info['statistics'].get('commentCount', 0)),
                        'url': f"https://www.youtube.com/watch?v={video_id}"
                    })
                
                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break
            
            self.logger.info(f"âœ… ì±„ë„ ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ ({len(videos)}ê°œ)")
            return videos
        except Exception as e:
            self.logger.error(f"âŒ ì±„ë„ ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_all_video_metrics(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> List[Dict]:
        """
        ì±„ë„ì˜ ëª¨ë“  ì˜ìƒì— ëŒ€í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
        
        Returns:
            ì˜ìƒë³„ ë©”íŠ¸ë¦­ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        videos = self.get_channel_videos()
        all_metrics = []
        
        for video in videos:
            video_id = video['video_id']
            self.logger.info(f"ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘: {video['title']}")
            
            metrics = self.get_video_metrics(
                video_id=video_id,
                start_date=start_date,
                end_date=end_date
            )
            
            if metrics:
                # ë©”íŠ¸ë¦­ ë°ì´í„°ì™€ ì˜ìƒ ì •ë³´ ê²°í•©
                video_metrics = {
                    **video,
                    'analytics': metrics
                }
                all_metrics.append(video_metrics)
        
        self.logger.info(f"âœ… ì „ì²´ ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ ({len(all_metrics)}ê°œ)")
        return all_metrics
    
    def save_metrics_to_json(self, metrics: Dict, output_path: str = "output/youtube_metrics.json"):
        """ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"ğŸ’¾ ë©”íŠ¸ë¦­ ë°ì´í„° ì €ì¥: {output_file}")
    
    def save_video_metrics_to_csv(
        self,
        video_metrics: List[Dict],
        output_path: str = "output/youtube_video_metrics.csv"
    ):
        """ì˜ìƒ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # CSV ë°ì´í„° ì¤€ë¹„
        rows = []
        for video in video_metrics:
            row = {
                'video_id': video.get('video_id', ''),
                'title': video.get('title', ''),
                'published_at': video.get('published_at', ''),
                'url': video.get('url', ''),
                'views': video.get('views', 0),
                'likes': video.get('likes', 0),
                'comments': video.get('comments', 0)
            }
            
            # Analytics ë°ì´í„° ì¶”ê°€
            analytics = video.get('analytics', {})
            if analytics and 'rows' in analytics:
                for metric_row in analytics['rows']:
                    # ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ ê°’ ë§¤í•‘
                    column_headers = analytics.get('columnHeaders', [])
                    for i, header in enumerate(column_headers):
                        metric_name = header.get('name', '')
                        if i < len(metric_row):
                            row[metric_name] = metric_row[i]
            
            rows.append(row)
        
        # CSV ì €ì¥
        if rows:
            fieldnames = set()
            for row in rows:
                fieldnames.update(row.keys())
            
            with open(output_file, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=sorted(fieldnames))
                writer.writeheader()
                writer.writerows(rows)
            
            self.logger.info(f"ğŸ’¾ ì˜ìƒ ë©”íŠ¸ë¦­ CSV ì €ì¥: {output_file} ({len(rows)}ê°œ ì˜ìƒ)")
    
    def generate_weekly_report(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        output_path: str = "output/weekly_report.md"
    ) -> Optional[str]:
        """
        ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: 7ì¼ ì „)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
            output_path: ë¦¬í¬íŠ¸ ì¶œë ¥ ê²½ë¡œ
        
        Returns:
            ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
        """
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        
        self.logger.info(f"ğŸ“Š ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ({start_date} ~ {end_date})")
        
        # ì±„ë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        channel_metrics = self.get_channel_metrics(start_date, end_date)
        video_metrics = self.collect_all_video_metrics(start_date, end_date)
        
        if not channel_metrics and not video_metrics:
            self.logger.warning("ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = self._format_report(
            title="ì£¼ê°„ ë¦¬í¬íŠ¸",
            start_date=start_date,
            end_date=end_date,
            channel_metrics=channel_metrics,
            video_metrics=video_metrics
        )
        
        # íŒŒì¼ ì €ì¥
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info(f"ğŸ’¾ ì£¼ê°„ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
        return str(output_file)
    
    def generate_monthly_report(
        self,
        year: Optional[int] = None,
        month: Optional[int] = None,
        output_path: str = "output/monthly_report.md"
    ) -> Optional[str]:
        """
        ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            year: ì—°ë„ (ê¸°ë³¸ê°’: í˜„ì¬ ì—°ë„)
            month: ì›” (ê¸°ë³¸ê°’: í˜„ì¬ ì›”)
            output_path: ë¦¬í¬íŠ¸ ì¶œë ¥ ê²½ë¡œ
        
        Returns:
            ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
        """
        now = datetime.now()
        if year is None:
            year = now.year
        if month is None:
            month = now.month
        
        # í•´ë‹¹ ì›”ì˜ ì²«ë‚ ê³¼ ë§ˆì§€ë§‰ë‚  ê³„ì‚°
        start_date = datetime(year, month, 1).strftime('%Y-%m-%d')
        if month == 12:
            end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
        else:
            end_date = datetime(year, month + 1, 1) - timedelta(days=1)
        end_date_str = end_date.strftime('%Y-%m-%d')
        
        self.logger.info(f"ğŸ“Š ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ({year}ë…„ {month}ì›”)")
        
        # ì±„ë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        channel_metrics = self.get_channel_metrics(start_date, end_date_str)
        video_metrics = self.collect_all_video_metrics(start_date, end_date_str)
        
        if not channel_metrics and not video_metrics:
            self.logger.warning("ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = self._format_report(
            title=f"{year}ë…„ {month}ì›” ì›”ê°„ ë¦¬í¬íŠ¸",
            start_date=start_date,
            end_date=end_date_str,
            channel_metrics=channel_metrics,
            video_metrics=video_metrics
        )
        
        # íŒŒì¼ ì €ì¥
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info(f"ğŸ’¾ ì›”ê°„ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
        return str(output_file)
    
    def _format_report(
        self,
        title: str,
        start_date: str,
        end_date: str,
        channel_metrics: Optional[Dict],
        video_metrics: List[Dict]
    ) -> str:
        """
        ë¦¬í¬íŠ¸ í¬ë§·íŒ…
        
        Args:
            title: ë¦¬í¬íŠ¸ ì œëª©
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            channel_metrics: ì±„ë„ ë©”íŠ¸ë¦­ ë°ì´í„°
            video_metrics: ì˜ìƒë³„ ë©”íŠ¸ë¦­ ë°ì´í„°
        
        Returns:
            í¬ë§·íŒ…ëœ ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ (Markdown)
        """
        report_lines = []
        
        # í—¤ë”
        report_lines.append(f"# {title}")
        report_lines.append("")
        report_lines.append(f"**ê¸°ê°„**: {start_date} ~ {end_date}")
        report_lines.append(f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")
        
        # ì±„ë„ ì „ì²´ ë©”íŠ¸ë¦­
        if channel_metrics:
            report_lines.append("## ğŸ“Š ì±„ë„ ì „ì²´ ë©”íŠ¸ë¦­")
            report_lines.append("")
            
            if 'rows' in channel_metrics and channel_metrics['rows']:
                column_headers = channel_metrics.get('columnHeaders', [])
                row_data = channel_metrics['rows'][0]
                
                for i, header in enumerate(column_headers):
                    metric_name = header.get('name', '')
                    metric_value = row_data[i] if i < len(row_data) else 0
                    
                    # ë©”íŠ¸ë¦­ ì´ë¦„ í•œê¸€í™”
                    metric_name_ko = {
                        'views': 'ì¡°íšŒìˆ˜',
                        'likes': 'ì¢‹ì•„ìš”',
                        'comments': 'ëŒ“ê¸€ ìˆ˜',
                        'subscribers': 'êµ¬ë…ì ìˆ˜',
                        'estimatedMinutesWatched': 'ì‹œì²­ ì‹œê°„ (ë¶„)',
                        'averageViewDuration': 'í‰ê·  ì‹œì²­ ì‹œê°„ (ì´ˆ)'
                    }.get(metric_name, metric_name)
                    
                    # ê°’ í¬ë§·íŒ…
                    if isinstance(metric_value, (int, float)):
                        if metric_name == 'estimatedMinutesWatched':
                            hours = metric_value / 60
                            report_lines.append(f"- **{metric_name_ko}**: {metric_value:,.0f}ë¶„ ({hours:,.1f}ì‹œê°„)")
                        elif metric_name == 'averageViewDuration':
                            minutes = metric_value / 60
                            report_lines.append(f"- **{metric_name_ko}**: {metric_value:,.0f}ì´ˆ ({minutes:,.1f}ë¶„)")
                        else:
                            report_lines.append(f"- **{metric_name_ko}**: {metric_value:,}")
                    else:
                        report_lines.append(f"- **{metric_name_ko}**: {metric_value}")
                
                report_lines.append("")
        
        # ì˜ìƒë³„ ë©”íŠ¸ë¦­
        if video_metrics:
            report_lines.append("## ğŸ“¹ ì˜ìƒë³„ ë©”íŠ¸ë¦­")
            report_lines.append("")
            report_lines.append(f"**ì´ ì˜ìƒ ìˆ˜**: {len(video_metrics)}ê°œ")
            report_lines.append("")
            
            # ì¡°íšŒìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ ì˜ìƒ
            sorted_videos = sorted(
                video_metrics,
                key=lambda x: x.get('views', 0),
                reverse=True
            )[:10]
            
            report_lines.append("### ğŸ”¥ ì¡°íšŒìˆ˜ ìƒìœ„ 10ê°œ ì˜ìƒ")
            report_lines.append("")
            report_lines.append("| ìˆœìœ„ | ì œëª© | ì¡°íšŒìˆ˜ | ì¢‹ì•„ìš” | ëŒ“ê¸€ | URL |")
            report_lines.append("|------|------|--------|--------|------|-----|")
            
            for i, video in enumerate(sorted_videos, 1):
                title = video.get('title', 'N/A')[:50]  # ì œëª© ê¸¸ì´ ì œí•œ
                views = video.get('views', 0)
                likes = video.get('likes', 0)
                comments = video.get('comments', 0)
                url = video.get('url', '')
                
                report_lines.append(f"| {i} | {title} | {views:,} | {likes:,} | {comments:,} | [ë§í¬]({url}) |")
            
            report_lines.append("")
            
            # í†µê³„ ìš”ì•½
            total_views = sum(v.get('views', 0) for v in video_metrics)
            total_likes = sum(v.get('likes', 0) for v in video_metrics)
            total_comments = sum(v.get('comments', 0) for v in video_metrics)
            avg_views = total_views / len(video_metrics) if video_metrics else 0
            
            report_lines.append("### ğŸ“ˆ í†µê³„ ìš”ì•½")
            report_lines.append("")
            report_lines.append(f"- **ì´ ì¡°íšŒìˆ˜**: {total_views:,}")
            report_lines.append(f"- **ì´ ì¢‹ì•„ìš”**: {total_likes:,}")
            report_lines.append(f"- **ì´ ëŒ“ê¸€ ìˆ˜**: {total_comments:,}")
            report_lines.append(f"- **í‰ê·  ì¡°íšŒìˆ˜**: {avg_views:,.0f}")
            report_lines.append("")
        
        # í‘¸í„°
        report_lines.append("---")
        report_lines.append("")
        report_lines.append("*ì´ ë¦¬í¬íŠ¸ëŠ” YouTube Analytics APIë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
        
        return "\n".join(report_lines)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YouTube Analytics ë©”íŠ¸ë¦­ ìˆ˜ì§‘')
    parser.add_argument('--channel', action='store_true', help='ì±„ë„ ì „ì²´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘')
    parser.add_argument('--videos', action='store_true', help='ëª¨ë“  ì˜ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘')
    parser.add_argument('--video-id', type=str, help='íŠ¹ì • ì˜ìƒ IDì˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘')
    parser.add_argument('--start-date', type=str, help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, help='ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--output-json', type=str, default='output/youtube_metrics.json', help='JSON ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output-csv', type=str, default='output/youtube_video_metrics.csv', help='CSV ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--weekly-report', action='store_true', help='ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±')
    parser.add_argument('--monthly-report', action='store_true', help='ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±')
    parser.add_argument('--year', type=int, help='ì›”ê°„ ë¦¬í¬íŠ¸ìš© ì—°ë„')
    parser.add_argument('--month', type=int, help='ì›”ê°„ ë¦¬í¬íŠ¸ìš© ì›”')
    parser.add_argument('--report-output', type=str, help='ë¦¬í¬íŠ¸ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    try:
        analytics = YouTubeAnalytics()
        
        if args.channel:
            # ì±„ë„ ì „ì²´ ë©”íŠ¸ë¦­
            metrics = analytics.get_channel_metrics(
                start_date=args.start_date,
                end_date=args.end_date
            )
            if metrics:
                analytics.save_metrics_to_json(metrics, args.output_json)
        
        elif args.videos:
            # ëª¨ë“  ì˜ìƒ ë©”íŠ¸ë¦­
            video_metrics = analytics.collect_all_video_metrics(
                start_date=args.start_date,
                end_date=args.end_date
            )
            if video_metrics:
                analytics.save_metrics_to_json(video_metrics, args.output_json)
                analytics.save_video_metrics_to_csv(video_metrics, args.output_csv)
        
        elif args.video_id:
            # íŠ¹ì • ì˜ìƒ ë©”íŠ¸ë¦­
            metrics = analytics.get_video_metrics(
                video_id=args.video_id,
                start_date=args.start_date,
                end_date=args.end_date
            )
            if metrics:
                analytics.save_metrics_to_json(metrics, args.output_json)
        
        elif args.weekly_report:
            # ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±
            output_path = args.report_output or "output/weekly_report.md"
            report_path = analytics.generate_weekly_report(
                start_date=args.start_date,
                end_date=args.end_date,
                output_path=output_path
            )
            if report_path:
                print(f"âœ… ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")
        
        elif args.monthly_report:
            # ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
            output_path = args.report_output or "output/monthly_report.md"
            report_path = analytics.generate_monthly_report(
                year=args.year,
                month=args.month,
                output_path=output_path
            )
            if report_path:
                print(f"âœ… ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")
        
        else:
            parser.print_help()
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

