"""
Phase 4: ì˜ìƒ í•©ì„± ë° í¸ì§‘ ìŠ¤í¬ë¦½íŠ¸
- ì˜¤ë””ì˜¤ ë¡œë“œ
- ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„± (ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶°)
- Ken Burns íš¨ê³¼ (ì¤Œì¸/íŒ¨ë‹)
- ì „í™˜ íš¨ê³¼ (í˜ì´ë“œ)
- ìë§‰ (OpenAI Whisper, ì„ íƒì‚¬í•­)
- ë Œë”ë§: 1080p, 30fps MP4
"""

import os
import random
import math
from pathlib import Path
from typing import List, Optional, Tuple
from dotenv import load_dotenv

try:
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, TextClip, ColorClip, concatenate_videoclips
    from moviepy.video.fx.all import fadein, fadeout
    MOVIEPY_AVAILABLE = True
    MOVIEPY_VERSION_NEW = True
except ImportError as e:
    try:
        # êµ¬ë²„ì „ í˜¸í™˜ì„±
        from moviepy import ImageClip, AudioFileClip, CompositeVideoClip, TextClip, ColorClip, concatenate_videoclips
        from moviepy.video.fx import FadeIn, FadeOut, CrossFadeIn, CrossFadeOut
        MOVIEPY_AVAILABLE = True
        MOVIEPY_VERSION_NEW = False
    except ImportError:
        MOVIEPY_AVAILABLE = False
        MOVIEPY_VERSION_NEW = False
        print(f"âš ï¸ MoviePy import ì˜¤ë¥˜: {e}")
        print("pip install moviepy")

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

load_dotenv()


class VideoMaker:
    """ì˜ìƒ ì œì‘ í´ë˜ìŠ¤"""
    
    def __init__(self, resolution: Tuple[int, int] = (1920, 1080), fps: int = 30):
        """
        Args:
            resolution: í•´ìƒë„ (width, height)
            fps: í”„ë ˆì„ë ˆì´íŠ¸
        """
        self.resolution = resolution
        self.fps = fps
        
        if not MOVIEPY_AVAILABLE:
            raise ImportError("MoviePyê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install moviepy")
    
    def load_audio(self, audio_path: str) -> AudioFileClip:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ"""
        audio_file = Path(audio_path)
        if not audio_file.exists():
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘: {audio_path}")
        try:
            audio = AudioFileClip(audio_path)
            print(f"   ê¸¸ì´: {audio.duration:.2f}ì´ˆ")
        except Exception as e:
            raise ValueError(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return audio
    
    def _ease_in_out(self, t: float) -> float:
        """
        ë¶€ë“œëŸ¬ìš´ easing í•¨ìˆ˜ (ease-in-out cubic)
        ì‹œì‘ê³¼ ëì—ì„œ ëŠë¦¬ê²Œ, ì¤‘ê°„ì—ì„œ ë¹ ë¥´ê²Œ
        """
        if t < 0.5:
            return 4 * t * t * t
        else:
            return 1 - pow(-2 * t + 2, 3) / 2
    
    def create_image_clip_with_ken_burns(
        self,
        image_path: str,
        duration: float,
        effect_type: str = "zoom_in",
        start_scale: float = 1.0,
        end_scale: float = 1.2,
        pan_direction: Optional[str] = None
    ) -> ImageClip:
        """
        Ken Burns íš¨ê³¼ê°€ ì ìš©ëœ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± (ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜)
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            duration: í´ë¦½ ê¸¸ì´ (ì´ˆ)
            effect_type: íš¨ê³¼ íƒ€ì… ("zoom_in", "zoom_out")
            start_scale: ì‹œì‘ ìŠ¤ì¼€ì¼
            end_scale: ë ìŠ¤ì¼€ì¼
            pan_direction: íŒ¨ë‹ ë°©í–¥ ("left", "right", "up", "down")
        """
        from PIL import Image
        import numpy as np
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (í•´ìƒë„ë³´ë‹¤ í¬ê²Œ)
        img = Image.open(image_path)
        img_width, img_height = img.size
        
        # í•´ìƒë„ ë¹„ìœ¨ ê³„ì‚°
        target_width, target_height = self.resolution
        aspect_ratio = target_width / target_height
        img_aspect = img_width / img_height
        
        # ì´ë¯¸ì§€ë¥¼ í•´ìƒë„ë³´ë‹¤ í¬ê²Œ ë¦¬ì‚¬ì´ì¦ˆ (ì¤Œ íš¨ê³¼ë¥¼ ìœ„í•´)
        # ìµœëŒ€ ìŠ¤ì¼€ì¼ë³´ë‹¤ ë” í¬ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ íŒ¨ë‹ ì—¬ìœ  ê³µê°„ í™•ë³´
        max_scale = max(end_scale, start_scale) * 1.2  # 20% ì—¬ìœ 
        scaled_width = int(target_width * max_scale)
        scaled_height = int(target_height * max_scale)
        
        # ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
        if img_aspect > aspect_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ
            scaled_height = int(scaled_width / img_aspect)
        else:
            # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ
            scaled_width = int(scaled_height * img_aspect)
        
        # ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
        img = img.resize((scaled_width, scaled_height), Image.Resampling.LANCZOS)
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (í•œ ë²ˆë§Œ)
        img_array = np.array(img)
        
        # Ken Burns íš¨ê³¼ ì ìš© (ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜)
        def make_frame(t):
            # ì§„í–‰ë¥  ê³„ì‚° (0.0 ~ 1.0)
            progress = t / duration if duration > 0 else 0
            progress = min(1.0, max(0.0, progress))
            
            # Easing ì ìš© (ë¶€ë“œëŸ¬ìš´ ì „í™˜)
            eased_progress = self._ease_in_out(progress)
            
            # ìŠ¤ì¼€ì¼ ê³„ì‚° (easing ì ìš©)
            if effect_type == "zoom_out":
                current_scale = start_scale + (end_scale - start_scale) * (1 - eased_progress)
            else:  # zoom_in or default
                current_scale = start_scale + (end_scale - start_scale) * eased_progress
            
            # íŒ¨ë‹ ê³„ì‚° (easing ì ìš©)
            pan_x = 0
            pan_y = 0
            if pan_direction:
                # íŒ¨ë‹ë„ easing ì ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ
                pan_amount = 0.15 * eased_progress  # ìµœëŒ€ 15% ì´ë™
                if pan_direction == "left":
                    pan_x = -pan_amount
                elif pan_direction == "right":
                    pan_x = pan_amount
                elif pan_direction == "up":
                    pan_y = -pan_amount
                elif pan_direction == "down":
                    pan_y = pan_amount
            
            # í˜„ì¬ í”„ë ˆì„ í¬ê¸° ê³„ì‚°
            current_width = int(target_width / current_scale)
            current_height = int(target_height / current_scale)
            
            # ì¤‘ì‹¬ì  ê³„ì‚° (ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            center_x = scaled_width // 2
            center_y = scaled_height // 2
            
            # íŒ¨ë‹ ì ìš© (ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€)
            center_x += int(pan_x * scaled_width)
            center_y += int(pan_y * scaled_height)
            
            # í¬ë¡­ ì˜ì—­ ê³„ì‚° (ê²½ê³„ ì²´í¬ ê°•í™”)
            left = max(0, center_x - current_width // 2)
            top = max(0, center_y - current_height // 2)
            right = min(scaled_width, left + current_width)
            bottom = min(scaled_height, top + current_height)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if right <= left or bottom <= top:
                # ì˜ëª»ëœ í¬ë¡­ ì˜ì—­ì´ë©´ ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                from PIL import Image as PILImage
                resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                return np.array(resized)
            
            # í¬ë¡­ (numpy ë°°ì—´ ìŠ¬ë¼ì´ì‹± ì‚¬ìš© - ë” ë¹ ë¦„)
            try:
                cropped = img_array[top:bottom, left:right]
                
                # ë¹ˆ ë°°ì—´ ì²´í¬
                if cropped.size == 0:
                    from PIL import Image as PILImage
                    resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                    return np.array(resized)
                
                # ë¦¬ì‚¬ì´ì¦ˆ (ê³ í’ˆì§ˆ)
                from PIL import Image as PILImage
                cropped_img = PILImage.fromarray(cropped)
                resized = cropped_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                
                return np.array(resized)
            except (IndexError, ValueError) as e:
                # í¬ë¡­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                from PIL import Image as PILImage
                resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                return np.array(resized)
        
        # make_frame í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦½ ìƒì„±
        try:
            # fl ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ë³„ë¡œ íš¨ê³¼ ì ìš©
            clip = ImageClip(img_array, duration=duration)
            clip = clip.fl(lambda get_frame, t: make_frame(t), apply_to=['video'])
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜ (íš¨ê³¼ ì—†ì´)
            print(f"   âš ï¸ Ken Burns íš¨ê³¼ ì ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë¦½ ì‚¬ìš©: {e}")
            clip = ImageClip(img_array, duration=duration)
            clip = clip.resized(newsize=self.resolution)
        
        return clip
    
    def create_image_sequence(
        self,
        image_paths: List[str],
        total_duration: float,
        fade_duration: float = 2.0  # í˜ì´ë“œ ì‹œê°„ (2ì´ˆë¡œ ì ë‹¹í•˜ê²Œ)
    ) -> List[ImageClip]:
        """
        ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„± (ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶°)
        
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            total_duration: ì „ì²´ ê¸¸ì´ (ì˜¤ë””ì˜¤ ê¸¸ì´)
            fade_duration: í˜ì´ë“œ ì „í™˜ ì‹œê°„
        """
        if not image_paths:
            raise ValueError("ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        num_images = len(image_paths)
        # ì´ë¯¸ì§€ë‹¹ ìµœì†Œ í‘œì‹œ ì‹œê°„ ë³´ì¥ (ë„ˆë¬´ ë¹ ë¥´ê²Œ ë°”ë€Œì§€ ì•Šë„ë¡)
        min_duration_per_image = 5.0  # ìµœì†Œ 5ì´ˆ (ì ë‹¹í•œ ì†ë„)
        duration_per_image = max(total_duration / num_images, min_duration_per_image)
        
        # ì‹¤ì œ í•„ìš”í•œ ì´ë¯¸ì§€ ê°œìˆ˜ ì¬ê³„ì‚° (ë„ˆë¬´ ë§ì€ ì´ë¯¸ì§€ ì‚¬ìš© ë°©ì§€)
        if duration_per_image > total_duration / num_images:
            # ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ ì¤„ì—¬ì„œ ê° ì´ë¯¸ì§€ê°€ ë” ì˜¤ë˜ í‘œì‹œë˜ë„ë¡
            effective_num_images = min(num_images, int(total_duration / min_duration_per_image))
            if effective_num_images < num_images:
                # ì´ë¯¸ì§€ ì„ íƒ (ê· ë“±í•˜ê²Œ ë¶„ì‚°)
                step = num_images / effective_num_images
                image_paths = [image_paths[int(i * step)] for i in range(effective_num_images)]
                num_images = effective_num_images
                duration_per_image = total_duration / num_images
        
        print(f"   ğŸ“Š ì´ë¯¸ì§€ ê°œìˆ˜: {num_images}ê°œ (ê° {duration_per_image:.1f}ì´ˆ í‘œì‹œ)")
        
        clips = []
        
        for i, image_path in enumerate(image_paths):
            # ì •ì  ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (ì¤Œì¸ íš¨ê³¼ ì œê±°)
            clip = ImageClip(image_path, duration=duration_per_image)
            clip = clip.resize(newsize=self.resolution)
            
            # í˜ì´ë“œ íš¨ê³¼ ì¶”ê°€
            if MOVIEPY_AVAILABLE:
                if MOVIEPY_VERSION_NEW:
                    # MoviePy 1.0+ ë²„ì „
                    if i == 0:
                        # ì²« ë²ˆì§¸: í˜ì´ë“œì¸
                        clip = clip.fx(fadein, fade_duration)
                    elif i == len(image_paths) - 1:
                        # ë§ˆì§€ë§‰: í˜ì´ë“œì•„ì›ƒ
                        clip = clip.fx(fadeout, fade_duration)
                    else:
                        # ì¤‘ê°„: ì–‘ìª½ ëª¨ë‘ í˜ì´ë“œ (í¬ë¡œìŠ¤í˜ì´ë“œ íš¨ê³¼)
                        # í˜ì´ë“œì¸ê³¼ í˜ì´ë“œì•„ì›ƒì„ ëª¨ë‘ ì ìš©í•˜ì—¬ ë¶€ë“œëŸ¬ìš´ ì „í™˜
                        fade_out_duration = min(fade_duration, duration_per_image / 2)
                        fade_in_duration = min(fade_duration, duration_per_image / 2)
                        clip = clip.fx(fadein, fade_in_duration).fx(fadeout, fade_out_duration)
                else:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„±
                    try:
                        if i == 0:
                            clip = clip.with_effects([FadeIn(fade_duration)])
                        elif i == len(image_paths) - 1:
                            clip = clip.with_effects([FadeOut(fade_duration)])
                        else:
                            clip = clip.with_effects([CrossFadeIn(fade_duration)])
                    except:
                        # í˜ì´ë“œ íš¨ê³¼ ì—†ì´ ì§„í–‰
                        pass
            
            clips.append(clip)
        
        return clips
    
    def generate_subtitles(self, audio_path: str, language: str = "ko") -> Optional[List[dict]]:
        """
        OpenAI Whisperë¡œ ìë§‰ ìƒì„±
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ ("ko", "en" ë“±)
            
        Returns:
            ìë§‰ ë¦¬ìŠ¤íŠ¸ [{"start": float, "end": float, "text": str}, ...]
        """
        if not WHISPER_AVAILABLE:
            print("âš ï¸ Whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë§‰ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        print("ğŸ“ ìë§‰ ìƒì„± ì¤‘ (Whisper)...")
        try:
            model = whisper.load_model("base")
            result = model.transcribe(audio_path, language=language)
            
            subtitles = []
            for segment in result.get("segments", []):
                subtitles.append({
                    "start": segment["start"],
                    "end": segment["end"],
                    "text": segment["text"].strip()
                })
            
            print(f"   âœ… {len(subtitles)}ê°œì˜ ìë§‰ ìƒì„± ì™„ë£Œ")
            return subtitles
            
        except Exception as e:
            print(f"   âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def add_subtitles(
        self,
        video_clip: CompositeVideoClip,
        subtitles: List[dict],
        font_size: int = 60,
        font_color: str = "white",
        stroke_color: str = "black",
        stroke_width: int = 2
    ) -> CompositeVideoClip:
        """
        ìë§‰ ì˜¤ë²„ë ˆì´ ì¶”ê°€
        
        Args:
            video_clip: ë¹„ë””ì˜¤ í´ë¦½
            subtitles: ìë§‰ ë¦¬ìŠ¤íŠ¸
            font_size: í°íŠ¸ í¬ê¸°
            font_color: í°íŠ¸ ìƒ‰ìƒ
            stroke_color: í…Œë‘ë¦¬ ìƒ‰ìƒ
            stroke_width: í…Œë‘ë¦¬ ë‘ê»˜
        """
        if not subtitles:
            return video_clip
        
        subtitle_clips = []
        
        for subtitle in subtitles:
            try:
                text_clip = TextClip(
                    subtitle["text"],
                    fontsize=font_size,
                    color=font_color,
                    stroke_color=stroke_color,
                    stroke_width=stroke_width,
                    method='caption',
                    size=(self.resolution[0] - 100, None),
                    align='center'
                ).with_duration(subtitle["end"] - subtitle["start"]).with_start(subtitle["start"]).with_position(('center', self.resolution[1] - 150))
                
                subtitle_clips.append(text_clip)
            except Exception as e:
                print(f"   âš ï¸ ìë§‰ ìƒì„± ì˜¤ë¥˜: {e}")
                continue
        
        if subtitle_clips:
            return CompositeVideoClip([video_clip] + subtitle_clips)
        
        return video_clip
    
    def create_video(
        self,
        audio_path: str,
        image_dir: str,
        output_path: str,
        add_subtitles_flag: bool = False,
        language: str = "ko",
        max_duration: Optional[float] = None
    ) -> str:
        """
        ìµœì¢… ì˜ìƒ ìƒì„±
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            add_subtitles_flag: ìë§‰ ì¶”ê°€ ì—¬ë¶€
            language: ìë§‰ ì–¸ì–´
        """
        print("=" * 60)
        print("ğŸ¬ ì˜ìƒ ì œì‘ ì‹œì‘")
        print("=" * 60)
        print()
        
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = self.load_audio(audio_path)
        audio_duration = audio.duration
        
        # í…ŒìŠ¤íŠ¸ìš©: ìµœëŒ€ ê¸¸ì´ ì œí•œ
        if max_duration and audio_duration > max_duration:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ì œí•œ: {audio_duration:.2f}ì´ˆ â†’ {max_duration}ì´ˆ")
            audio = audio.subclip(0, max_duration)
            audio_duration = max_duration
        
        print()
        
        # 2. ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
        image_dir_path = Path(image_dir)
        if not image_dir_path.exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        cover_path = image_dir_path / "cover.jpg"
        mood_images = sorted(image_dir_path.glob("mood_*.jpg"))
        
        if not mood_images:
            raise FileNotFoundError(f"ë¬´ë“œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        image_paths = []
        
        # âš ï¸ í‘œì§€ ì´ë¯¸ì§€ëŠ” ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ì €ì‘ê¶Œ ì—†ëŠ” ë¬´ë“œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        if cover_path.exists():
            print(f"âš ï¸ í‘œì§€ ì´ë¯¸ì§€ ë°œê²¬: {cover_path.name}")
            print("   â†’ ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬´ë“œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        for mood_img in mood_images:
            image_paths.append(str(mood_img))
            print(f"ğŸ¨ ë¬´ë“œ ì´ë¯¸ì§€ ì¶”ê°€: {mood_img.name}")
        
        if not image_paths:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        print(f"\nì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ ì‚¬ìš©")
        print()
        
        # 3. ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„±
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        image_clips = self.create_image_sequence(
            image_paths=image_paths,
            total_duration=audio_duration,
            fade_duration=2.0  # í˜ì´ë“œ ì‹œê°„ (2ì´ˆ)
        )
        print(f"   âœ… {len(image_clips)}ê°œì˜ í´ë¦½ ìƒì„± ì™„ë£Œ")
        print()
        
        # 4. í´ë¦½ ì—°ê²°
        print("ğŸ”— í´ë¦½ ì—°ê²° ì¤‘...")
        video = concatenate_videoclips(image_clips, method="compose")
        print("   âœ… ì—°ê²° ì™„ë£Œ")
        print()
        
        # 5. ì˜¤ë””ì˜¤ ì¶”ê°€
        print("ğŸµ ì˜¤ë””ì˜¤ ì¶”ê°€ ì¤‘...")
        try:
            # MoviePy 1.0+ ë²„ì „
            video = video.set_audio(audio)
        except AttributeError:
            # êµ¬ë²„ì „ í˜¸í™˜ì„±
            video = video.with_audio(audio)
        print("   âœ… ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
        print()
        
        # 6. ìë§‰ ì¶”ê°€ (ì„ íƒì‚¬í•­)
        subtitles = None
        if add_subtitles_flag:
            subtitles = self.generate_subtitles(audio_path, language)
            if subtitles:
                print("ğŸ“ ìë§‰ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì¤‘...")
                video = self.add_subtitles(video, subtitles)
                print("   âœ… ìë§‰ ì¶”ê°€ ì™„ë£Œ")
                print()
        
        # 7. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        # 8. ë Œë”ë§
        print("ğŸï¸ ì˜ìƒ ë Œë”ë§ ì¤‘...")
        print(f"   í•´ìƒë„: {self.resolution[0]}x{self.resolution[1]}")
        print(f"   í”„ë ˆì„ë ˆì´íŠ¸: {self.fps}fps")
        print(f"   ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
        print()
        
        video.write_videofile(
            output_path,
            fps=self.fps,
            codec='libx264',
            audio_codec='aac',
            bitrate='1500k',  # í˜ì´ë“œ íš¨ê³¼ë§Œ ìˆëŠ” ì •ì  ì´ë¯¸ì§€ì´ë¯€ë¡œ ë§¤ìš° ë‚®ì€ ë¹„íŠ¸ë ˆì´íŠ¸ë¡œ ì¶©ë¶„
            preset='medium'
        )
        
        print()
        print("=" * 60)
        print("âœ… ì˜ìƒ ì œì‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print()
        
        # ì •ë¦¬
        audio.close()
        video.close()
        
        return output_path


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì±… ë¦¬ë·° ì˜ìƒ ì œì‘')
    parser.add_argument('--audio', type=str, help='ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--book-title', type=str, help='ì±… ì œëª©')
    parser.add_argument('--image-dir', type=str, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', type=str, help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--subtitles', action='store_true', help='ìë§‰ ì¶”ê°€ (Whisper)')
    parser.add_argument('--language', type=str, default='ko', help='ìë§‰ ì–¸ì–´ (ê¸°ë³¸ê°’: ko)')
    parser.add_argument('--max-duration', type=float, help='ìµœëŒ€ ì˜ìƒ ê¸¸ì´ (ì´ˆ, í…ŒìŠ¤íŠ¸ìš©)')
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    if args.audio is None:
        # ìë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        audio_dir = Path("assets/audio")
        audio_files = list(audio_dir.glob("*.m4a")) + list(audio_dir.glob("*.wav")) + list(audio_dir.glob("*.mp3"))
        if audio_files:
            # í•œê¸€ ì˜¤ë””ì˜¤ ìš°ì„  ì„ íƒ (íŒŒì¼ëª…ì— í•œê¸€ì´ í¬í•¨ëœ ê²ƒ)
            korean_audio = [f for f in audio_files if any(ord(c) > 127 for c in f.stem)]
            if korean_audio:
                args.audio = str(korean_audio[0])
                print(f"ğŸ“ í•œê¸€ ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì„ íƒ: {args.audio}")
            else:
                args.audio = str(audio_files[0])
                print(f"ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì„ íƒ: {args.audio}")
        else:
            print("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    if args.book_title is None:
        # ì˜¤ë””ì˜¤ íŒŒì¼ëª…ì—ì„œ ì±… ì œëª© ì¶”ì¶œ
        audio_name = Path(args.audio).stem
        args.book_title = audio_name.replace("_review", "").replace("_Review", "")
        print(f"ğŸ“š ì±… ì œëª© ìë™ ì¶”ì¶œ: {args.book_title}")
    
    if args.image_dir is None:
        from utils.file_utils import safe_title
        safe_title_str = safe_title(args.book_title)
        args.image_dir = f"assets/images/{safe_title_str}"
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {args.image_dir}")
    
    if args.output is None:
        from utils.file_utils import safe_title
        safe_title_str = safe_title(args.book_title)
        args.output = f"output/{safe_title_str}_review.mp4"
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {args.output}")
    
    print()
    
    # ì˜ìƒ ì œì‘
    maker = VideoMaker(resolution=(1920, 1080), fps=30)
    maker.create_video(
        audio_path=args.audio,
        image_dir=args.image_dir,
        output_path=args.output,
        add_subtitles_flag=args.subtitles,
        language=args.language,
        max_duration=args.max_duration
    )


if __name__ == "__main__":
    main()

