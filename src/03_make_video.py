"""
Phase 4: ì˜ìƒ í•©ì„± ë° í¸ì§‘ ìŠ¤í¬ë¦½íŠ¸
- ì˜¤ë””ì˜¤ ë¡œë“œ
- ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„± (ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶°)
- Ken Burns íš¨ê³¼ (ì¤Œì¸/íŒ¨ë‹)
- ì „í™˜ íš¨ê³¼ (í˜ì´ë“œ)
- ìë§‰ (OpenAI Whisper, ì„ íƒì‚¬í•­)
- ë Œë”ë§: 1080p, 30fps MP4
"""

import os
import random
import math
from pathlib import Path
from typing import List, Optional, Tuple
from dotenv import load_dotenv

try:
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, TextClip, ColorClip, concatenate_videoclips, VideoFileClip
    from moviepy.video.fx.all import fadein, fadeout
    MOVIEPY_AVAILABLE = True
    MOVIEPY_VERSION_NEW = True
except ImportError as e:
    try:
        # êµ¬ë²„ì „ í˜¸í™˜ì„±
        from moviepy import ImageClip, AudioFileClip, CompositeVideoClip, TextClip, ColorClip, concatenate_videoclips, VideoFileClip
        from moviepy.video.fx import FadeIn, FadeOut, CrossFadeIn, CrossFadeOut
        MOVIEPY_AVAILABLE = True
        MOVIEPY_VERSION_NEW = False
    except ImportError:
        MOVIEPY_AVAILABLE = False
        MOVIEPY_VERSION_NEW = False
        print(f"âš ï¸ MoviePy import ì˜¤ë¥˜: {e}")
        print("pip install moviepy")

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

load_dotenv()


class VideoMaker:
    """ì˜ìƒ ì œì‘ í´ë˜ìŠ¤"""
    
    def __init__(self, resolution: Tuple[int, int] = (1920, 1080), fps: int = 30):
        """
        Args:
            resolution: í•´ìƒë„ (width, height)
            fps: í”„ë ˆì„ë ˆì´íŠ¸
        """
        self.resolution = resolution
        self.fps = fps
        
        if not MOVIEPY_AVAILABLE:
            raise ImportError("MoviePyê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install moviepy")
    
    def load_audio(self, audio_path: str) -> AudioFileClip:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ"""
        audio_file = Path(audio_path)
        if not audio_file.exists():
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘: {audio_path}")
        try:
            audio = AudioFileClip(audio_path)
            print(f"   ê¸¸ì´: {audio.duration:.2f}ì´ˆ")
        except Exception as e:
            raise ValueError(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return audio
    
    def concatenate_audios(
        self,
        audio_paths: List[str],
        output_path: str = None,
        fade_duration: float = 1.0,
        gap_duration: float = 3.0
    ) -> AudioFileClip:
        """
        ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—°ê²°
        
        Args:
            audio_paths: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            output_path: ì—°ê²°ëœ ì˜¤ë””ì˜¤ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            fade_duration: ì „í™˜ í˜ì´ë“œ ì‹œê°„ (ì´ˆ)
            gap_duration: ì˜¤ë””ì˜¤ ê°„ ê°„ê²© ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 3.0)
            
        Returns:
            ì—°ê²°ëœ ì˜¤ë””ì˜¤ í´ë¦½
        """
        if not audio_paths:
            raise ValueError("ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        print("ğŸ”— ì˜¤ë””ì˜¤ ì—°ê²° ì¤‘...")
        audio_clips = []
        
        for i, audio_path in enumerate(audio_paths):
            print(f"   [{i+1}/{len(audio_paths)}] ë¡œë“œ: {Path(audio_path).name}")
            audio_clip = self.load_audio(audio_path)
            
            # ì˜¤ë””ì˜¤ í´ë¦½ì— fade íš¨ê³¼ ì ìš© (ì˜¤ë””ì˜¤ ì „ìš© ë©”ì„œë“œ ì‚¬ìš©)
            if i > 0:
                # ì´ì „ í´ë¦½ì— fade out
                if audio_clips:
                    try:
                        from moviepy.audio.fx.all import audio_fadeout
                        audio_clips[-1] = audio_clips[-1].fx(audio_fadeout, fade_duration)
                    except ImportError:
                        # êµ¬ë²„ì „ í˜¸í™˜ì„± ë˜ëŠ” fade íš¨ê³¼ ì—†ì´ ì§„í–‰
                        pass
                
                # ì˜¤ë””ì˜¤ ê°„ ê°„ê²© ì¶”ê°€ (ì¡°ìš©í•œ êµ¬ê°„)
                if gap_duration > 0:
                    print(f"   â¸ï¸  {gap_duration}ì´ˆ ê°„ê²© ì¶”ê°€...")
                    try:
                        # ë¬´ìŒ ì˜¤ë””ì˜¤ í´ë¦½ ìƒì„±
                        from moviepy.audio.AudioClip import AudioArrayClip
                        import numpy as np
                        # ìƒ˜í”Œë ˆì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
                        sample_rate = audio_clip.fps if hasattr(audio_clip, 'fps') else 44100
                        # ë¬´ìŒ ë°°ì—´ ìƒì„± (ìŠ¤í…Œë ˆì˜¤)
                        silence_array = np.zeros((int(sample_rate * gap_duration), 2))
                        silence = AudioArrayClip(silence_array, fps=sample_rate)
                        audio_clips.append(silence)
                    except Exception as e:
                        # AudioArrayClip ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
                        try:
                            from moviepy.editor import ColorClip
                            # ê²€ì€ìƒ‰ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± (ë¬´ìŒ ì˜¤ë””ì˜¤ í¬í•¨)
                            silence_video = ColorClip(size=(1, 1), color=(0, 0, 0), duration=gap_duration)
                            # ë¬´ìŒ ì˜¤ë””ì˜¤ ì¶”ê°€
                            from moviepy.audio.AudioClip import AudioClip
                            silence_audio = AudioClip(lambda t: [0, 0], duration=gap_duration, fps=44100)
                            silence_video = silence_video.set_audio(silence_audio)
                            audio_clips.append(silence_video)
                        except Exception as e2:
                            # ê°„ê²© ì¶”ê°€ ì‹¤íŒ¨ ì‹œ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                            print(f"   âš ï¸ ê°„ê²© ì¶”ê°€ ì‹¤íŒ¨: {e2}, ê°„ê²© ì—†ì´ ì—°ê²°í•©ë‹ˆë‹¤.")
                
                # í˜„ì¬ í´ë¦½ì— fade in
                try:
                    from moviepy.audio.fx.all import audio_fadein
                    audio_clip = audio_clip.fx(audio_fadein, fade_duration)
                except ImportError:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„± ë˜ëŠ” fade íš¨ê³¼ ì—†ì´ ì§„í–‰
                    pass
            
            audio_clips.append(audio_clip)
        
        # ë§ˆì§€ë§‰ í´ë¦½ì— fade out
        if audio_clips:
            try:
                from moviepy.audio.fx.all import audio_fadeout
                audio_clips[-1] = audio_clips[-1].fx(audio_fadeout, fade_duration)
            except ImportError:
                pass
        
        # ì˜¤ë””ì˜¤ í´ë¦½ë“¤ì„ ì—°ê²°
        print("   ì—°ê²° ì¤‘...")
        try:
            from moviepy.audio.AudioClip import concatenate_audioclips
            final_audio = concatenate_audioclips(audio_clips)
        except ImportError:
            # êµ¬ë²„ì „ í˜¸í™˜ì„±: ë¹„ë””ì˜¤ í´ë¦½ìœ¼ë¡œ ë³€í™˜ í›„ ì—°ê²°
            from moviepy.editor import ColorClip
            video_clips = []
            for audio_clip in audio_clips:
                # ì˜¤ë””ì˜¤ ê¸¸ì´ë§Œí¼ì˜ ê²€ì€ìƒ‰ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±
                video_clip = ColorClip(size=(1, 1), color=(0, 0, 0), duration=audio_clip.duration)
                video_clip = video_clip.set_audio(audio_clip)
                video_clips.append(video_clip)
            concatenated = concatenate_videoclips(video_clips, method="compose")
            final_audio = concatenated.audio
        
        print(f"   âœ… ì—°ê²° ì™„ë£Œ: ì´ ê¸¸ì´ {final_audio.duration:.2f}ì´ˆ")
        
        # ì €ì¥ (ì„ íƒì‚¬í•­)
        if output_path:
            print(f"   ğŸ’¾ ì €ì¥ ì¤‘: {output_path}")
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            final_audio.write_audiofile(output_path, codec='aac', bitrate='192k')
            print(f"   âœ… ì €ì¥ ì™„ë£Œ")
        
        return final_audio
    
    def _ease_in_out(self, t: float) -> float:
        """
        ë¶€ë“œëŸ¬ìš´ easing í•¨ìˆ˜ (ease-in-out cubic)
        ì‹œì‘ê³¼ ëì—ì„œ ëŠë¦¬ê²Œ, ì¤‘ê°„ì—ì„œ ë¹ ë¥´ê²Œ
        """
        if t < 0.5:
            return 4 * t * t * t
        else:
            return 1 - pow(-2 * t + 2, 3) / 2
    
    def create_image_clip_with_ken_burns(
        self,
        image_path: str,
        duration: float,
        effect_type: str = "zoom_in",
        start_scale: float = 1.0,
        end_scale: float = 1.2,
        pan_direction: Optional[str] = None
    ) -> ImageClip:
        """
        Ken Burns íš¨ê³¼ê°€ ì ìš©ëœ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± (ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜)
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            duration: í´ë¦½ ê¸¸ì´ (ì´ˆ)
            effect_type: íš¨ê³¼ íƒ€ì… ("zoom_in", "zoom_out")
            start_scale: ì‹œì‘ ìŠ¤ì¼€ì¼
            end_scale: ë ìŠ¤ì¼€ì¼
            pan_direction: íŒ¨ë‹ ë°©í–¥ ("left", "right", "up", "down")
        """
        from PIL import Image
        import numpy as np
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ (í•´ìƒë„ë³´ë‹¤ í¬ê²Œ)
        img = Image.open(image_path)
        img_width, img_height = img.size
        
        # í•´ìƒë„ ë¹„ìœ¨ ê³„ì‚°
        target_width, target_height = self.resolution
        aspect_ratio = target_width / target_height
        img_aspect = img_width / img_height
        
        # ì´ë¯¸ì§€ë¥¼ í•´ìƒë„ë³´ë‹¤ í¬ê²Œ ë¦¬ì‚¬ì´ì¦ˆ (ì¤Œ íš¨ê³¼ë¥¼ ìœ„í•´)
        # ìµœëŒ€ ìŠ¤ì¼€ì¼ë³´ë‹¤ ë” í¬ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ íŒ¨ë‹ ì—¬ìœ  ê³µê°„ í™•ë³´
        max_scale = max(end_scale, start_scale) * 1.2  # 20% ì—¬ìœ 
        scaled_width = int(target_width * max_scale)
        scaled_height = int(target_height * max_scale)
        
        # ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
        if img_aspect > aspect_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ
            scaled_height = int(scaled_width / img_aspect)
        else:
            # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ
            scaled_width = int(scaled_height * img_aspect)
        
        # ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
        img = img.resize((scaled_width, scaled_height), Image.Resampling.LANCZOS)
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (í•œ ë²ˆë§Œ)
        img_array = np.array(img)
        
        # Ken Burns íš¨ê³¼ ì ìš© (ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜)
        def make_frame(t):
            # ì§„í–‰ë¥  ê³„ì‚° (0.0 ~ 1.0)
            progress = t / duration if duration > 0 else 0
            progress = min(1.0, max(0.0, progress))
            
            # Easing ì ìš© (ë¶€ë“œëŸ¬ìš´ ì „í™˜)
            eased_progress = self._ease_in_out(progress)
            
            # ìŠ¤ì¼€ì¼ ê³„ì‚° (easing ì ìš©)
            if effect_type == "zoom_out":
                current_scale = start_scale + (end_scale - start_scale) * (1 - eased_progress)
            else:  # zoom_in or default
                current_scale = start_scale + (end_scale - start_scale) * eased_progress
            
            # íŒ¨ë‹ ê³„ì‚° (easing ì ìš©)
            pan_x = 0
            pan_y = 0
            if pan_direction:
                # íŒ¨ë‹ë„ easing ì ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ
                pan_amount = 0.15 * eased_progress  # ìµœëŒ€ 15% ì´ë™
                if pan_direction == "left":
                    pan_x = -pan_amount
                elif pan_direction == "right":
                    pan_x = pan_amount
                elif pan_direction == "up":
                    pan_y = -pan_amount
                elif pan_direction == "down":
                    pan_y = pan_amount
            
            # í˜„ì¬ í”„ë ˆì„ í¬ê¸° ê³„ì‚°
            current_width = int(target_width / current_scale)
            current_height = int(target_height / current_scale)
            
            # ì¤‘ì‹¬ì  ê³„ì‚° (ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            center_x = scaled_width // 2
            center_y = scaled_height // 2
            
            # íŒ¨ë‹ ì ìš© (ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€)
            center_x += int(pan_x * scaled_width)
            center_y += int(pan_y * scaled_height)
            
            # í¬ë¡­ ì˜ì—­ ê³„ì‚° (ê²½ê³„ ì²´í¬ ê°•í™”)
            left = max(0, center_x - current_width // 2)
            top = max(0, center_y - current_height // 2)
            right = min(scaled_width, left + current_width)
            bottom = min(scaled_height, top + current_height)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if right <= left or bottom <= top:
                # ì˜ëª»ëœ í¬ë¡­ ì˜ì—­ì´ë©´ ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                from PIL import Image as PILImage
                resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                return np.array(resized)
            
            # í¬ë¡­ (numpy ë°°ì—´ ìŠ¬ë¼ì´ì‹± ì‚¬ìš© - ë” ë¹ ë¦„)
            try:
                cropped = img_array[top:bottom, left:right]
                
                # ë¹ˆ ë°°ì—´ ì²´í¬
                if cropped.size == 0:
                    from PIL import Image as PILImage
                    resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                    return np.array(resized)
                
                # ë¦¬ì‚¬ì´ì¦ˆ (ê³ í’ˆì§ˆ)
                from PIL import Image as PILImage
                cropped_img = PILImage.fromarray(cropped)
                resized = cropped_img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                
                return np.array(resized)
            except (IndexError, ValueError) as e:
                # í¬ë¡­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                from PIL import Image as PILImage
                resized = PILImage.fromarray(img_array).resize((target_width, target_height), Image.Resampling.LANCZOS)
                return np.array(resized)
        
        # make_frame í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦½ ìƒì„±
        try:
            # fl ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ë³„ë¡œ íš¨ê³¼ ì ìš©
            clip = ImageClip(img_array, duration=duration)
            clip = clip.fl(lambda get_frame, t: make_frame(t), apply_to=['video'])
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜ (íš¨ê³¼ ì—†ì´)
            print(f"   âš ï¸ Ken Burns íš¨ê³¼ ì ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë¦½ ì‚¬ìš©: {e}")
            clip = ImageClip(img_array, duration=duration)
            clip = clip.resized(newsize=self.resolution)
        
        return clip
    
    def create_image_sequence(
        self,
        image_paths: List[str],
        total_duration: float,
        fade_duration: float = 1.5  # í˜ì´ë“œ ì „í™˜ ì‹œê°„ (1.5ì´ˆ - ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜)
    ) -> List[ImageClip]:
        """
        ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„± (ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ë°˜ë³µ)
        - ì´ë¯¸ì§€ 20ê°œë¥¼ ì˜ìƒì´ ëë‚  ë•Œê¹Œì§€ ê³„ì† ë°˜ë³µ
        - ìì—°ìŠ¤ëŸ¬ìš´ fade out/in ì „í™˜ íš¨ê³¼ ì ìš©
        
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (20ê°œ)
            total_duration: ì „ì²´ ê¸¸ì´ (ì˜¤ë””ì˜¤ ê¸¸ì´)
            fade_duration: í˜ì´ë“œ ì „í™˜ ì‹œê°„ (ê¸°ë³¸ê°’: 1.5ì´ˆ - ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜)
        """
        if not image_paths:
            raise ValueError("ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        num_images = len(image_paths)
        
        # ì´ë¯¸ì§€ë‹¹ ìµœì  í‘œì‹œ ì‹œê°„ ê³„ì‚°
        # ì‹œì²­ì ê´€ì ì—ì„œ ìµœì : 4-5ì´ˆ
        optimal_duration_per_image = 4.5  # ìµœì  í‘œì‹œ ì‹œê°„: 4.5ì´ˆ
        min_duration_per_image = 4.0  # ìµœì†Œ í‘œì‹œ ì‹œê°„: 4ì´ˆ
        max_duration_per_image = 6.0  # ìµœëŒ€ í‘œì‹œ ì‹œê°„: 6ì´ˆ
        
        # ì „ì²´ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ì´ë¯¸ì§€ë‹¹ í‘œì‹œ ì‹œê°„ ê³„ì‚°
        calculated_duration = total_duration / num_images
        
        # ìµœì  ë²”ìœ„ ë‚´ë¡œ ì¡°ì •
        if calculated_duration < min_duration_per_image:
            duration_per_image = min_duration_per_image
        elif calculated_duration > max_duration_per_image:
            duration_per_image = max_duration_per_image
        else:
            duration_per_image = calculated_duration
        
        # í˜ì´ë“œ ì „í™˜ ì‹œê°„ ì¡°ì • (ì´ë¯¸ì§€ í‘œì‹œ ì‹œê°„ì˜ 30% ì´í•˜ë¡œ ì œí•œ)
        fade_duration = min(fade_duration, duration_per_image * 0.3)
        
        # ì˜ìƒ ê¸¸ì´ì™€ ìƒê´€ì—†ì´ 100ê°œ ì´ë¯¸ì§€ë¥¼ ë²ˆê°ˆì•„ê°€ë©´ì„œ ì‚¬ìš©
        # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ 100ê°œë¡œ ì œí•œ (ë” ë§ìœ¼ë©´ ì•ì—ì„œ 100ê°œë§Œ ì‚¬ìš©)
        max_images = 100
        if len(image_paths) > max_images:
            image_paths = image_paths[:max_images]
            print(f"   âš ï¸ ì´ë¯¸ì§€ê°€ {len(image_paths)}ê°œ ì´ìƒì…ë‹ˆë‹¤. ì•ì—ì„œ {max_images}ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ì˜ìƒì´ ëë‚  ë•Œê¹Œì§€ í•„ìš”í•œ ì´ë¯¸ì§€ ê°œìˆ˜ ê³„ì‚°
        num_needed = math.ceil(total_duration / duration_per_image)
        num_cycles = math.ceil(num_needed / len(image_paths))
        
        print(f"   ğŸ“Š ì‚¬ìš©í•  ì´ë¯¸ì§€ ê°œìˆ˜: {len(image_paths)}ê°œ (ìµœëŒ€ 100ê°œ)")
        print(f"   ğŸ“Š í•„ìš”í•œ ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {num_needed}ê°œ")
        print(f"   â±ï¸  ì´ë¯¸ì§€ë‹¹ í‘œì‹œ ì‹œê°„: {duration_per_image:.1f}ì´ˆ")
        print(f"   ğŸ¨ í˜ì´ë“œ ì „í™˜ ì‹œê°„: {fade_duration:.1f}ì´ˆ (fade out/in)")
        print(f"   ğŸ”„ ë°˜ë³µ íšŸìˆ˜: {num_cycles}íšŒ (100ê°œ ì´ë¯¸ì§€ë¥¼ ìˆœí™˜ ì‚¬ìš©)")
        print(f"   ğŸ’¡ ì‹œì²­ì ê´€ì  ê¶Œì¥: ì´ë¯¸ì§€ë‹¹ 4-5ì´ˆê°€ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•©ë‹ˆë‹¤")
        
        clips = []
        current_time = 0.0
        image_index = 0  # ì´ë¯¸ì§€ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘í•˜ì—¬ ìˆœí™˜)
        
        # ì˜ìƒì´ ëë‚  ë•Œê¹Œì§€ 100ê°œ ì´ë¯¸ì§€ë¥¼ ìˆœí™˜í•˜ë©´ì„œ ì‚¬ìš©
        while current_time < total_duration:
            # í˜„ì¬ ì‚¬ìš©í•  ì´ë¯¸ì§€ (ìˆœí™˜)
            image_path = image_paths[image_index % len(image_paths)]
            if current_time >= total_duration:
                break
            
            # í´ë¦½ ê¸¸ì´ ê³„ì‚° (ë§ˆì§€ë§‰ í´ë¦½ì€ ë‚¨ì€ ì‹œê°„ë§Œí¼ë§Œ)
            remaining_time = total_duration - current_time
            clip_duration = min(duration_per_image, remaining_time)
            
            if clip_duration <= 0:
                break
            
            # ì •ì  ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (ì¤Œì¸ íš¨ê³¼ ì—†ìŒ)
            clip = ImageClip(image_path, duration=clip_duration)
            # MoviePy ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¸ ë©”ì„œë“œ ì‚¬ìš©
            try:
                # MoviePy 1.0+ ë²„ì „
                clip = clip.resized(height=self.resolution[1])
            except (TypeError, AttributeError):
                try:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„±
                    clip = clip.resize(height=self.resolution[1])
                except:
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: PILë¡œ ì§ì ‘ ë¦¬ì‚¬ì´ì¦ˆ
                    from PIL import Image as PILImage
                    img = PILImage.open(image_path)
                    img = img.resize(self.resolution, PILImage.Resampling.LANCZOS)
                    clip = ImageClip(img, duration=clip_duration)
            
            # fade out/in ì „í™˜ íš¨ê³¼ ì ìš©
            # ëª¨ë“  ì´ë¯¸ì§€ì— fade outê³¼ fade inì„ ëª¨ë‘ ì ìš©í•˜ì—¬ í¬ë¡œìŠ¤í˜ì´ë“œ íš¨ê³¼
            if MOVIEPY_AVAILABLE:
                if MOVIEPY_VERSION_NEW:
                    # MoviePy 1.0+ ë²„ì „
                    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ê°€ ì•„ë‹ˆë©´ fade in ì ìš©
                    # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ê°€ ì•„ë‹ˆë©´ fade out ì ìš©
                    # (ë°˜ë³µì´ë¯€ë¡œ ëª¨ë“  ì´ë¯¸ì§€ì— ì–‘ìª½ ëª¨ë‘ ì ìš©)
                    
                    # fade in: ì´ì „ ì´ë¯¸ì§€ì—ì„œ ì „í™˜ë  ë•Œ (ì²« ë²ˆì§¸ê°€ ì•„ë‹ˆë©´)
                    # fade out: ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ì „í™˜ë  ë•Œ (ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´)
                    is_first = (current_time == 0.0)
                    is_last = (current_time + clip_duration >= total_duration)
                    
                    if not is_first:
                        # fade in ì ìš©
                        clip = clip.fx(fadein, fade_duration)
                    if not is_last:
                        # fade out ì ìš©
                        clip = clip.fx(fadeout, fade_duration)
                else:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„±
                    try:
                        if current_time > 0:
                            clip = clip.with_effects([FadeIn(fade_duration)])
                        if (current_time + clip_duration) < total_duration:
                            clip = clip.with_effects([FadeOut(fade_duration)])
                    except:
                        # í˜ì´ë“œ íš¨ê³¼ ì—†ì´ ì§„í–‰
                        pass
            
            clips.append(clip)
            current_time += clip_duration
            image_index += 1  # ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ì´ë™ (ìˆœí™˜)
        
        print(f"   âœ… ì´ {len(clips)}ê°œì˜ í´ë¦½ ìƒì„± ì™„ë£Œ")
        return clips
    
    def generate_subtitles(self, audio_path: str, language: str = "ko") -> Optional[List[dict]]:
        """
        OpenAI Whisperë¡œ ìë§‰ ìƒì„±
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ ("ko", "en" ë“±)
            
        Returns:
            ìë§‰ ë¦¬ìŠ¤íŠ¸ [{"start": float, "end": float, "text": str}, ...]
        """
        if not WHISPER_AVAILABLE:
            print("âš ï¸ Whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë§‰ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        print("ğŸ“ ìë§‰ ìƒì„± ì¤‘ (Whisper)...")
        try:
            model = whisper.load_model("base")
            result = model.transcribe(audio_path, language=language)
            
            subtitles = []
            for segment in result.get("segments", []):
                subtitles.append({
                    "start": segment["start"],
                    "end": segment["end"],
                    "text": segment["text"].strip()
                })
            
            print(f"   âœ… {len(subtitles)}ê°œì˜ ìë§‰ ìƒì„± ì™„ë£Œ")
            return subtitles
            
        except Exception as e:
            print(f"   âŒ ìë§‰ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def add_subtitles(
        self,
        video_clip: CompositeVideoClip,
        subtitles: List[dict],
        font_size: int = 60,
        font_color: str = "white",
        stroke_color: str = "black",
        stroke_width: int = 2
    ) -> CompositeVideoClip:
        """
        ìë§‰ ì˜¤ë²„ë ˆì´ ì¶”ê°€
        
        Args:
            video_clip: ë¹„ë””ì˜¤ í´ë¦½
            subtitles: ìë§‰ ë¦¬ìŠ¤íŠ¸
            font_size: í°íŠ¸ í¬ê¸°
            font_color: í°íŠ¸ ìƒ‰ìƒ
            stroke_color: í…Œë‘ë¦¬ ìƒ‰ìƒ
            stroke_width: í…Œë‘ë¦¬ ë‘ê»˜
        """
        if not subtitles:
            return video_clip
        
        subtitle_clips = []
        
        for subtitle in subtitles:
            try:
                text_clip = TextClip(
                    subtitle["text"],
                    fontsize=font_size,
                    color=font_color,
                    stroke_color=stroke_color,
                    stroke_width=stroke_width,
                    method='caption',
                    size=(self.resolution[0] - 100, None),
                    align='center'
                ).with_duration(subtitle["end"] - subtitle["start"]).with_start(subtitle["start"]).with_position(('center', self.resolution[1] - 150))
                
                subtitle_clips.append(text_clip)
            except Exception as e:
                print(f"   âš ï¸ ìë§‰ ìƒì„± ì˜¤ë¥˜: {e}")
                continue
        
        if subtitle_clips:
            return CompositeVideoClip([video_clip] + subtitle_clips)
        
        return video_clip
    
    def create_video(
        self,
        audio_path: str,
        image_dir: str,
        output_path: str,
        add_subtitles_flag: bool = False,
        language: str = "ko",
        max_duration: Optional[float] = None,
        summary_audio_path: Optional[str] = None,
        notebooklm_video_path: Optional[str] = None,
        summary_audio_volume: float = 1.2
    ) -> str:
        """
        ìµœì¢… ì˜ìƒ ìƒì„± (Summary â†’ NotebookLM Video â†’ Audio ìˆœì„œ)
        
        Args:
            audio_path: ë¦¬ë·° ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            add_subtitles_flag: ìë§‰ ì¶”ê°€ ì—¬ë¶€
            language: ìë§‰ ì–¸ì–´
            max_duration: ìµœëŒ€ ê¸¸ì´ ì œí•œ
            summary_audio_path: ìš”ì•½ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ìˆìœ¼ë©´ Summary ë¶€ë¶„ ìƒì„±)
            notebooklm_video_path: NotebookLM ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ìˆìœ¼ë©´ ì¤‘ê°„ì— ì‚½ì…)
            summary_audio_volume: Summary ì˜¤ë””ì˜¤ ìŒëŸ‰ ë°°ìœ¨ (ê¸°ë³¸ê°’: 1.2, 20% ì¦ê°€)
        """
        print("=" * 60)
        print("ğŸ¬ ì˜ìƒ ì œì‘ ì‹œì‘")
        print("=" * 60)
        print()
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
        image_dir_path = Path(image_dir)
        if not image_dir_path.exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        cover_path = image_dir_path / "cover.jpg"
        mood_images = sorted(image_dir_path.glob("mood_*.jpg"))
        
        if not mood_images:
            raise FileNotFoundError(f"ë¬´ë“œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        image_paths = []
        
        # âš ï¸ í‘œì§€ ì´ë¯¸ì§€ëŠ” ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        if cover_path.exists():
            print(f"âš ï¸ í‘œì§€ ì´ë¯¸ì§€ ë°œê²¬: {cover_path.name}")
            print("   â†’ ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬´ë“œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        for mood_img in mood_images:
            image_paths.append(str(mood_img))
        
        if not image_paths:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        
        print(f"ğŸ¨ ë¬´ë“œ ì´ë¯¸ì§€: {len(image_paths)}ê°œ")
        print()
        
        video_clips = []
        
        # 1. Summary ë¶€ë¶„: ìš”ì•½ ì˜¤ë””ì˜¤ + ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë“œì‡¼
        if summary_audio_path and Path(summary_audio_path).exists():
            print("ğŸ“š 1ë‹¨ê³„: Summary ë¶€ë¶„ ì˜ìƒ ìƒì„±")
            print("-" * 60)
            summary_audio = self.load_audio(summary_audio_path)
            summary_duration = summary_audio.duration
            
            # Summary ì˜¤ë””ì˜¤ ìŒëŸ‰ ì¡°ì •
            if summary_audio_volume != 1.0:
                print(f"   ğŸ”Š Summary ì˜¤ë””ì˜¤ ìŒëŸ‰ ì¡°ì •: {summary_audio_volume}x")
                try:
                    from moviepy.audio.fx.all import volumex
                    summary_audio = summary_audio.fx(volumex, summary_audio_volume)
                except ImportError:
                    try:
                        # êµ¬ë²„ì „ í˜¸í™˜ì„±
                        summary_audio = summary_audio.volumex(summary_audio_volume)
                    except AttributeError:
                        print("   âš ï¸ ìŒëŸ‰ ì¡°ì • ì‹¤íŒ¨, ì›ë³¸ ìŒëŸ‰ ì‚¬ìš©")
            
            print(f"   ìš”ì•½ ì˜¤ë””ì˜¤ ê¸¸ì´: {summary_duration:.2f}ì´ˆ")
            
            # Summary ë¶€ë¶„ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„±
            summary_image_clips = self.create_image_sequence(
                image_paths=image_paths,
                total_duration=summary_duration,
                fade_duration=1.5
            )
            summary_video = concatenate_videoclips(summary_image_clips, method="compose")
            summary_video = summary_video.set_audio(summary_audio)
            
            video_clips.append(summary_video)
            print(f"   âœ… Summary ë¶€ë¶„ ì™„ë£Œ ({summary_duration:.2f}ì´ˆ)")
            print()
        else:
            print("ğŸ“š Summary ë¶€ë¶„: ìš”ì•½ ì˜¤ë””ì˜¤ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            print()
        
        # 2. NotebookLM Video ë¶€ë¶„
        if notebooklm_video_path and Path(notebooklm_video_path).exists():
            print("ğŸ¥ 2ë‹¨ê³„: NotebookLM Video ë¶€ë¶„")
            print("-" * 60)
            print(f"   ë¹„ë””ì˜¤ ë¡œë“œ ì¤‘: {Path(notebooklm_video_path).name}")
            
            notebooklm_video = VideoFileClip(notebooklm_video_path)
            
            # í•´ìƒë„ ë° í”„ë ˆì„ë ˆì´íŠ¸ í†µì¼
            if notebooklm_video.size != self.resolution:
                print(f"   ğŸ”„ ë¦¬ì‚¬ì´ì¦ˆ ì¤‘: {notebooklm_video.size} -> {self.resolution}")
                notebooklm_video = notebooklm_video.resize(self.resolution)
            
            if notebooklm_video.fps != self.fps:
                print(f"   ğŸ”„ í”„ë ˆì„ë ˆì´íŠ¸ ì¡°ì • ì¤‘: {notebooklm_video.fps}fps -> {self.fps}fps")
                notebooklm_video = notebooklm_video.set_fps(self.fps)
            
            video_clips.append(notebooklm_video)
            print(f"   âœ… NotebookLM Video ë¶€ë¶„ ì™„ë£Œ ({notebooklm_video.duration:.2f}ì´ˆ)")
            print()
        else:
            print("ğŸ¥ NotebookLM Video ë¶€ë¶„: ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            print()
        
        # 3. Audio ë¶€ë¶„: ë¦¬ë·° ì˜¤ë””ì˜¤ + ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë“œì‡¼
        print("ğŸµ 3ë‹¨ê³„: Audio ë¶€ë¶„ ì˜ìƒ ìƒì„±")
        print("-" * 60)
        review_audio = self.load_audio(audio_path)
        review_duration = review_audio.duration
        
        # í…ŒìŠ¤íŠ¸ìš©: ìµœëŒ€ ê¸¸ì´ ì œí•œ
        if max_duration and review_duration > max_duration:
            print(f"   âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ì œí•œ: {review_duration:.2f}ì´ˆ â†’ {max_duration}ì´ˆ")
            review_audio = review_audio.subclip(0, max_duration)
            review_duration = max_duration
        
        print(f"   ë¦¬ë·° ì˜¤ë””ì˜¤ ê¸¸ì´: {review_duration:.2f}ì´ˆ")
        
        # Audio ë¶€ë¶„ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ìƒì„±
        review_image_clips = self.create_image_sequence(
            image_paths=image_paths,
            total_duration=review_duration,
            fade_duration=1.5
        )
        review_video = concatenate_videoclips(review_image_clips, method="compose")
        review_video = review_video.set_audio(review_audio)
        
        video_clips.append(review_video)
        print(f"   âœ… Audio ë¶€ë¶„ ì™„ë£Œ ({review_duration:.2f}ì´ˆ)")
        print()
        
        # 4. ì„¸ ë¶€ë¶„ ì—°ê²° (ê° ì„¹ì…˜ ì‚¬ì´ì— 3ì´ˆ silence ì¶”ê°€)
        if not video_clips:
            raise ValueError("ìƒì„±í•  ì˜ìƒ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # 3ì´ˆ silence í´ë¦½ ìƒì„± í•¨ìˆ˜
        def create_silence_clip(duration: float = 3.0):
            """3ì´ˆ ê²€ì€ìƒ‰ ë¬´ìŒ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±"""
            silence_video = ColorClip(size=self.resolution, color=(0, 0, 0), duration=duration)
            # ë¬´ìŒ ì˜¤ë””ì˜¤ ì¶”ê°€
            try:
                from moviepy.audio.AudioClip import AudioArrayClip
                import numpy as np
                sample_rate = 44100
                silence_array = np.zeros((int(sample_rate * duration), 2))
                silence_audio = AudioArrayClip(silence_array, fps=sample_rate)
                silence_video = silence_video.set_audio(silence_audio)
            except Exception as e:
                # ì˜¤ë””ì˜¤ ì¶”ê°€ ì‹¤íŒ¨ ì‹œ ë¹„ë””ì˜¤ë§Œ ë°˜í™˜
                pass
            return silence_video
        
        # ì„¹ì…˜ ì‚¬ì´ì— 3ì´ˆ silence ì¶”ê°€
        final_clips = []
        silence_duration = 3.0
        
        for i, clip in enumerate(video_clips):
            final_clips.append(clip)
            
            # ë§ˆì§€ë§‰ í´ë¦½ì´ ì•„ë‹ˆë©´ 3ì´ˆ silence ì¶”ê°€
            if i < len(video_clips) - 1:
                print(f"   â¸ï¸  {silence_duration}ì´ˆ silence ì¶”ê°€...")
                silence_clip = create_silence_clip(silence_duration)
                final_clips.append(silence_clip)
        
        print("ğŸ”— ì „ì²´ ì˜ìƒ ì—°ê²° ì¤‘...")
        print(f"   ì´ {len(final_clips)}ê°œ í´ë¦½ ì—°ê²° (ì„¹ì…˜ {len(video_clips)}ê°œ + silence {len(final_clips) - len(video_clips)}ê°œ)")
        for i, clip in enumerate(final_clips, 1):
            if i <= len(video_clips):
                print(f"      [{i}] {clip.duration:.2f}ì´ˆ")
            else:
                print(f"      [{i}] {clip.duration:.2f}ì´ˆ (silence)")
        
        # í˜ì´ë“œ íš¨ê³¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
        final_video = concatenate_videoclips(final_clips, method="compose")
        total_duration = final_video.duration
        print(f"   âœ… ì—°ê²° ì™„ë£Œ: ì´ ê¸¸ì´ {total_duration:.2f}ì´ˆ ({total_duration/60:.2f}ë¶„)")
        print()
        
        # 5. ìë§‰ ì¶”ê°€ (ì„ íƒì‚¬í•­)
        if add_subtitles_flag:
            print("ğŸ“ ìë§‰ ìƒì„± ì¤‘...")
            subtitles = self.generate_subtitles(audio_path, language)
            if subtitles:
                print("ğŸ“ ìë§‰ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì¤‘...")
                final_video = self.add_subtitles(final_video, subtitles)
                print("   âœ… ìë§‰ ì¶”ê°€ ì™„ë£Œ")
                print()
        
        # 6. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        # 7. ë Œë”ë§
        print("ğŸï¸ ì˜ìƒ ë Œë”ë§ ì¤‘...")
        print(f"   í•´ìƒë„: {self.resolution[0]}x{self.resolution[1]}")
        print(f"   í”„ë ˆì„ë ˆì´íŠ¸: {self.fps}fps")
        print(f"   ì´ ê¸¸ì´: {total_duration:.2f}ì´ˆ ({total_duration/60:.2f}ë¶„)")
        print()
        
        final_video.write_videofile(
            output_path,
            fps=self.fps,
            codec='libx264',
            audio_codec='aac',
            bitrate='1500k',
            preset='medium'
        )
        
        print()
        print("=" * 60)
        print("âœ… ì˜ìƒ ì œì‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print()
        
        # ì •ë¦¬
        review_audio.close()
        final_video.close()
        if summary_audio_path and Path(summary_audio_path).exists():
            summary_audio.close()
        if notebooklm_video_path and Path(notebooklm_video_path).exists():
            notebooklm_video.close()
        
        return output_path


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì±… ë¦¬ë·° ì˜ìƒ ì œì‘')
    parser.add_argument('--audio', type=str, help='ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--summary-audio', type=str, help='ìš”ì•½ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)')
    parser.add_argument('--book-title', type=str, help='ì±… ì œëª©')
    parser.add_argument('--image-dir', type=str, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', type=str, help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--subtitles', action='store_true', help='ìë§‰ ì¶”ê°€ (Whisper)')
    parser.add_argument('--language', type=str, default='ko', help='ìë§‰ ì–¸ì–´ (ê¸°ë³¸ê°’: ko)')
    parser.add_argument('--max-duration', type=float, help='ìµœëŒ€ ì˜ìƒ ê¸¸ì´ (ì´ˆ, í…ŒìŠ¤íŠ¸ìš©)')
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    if args.audio is None:
        # ìë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        audio_dir = Path("assets/audio")
        audio_files = list(audio_dir.glob("*.m4a")) + list(audio_dir.glob("*.wav")) + list(audio_dir.glob("*.mp3"))
        if audio_files:
            # í•œê¸€ ì˜¤ë””ì˜¤ ìš°ì„  ì„ íƒ (íŒŒì¼ëª…ì— í•œê¸€ì´ í¬í•¨ëœ ê²ƒ)
            korean_audio = [f for f in audio_files if any(ord(c) > 127 for c in f.stem)]
            if korean_audio:
                args.audio = str(korean_audio[0])
                print(f"ğŸ“ í•œê¸€ ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì„ íƒ: {args.audio}")
            else:
                args.audio = str(audio_files[0])
                print(f"ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì„ íƒ: {args.audio}")
        else:
            print("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    if args.book_title is None:
        # ì˜¤ë””ì˜¤ íŒŒì¼ëª…ì—ì„œ ì±… ì œëª© ì¶”ì¶œ
        audio_name = Path(args.audio).stem
        args.book_title = audio_name.replace("_review", "").replace("_Review", "")
        print(f"ğŸ“š ì±… ì œëª© ìë™ ì¶”ì¶œ: {args.book_title}")
    
    if args.image_dir is None:
        from utils.file_utils import safe_title
        safe_title_str = safe_title(args.book_title)
        args.image_dir = f"assets/images/{safe_title_str}"
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {args.image_dir}")
    
    if args.output is None:
        from utils.file_utils import safe_title
        safe_title_str = safe_title(args.book_title)
        args.output = f"output/{safe_title_str}_review.mp4"
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {args.output}")
    
    print()
    
    # ì˜ìƒ ì œì‘
    maker = VideoMaker(resolution=(1920, 1080), fps=30)
    maker.create_video(
        audio_path=args.audio,
        image_dir=args.image_dir,
        output_path=args.output,
        add_subtitles_flag=args.subtitles,
        language=args.language,
        max_duration=args.max_duration,
        summary_audio_path=args.summary_audio
    )


if __name__ == "__main__":
    main()

