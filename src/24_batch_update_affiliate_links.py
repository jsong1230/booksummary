#!/usr/bin/env python3
"""
ê¸°ì¡´ YouTube ì˜ìƒì— ì œíœ´ ë§í¬ ì¼ê´„ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì±„ë„ì˜ ëª¨ë“  ì˜ìƒì„ ê°€ì ¸ì™€ì„œ descriptionì— ì œíœ´ ë§í¬ê°€ ì—†ëŠ” ê²½ìš° ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
ì•ˆì „ì¥ì¹˜ë¡œ --dry-runì´ ê¸°ë³¸ì´ë©°, --apply í”Œë˜ê·¸ë¥¼ ëª…ì‹œí•´ì•¼ ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
"""

import os
import sys
import json
import time
import argparse
import re
from pathlib import Path
from typing import Optional, Dict, List
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from google.oauth2.credentials import Credentials
    from google.auth.transport.requests import Request
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    GOOGLE_API_AVAILABLE = True
except ImportError:
    GOOGLE_API_AVAILABLE = False
    print("âŒ google-api-python-clientê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   pip install google-api-python-client google-auth-oauthlib google-auth-httplib2")
    sys.exit(1)

from src.utils.affiliate_links import generate_affiliate_section
from src.utils.translations import translate_book_title, translate_author_name, is_english_title

load_dotenv()

# YouTube API ìŠ¤ì½”í”„ (ì˜ìƒ ë©”íƒ€ë°ì´í„° ìˆ˜ì • ê¶Œí•œ í•„ìš”)
SCOPES = ['https://www.googleapis.com/auth/youtube']

# ì œíœ´ ë§í¬ ë§ˆì»¤ (descriptionì— ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ìš©)
AFFILIATE_MARKERS = [
    "ğŸ“– ì´ ì±… êµ¬ë§¤í•˜ê¸°:",
    "ğŸ“– Get this book:"
]


class AffiliateLinksUpdater:
    """YouTube ì˜ìƒì— ì œíœ´ ë§í¬ë¥¼ ì¼ê´„ ì—…ë°ì´íŠ¸í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, dry_run: bool = True, delay: float = 1.0):
        """
        Args:
            dry_run: Trueë©´ ë¯¸ë¦¬ë³´ê¸°ë§Œ, Falseë©´ ì‹¤ì œ ì—…ë°ì´íŠ¸
            delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        """
        if not GOOGLE_API_AVAILABLE:
            raise ImportError("google-api-python-clientê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.dry_run = dry_run
        self.delay = delay
        self.youtube = None
        self.channel_id = os.getenv("YOUTUBE_CHANNEL_ID")

        if not self.channel_id:
            raise ValueError("YOUTUBE_CHANNEL_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self._authenticate()

    def _authenticate(self):
        """OAuth2 ì¸ì¦"""
        client_id = os.getenv("YOUTUBE_CLIENT_ID")
        client_secret = os.getenv("YOUTUBE_CLIENT_SECRET")
        refresh_token = os.getenv("YOUTUBE_REFRESH_TOKEN")

        if not all([client_id, client_secret, refresh_token]):
            raise ValueError("YouTube API ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            credentials = Credentials(
                token=None,
                refresh_token=refresh_token,
                token_uri="https://oauth2.googleapis.com/token",
                client_id=client_id,
                client_secret=client_secret,
                scopes=SCOPES
            )

            credentials.refresh(Request())
            self.youtube = build('youtube', 'v3', credentials=credentials)
            print("âœ… YouTube API ì¸ì¦ ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
            raise

    def get_channel_videos(self, max_results: Optional[int] = None) -> List[Dict]:
        """
        ì±„ë„ì˜ ëª¨ë“  ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

        Args:
            max_results: ìµœëŒ€ ì˜ìƒ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)

        Returns:
            ì˜ìƒ ì •ë³´ ëª©ë¡ [{"video_id": "...", "title": "..."}, ...]
        """
        print(f"\nğŸ“‹ ì±„ë„ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘... (ì±„ë„ ID: {self.channel_id})")

        videos = []

        try:
            # 1. ì±„ë„ì˜ uploads ì¬ìƒëª©ë¡ ID ê°€ì ¸ì˜¤ê¸°
            channel_response = self.youtube.channels().list(
                part='contentDetails',
                id=self.channel_id
            ).execute()

            if not channel_response.get('items'):
                print("âŒ ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return videos

            uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            print(f"   ğŸ“‚ Uploads ì¬ìƒëª©ë¡ ID: {uploads_playlist_id}")

            # 2. ì¬ìƒëª©ë¡ì˜ ëª¨ë“  ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
            next_page_token = None
            page = 1

            while True:
                playlist_response = self.youtube.playlistItems().list(
                    part='snippet',
                    playlistId=uploads_playlist_id,
                    maxResults=50,  # í˜ì´ì§€ë‹¹ ìµœëŒ€ 50ê°œ
                    pageToken=next_page_token
                ).execute()

                items = playlist_response.get('items', [])
                print(f"   ğŸ“„ Page {page}: {len(items)}ê°œ ì˜ìƒ")

                for item in items:
                    video_id = item['snippet']['resourceId']['videoId']
                    title = item['snippet']['title']
                    videos.append({
                        'video_id': video_id,
                        'title': title
                    })

                    if max_results and len(videos) >= max_results:
                        break

                if max_results and len(videos) >= max_results:
                    break

                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break

                page += 1
                time.sleep(self.delay)  # API í˜¸ì¶œ ê°„ ëŒ€ê¸°

            print(f"âœ… ì´ {len(videos)}ê°œ ì˜ìƒ ë°œê²¬")
            return videos

        except HttpError as e:
            print(f"âŒ API ì˜¤ë¥˜: {e}")
            return videos

    def has_affiliate_links(self, description: str) -> bool:
        """
        Descriptionì— ì´ë¯¸ ì œíœ´ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸

        Args:
            description: YouTube ì˜ìƒ ì„¤ëª…

        Returns:
            ì œíœ´ ë§í¬ê°€ ìˆìœ¼ë©´ True
        """
        for marker in AFFILIATE_MARKERS:
            if marker in description:
                return True
        return False

    def extract_book_info_from_description(self, description: str, title: str) -> Optional[Dict]:
        """
        Descriptionê³¼ ì œëª©ì—ì„œ ì±… ì •ë³´ ì¶”ì¶œ

        Args:
            description: YouTube ì˜ìƒ ì„¤ëª…
            title: YouTube ì˜ìƒ ì œëª©

        Returns:
            {"book_title_ko": "...", "book_title_en": "...", "author_ko": "...", "author_en": "..."}
            ë˜ëŠ” None
        """
        # ì œëª©ì—ì„œ ì±… ì œëª© ì¶”ì¶œ (íŒ¨í„´: [í•µì‹¬ ìš”ì•½] ì±…ì œëª©: ì‘ê°€ ë˜ëŠ” [í•œêµ­ì–´] ì±…ì œëª© ì±… ë¦¬ë·°)
        # ì˜ˆ: "[í•µì‹¬ ìš”ì•½] ë…¸ì¸ê³¼ ë°”ë‹¤: ì–´ë‹ˆìŠ¤íŠ¸ í—¤ë°ì›¨ì´"
        # ì˜ˆ: "[í•œêµ­ì–´] ë…¸ë¥´ì›¨ì´ì˜ ìˆ² ì±… ë¦¬ë·° ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤ | [Korean] Norwegian Wood Book Review"

        book_title_ko = ""
        book_title_en = ""
        author_ko = ""
        author_en = ""

        # íŒ¨í„´ 1: [í•µì‹¬ ìš”ì•½] ë˜ëŠ” [í•œêµ­ì–´] í˜•ì‹
        match = re.search(r'\[(?:í•µì‹¬ ìš”ì•½|í•œêµ­ì–´|English)\]\s*([^:|\[]+)', title)
        if match:
            extracted = match.group(1).strip()
            # "ì±… ë¦¬ë·°", "Book Review" ì œê±°
            extracted = re.sub(r'\s*ì±…\s*ë¦¬ë·°\s*', '', extracted)
            extracted = re.sub(r'\s*Book\s*Review\s*', '', extracted)

            # í•œê¸€ì¸ì§€ ì˜ë¬¸ì¸ì§€ íŒë‹¨
            if is_english_title(extracted):
                book_title_en = extracted
            else:
                book_title_ko = extracted

        # íŒ¨í„´ 2: descriptionì—ì„œ "âœï¸ ì‘ê°€:" ë˜ëŠ” "âœï¸ Author:" ì°¾ê¸°
        author_match_ko = re.search(r'âœï¸\s*ì‘ê°€:\s*([^\n]+)', description)
        if author_match_ko:
            author_ko = author_match_ko.group(1).strip()

        author_match_en = re.search(r'âœï¸\s*Author:\s*([^\n]+)', description)
        if author_match_en:
            author_en = author_match_en.group(1).strip()

        # ì±… ì œëª©ì´ë‚˜ ì‘ê°€ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë°˜í™˜
        if book_title_ko or book_title_en or author_ko or author_en:
            return {
                "book_title_ko": book_title_ko,
                "book_title_en": book_title_en,
                "author_ko": author_ko,
                "author_en": author_en
            }

        return None

    def insert_affiliate_links(self, description: str, book_info: Dict, language: str) -> str:
        """
        Descriptionì— ì œíœ´ ë§í¬ ì‚½ì… (í•´ì‹œíƒœê·¸ ì•)

        Args:
            description: ê¸°ì¡´ YouTube ì˜ìƒ ì„¤ëª…
            book_info: ì±… ì •ë³´ ë”•ì…”ë„ˆë¦¬
            language: 'ko' ë˜ëŠ” 'en'

        Returns:
            ì œíœ´ ë§í¬ê°€ ì‚½ì…ëœ description
        """
        # í•´ì‹œíƒœê·¸ ìœ„ì¹˜ ì°¾ê¸°
        hashtag_pattern = r'#[^\s#]+'
        matches = list(re.finditer(hashtag_pattern, description))

        if not matches:
            # í•´ì‹œíƒœê·¸ê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ì— ì¶”ê°€
            insert_pos = len(description)
        else:
            # ì²« ë²ˆì§¸ í•´ì‹œíƒœê·¸ ìœ„ì¹˜
            insert_pos = matches[0].start()

        # ì œíœ´ ë§í¬ ìƒì„±
        affiliate_section = generate_affiliate_section(
            book_title_ko=book_info.get("book_title_ko", ""),
            book_title_en=book_info.get("book_title_en", ""),
            author_ko=book_info.get("author_ko", ""),
            author_en=book_info.get("author_en", ""),
            language=language
        )

        if not affiliate_section:
            return description  # ì œíœ´ IDê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ

        # ì‚½ì…
        new_description = description[:insert_pos] + affiliate_section + "\n" + description[insert_pos:]
        return new_description

    def update_video_description(self, video_id: str, new_description: str, title: str, tags: List[str]) -> bool:
        """
        YouTube ì˜ìƒ description ì—…ë°ì´íŠ¸

        Args:
            video_id: YouTube ì˜ìƒ ID
            new_description: ìƒˆ description
            title: ì˜ìƒ ì œëª© (ë³€ê²½í•˜ì§€ ì•Šì§€ë§Œ API ìš”ì²­ì— í•„ìš”)
            tags: ì˜ìƒ íƒœê·¸ (ë³€ê²½í•˜ì§€ ì•Šì§€ë§Œ API ìš”ì²­ì— í•„ìš”)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if self.dry_run:
            print("   ğŸ” [DRY RUN] ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return True

        try:
            self.youtube.videos().update(
                part='snippet',
                body={
                    'id': video_id,
                    'snippet': {
                        'title': title,
                        'description': new_description,
                        'tags': tags,
                        'categoryId': '27'  # Education
                    }
                }
            ).execute()

            print("   âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True

        except HttpError as e:
            print(f"   âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    def process_videos(self, video_ids: Optional[List[str]] = None, limit: Optional[int] = None):
        """
        ì˜ìƒë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì œíœ´ ë§í¬ ì¶”ê°€

        Args:
            video_ids: ì²˜ë¦¬í•  ì˜ìƒ ID ëª©ë¡ (Noneì´ë©´ ì „ì²´ ì±„ë„)
            limit: ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜
        """
        if video_ids:
            # íŠ¹ì • ì˜ìƒë§Œ ì²˜ë¦¬
            videos = [{"video_id": vid, "title": "Unknown"} for vid in video_ids]
        else:
            # ì±„ë„ ì „ì²´ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
            videos = self.get_channel_videos(max_results=limit)

        if not videos:
            print("ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*60}")
        print(f"ì²˜ë¦¬ ëª¨ë“œ: {'ğŸ” DRY RUN (ë¯¸ë¦¬ë³´ê¸°)' if self.dry_run else 'âœï¸ APPLY (ì‹¤ì œ ì—…ë°ì´íŠ¸)'}")
        print(f"ì²˜ë¦¬ ëŒ€ìƒ: {len(videos)}ê°œ ì˜ìƒ")
        print(f"{'='*60}\n")

        updated_count = 0
        skipped_count = 0
        error_count = 0

        for idx, video in enumerate(videos, 1):
            video_id = video['video_id']
            video_title = video['title']

            print(f"\n[{idx}/{len(videos)}] ğŸ¬ {video_title}")
            print(f"   ğŸ“¹ Video ID: {video_id}")

            try:
                # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                video_response = self.youtube.videos().list(
                    part='snippet',
                    id=video_id
                ).execute()

                if not video_response.get('items'):
                    print("   âš ï¸ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì‚­ì œë˜ì—ˆê±°ë‚˜ ë¹„ê³µê°œ)")
                    skipped_count += 1
                    continue

                snippet = video_response['items'][0]['snippet']
                current_description = snippet.get('description', '')
                current_title = snippet.get('title', video_title)
                current_tags = snippet.get('tags', [])

                # 1. ì´ë¯¸ ì œíœ´ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                if self.has_affiliate_links(current_description):
                    print("   âœ… ì´ë¯¸ ì œíœ´ ë§í¬ê°€ ìˆìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
                    skipped_count += 1
                    continue

                # 2. ì±… ì •ë³´ ì¶”ì¶œ
                book_info = self.extract_book_info_from_description(current_description, current_title)
                if not book_info:
                    print("   âš ï¸ ì±… ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
                    skipped_count += 1
                    continue

                print(f"   ğŸ“š ì±… ì •ë³´: {book_info}")

                # 3. ì–¸ì–´ ê°ì§€ (í•œê¸€/ì˜ë¬¸)
                if book_info.get("book_title_ko"):
                    language = "ko"
                elif book_info.get("book_title_en"):
                    language = "en"
                else:
                    print("   âš ï¸ ì–¸ì–´ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")
                    skipped_count += 1
                    continue

                # 4. ì œíœ´ ë§í¬ ì‚½ì…
                new_description = self.insert_affiliate_links(current_description, book_info, language)

                if new_description == current_description:
                    print("   âš ï¸ ì œíœ´ ë§í¬ ìƒì„± ì‹¤íŒ¨ (ì œíœ´ ID ë¯¸ì„¤ì •?). (ê±´ë„ˆëœ€)")
                    skipped_count += 1
                    continue

                print(f"   ğŸ“ ìƒˆ description ê¸¸ì´: {len(new_description)}ì (ê¸°ì¡´: {len(current_description)}ì)")

                # 5. ì—…ë°ì´íŠ¸
                if self.update_video_description(video_id, new_description, current_title, current_tags):
                    updated_count += 1
                else:
                    error_count += 1

                # API í˜¸ì¶œ ê°„ ëŒ€ê¸°
                time.sleep(self.delay)

            except HttpError as e:
                print(f"   âŒ API ì˜¤ë¥˜: {e}")
                error_count += 1
                time.sleep(self.delay)
            except Exception as e:
                print(f"   âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
                error_count += 1
                time.sleep(self.delay)

        # ìµœì¢… ê²°ê³¼
        print(f"\n{'='*60}")
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
        print(f"   - ê±´ë„ˆëœ€: {skipped_count}ê°œ")
        print(f"   - ì˜¤ë¥˜: {error_count}ê°œ")
        print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(
        description="ê¸°ì¡´ YouTube ì˜ìƒì— ì œíœ´ ë§í¬ ì¼ê´„ ì—…ë°ì´íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë¯¸ë¦¬ë³´ê¸° (ê¸°ë³¸)
  python src/24_batch_update_affiliate_links.py --dry-run

  # ì‹¤ì œ ì ìš© (50ê°œ ì œí•œ)
  python src/24_batch_update_affiliate_links.py --apply --limit 50

  # íŠ¹ì • ì˜ìƒë§Œ ì—…ë°ì´íŠ¸
  python src/24_batch_update_affiliate_links.py --video-id VIDEO_ID --apply

  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (ì´ˆ)
  python src/24_batch_update_affiliate_links.py --apply --delay 2.0

ì£¼ì˜ì‚¬í•­:
  - YouTube API ì¼ì¼ ì¿¼í„°: videos.update 1ê±´ = 50 units (ì¼ 10,000 units ì œí•œ â†’ ì•½ 200ê±´/ì¼)
  - --apply í”Œë˜ê·¸ ì—†ì´ëŠ” ë¯¸ë¦¬ë³´ê¸°ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
  - ì´ë¯¸ ì œíœ´ ë§í¬ê°€ ìˆëŠ” ì˜ìƒì€ ê±´ë„ˆëœë‹ˆë‹¤ (ë©±ë“±ì„±).
        """
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='ë¯¸ë¦¬ë³´ê¸°ë§Œ ìˆ˜í–‰ (ì‹¤ì œ ì—…ë°ì´íŠ¸ ì•ˆ í•¨, ê¸°ë³¸ê°’)'
    )

    parser.add_argument(
        '--apply',
        action='store_true',
        help='ì‹¤ì œë¡œ ì—…ë°ì´íŠ¸ ì ìš© (ì´ í”Œë˜ê·¸ê°€ ìˆì–´ì•¼ ì—…ë°ì´íŠ¸ë¨)'
    )

    parser.add_argument(
        '--limit',
        type=int,
        default=None,
        help='ì²˜ë¦¬í•  ìµœëŒ€ ì˜ìƒ ê°œìˆ˜'
    )

    parser.add_argument(
        '--delay',
        type=float,
        default=1.0,
        help='API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1.0)'
    )

    parser.add_argument(
        '--video-id',
        action='append',
        help='ì²˜ë¦¬í•  íŠ¹ì • ì˜ìƒ ID (ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥)'
    )

    args = parser.parse_args()

    # --apply í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ dry_run=False
    dry_run = not args.apply

    if not dry_run:
        print("âš ï¸ ì‹¤ì œ ì—…ë°ì´íŠ¸ ëª¨ë“œì…ë‹ˆë‹¤. 5ì´ˆ í›„ ì‹œì‘í•©ë‹ˆë‹¤...")
        time.sleep(5)

    try:
        updater = AffiliateLinksUpdater(dry_run=dry_run, delay=args.delay)
        updater.process_videos(video_ids=args.video_id, limit=args.limit)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
