"""
ì±… í‘œì§€ ë° ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
- Google Books APIë¡œ ì±… í‘œì§€ ë‹¤ìš´ë¡œë“œ
- Unsplash/Pexels APIë¡œ ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (5~10ì¥)
"""

import os
import json
import time
import requests
from pathlib import Path
from typing import List, Dict, Optional
import concurrent.futures
import random
from dotenv import load_dotenv
try:
    from utils.retry_utils import retry_with_backoff
except ImportError:
    from src.utils.retry_utils import retry_with_backoff

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from googleapiclient.discovery import build
    GOOGLE_BOOKS_AVAILABLE = True
except ImportError:
    GOOGLE_BOOKS_AVAILABLE = False

try:
    from pexels_api import API as PexelsAPI
    PEXELS_AVAILABLE = True
except ImportError:
    PEXELS_AVAILABLE = False

load_dotenv()


class ImageDownloader:
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # API í‚¤ ë¡œë“œ
        self.google_books_api_key = os.getenv("GOOGLE_BOOKS_API_KEY")
        self.pexels_api_key = os.getenv("PEXELS_API_KEY")
        self.unsplash_access_key = os.getenv("UNSPLASH_ACCESS_KEY")
        self.pixabay_api_key = os.getenv("PIXABAY_API_KEY")
        
        # Google Books API ì´ˆê¸°í™”
        self.books_service = None
        if GOOGLE_BOOKS_AVAILABLE and self.google_books_api_key:
            try:
                self.books_service = build('books', 'v1', developerKey=self.google_books_api_key)
            except Exception as e:
                print(f"âš ï¸ Google Books API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Pexels API ì´ˆê¸°í™”
        self.pexels = None
        if PEXELS_AVAILABLE and self.pexels_api_key:
            try:
                self.pexels = PexelsAPI(self.pexels_api_key)
            except Exception as e:
                print(f"âš ï¸ Pexels API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # AI API í‚¤ ë¡œë“œ
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.claude_api_key = os.getenv("CLAUDE_API_KEY")
    
    @retry_with_backoff(retries=3, backoff_in_seconds=1.0)
    def _download_single_image(self, url: str, output_path: Path) -> str:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        with open(output_path, 'wb') as f:
            f.write(response.content)
        
        return str(output_path)

    @retry_with_backoff(retries=3, backoff_in_seconds=2.0)
    def _make_request(self, url: str, headers: Dict = None, params: Dict = None) -> Dict:
        """API ìš”ì²­ ìˆ˜í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        return response.json()

    @retry_with_backoff(retries=3, backoff_in_seconds=2.0)
    def _search_pexels(self, keyword: str, page: int, results_per_page: int) -> Dict:
        """Pexels ê²€ìƒ‰ ìˆ˜í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        if not self.pexels:
            raise ValueError("Pexels API not initialized")
        
        # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ëœë¤í•˜ê²Œ í˜ì´ì§€ ì„ íƒ (1~3í˜ì´ì§€)
        if page == 1:
            page = random.randint(1, 3)
            
        return self.pexels.search(keyword, page=page, results_per_page=results_per_page)
    
    def download_book_cover(self, book_title: str, author: str = None, output_dir: Path = None, skip_image: bool = False) -> Optional[str]:
        """
        Google Books APIë¡œ ì±… í‘œì§€ ë‹¤ìš´ë¡œë“œ ë° book_info.json ìƒì„±
        
        âš ï¸ ì£¼ì˜: ì±… í‘œì§€ ì´ë¯¸ì§€ëŠ” ì €ì‘ê¶Œì´ ìˆì–´ YouTube ë“±ì— ì‚¬ìš© ì‹œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        í‘œì§€ ì´ë¯¸ì§€ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ë‹¤ìš´ë¡œë“œí•˜ë©°, ì‹¤ì œ ì˜ìƒ ì œì‘ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        
        Args:
            book_title: ì±… ì œëª©
            author: ì €ì ì´ë¦„
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            skip_image: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œëŠ” ê±´ë„ˆë›°ê³  book_info.jsonë§Œ ìƒì„±
            
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ (skip_image=Trueë©´ None)
        """
        if not self.books_service:
            print("âš ï¸ Google Books APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ“š ì±… í‘œì§€ ê²€ìƒ‰ ì¤‘: {book_title}")
        if author:
            print(f"   ì €ì: {author}")
        
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± (ì €ì í¬í•¨í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
            query = f'intitle:"{book_title}"'
            if author:
                query += f' inauthor:"{author}"'
            
            # ì–¸ì–´ ê°ì§€: ì œëª©ì— í•œê¸€ì´ ìˆìœ¼ë©´ í•œêµ­ì–´, ì—†ìœ¼ë©´ ì˜ì–´ë¡œ ê²€ìƒ‰
            has_korean = any('\uAC00' <= c <= '\uD7A3' for c in book_title)
            lang_restrict = 'ko' if has_korean else 'en'
            
            print(f"   ê²€ìƒ‰ ì–¸ì–´: {lang_restrict}")
            
            # Google Books API ê²€ìƒ‰
            results = self.books_service.volumes().list(
                q=query,
                maxResults=10,  # ë” ë§ì€ ê²°ê³¼ í™•ì¸
                langRestrict=lang_restrict
            ).execute()
            
            if not results.get('items'):
                # ì–¸ì–´ ì œí•œ ì—†ì´ ì¬ì‹œë„
                print("  âš ï¸ ì–¸ì–´ ì œí•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì–¸ì–´ ì œí•œ ì—†ì´ ì¬ì‹œë„...")
                results = self.books_service.volumes().list(
                    q=query,
                    maxResults=10
                ).execute()
            
            if not results.get('items'):
                print("  âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ ì„ íƒ (ì €ìëª…ë„ í™•ì¸)
            best_book = None
            for book in results['items']:
                volume_info = book.get('volumeInfo', {})
                book_authors = volume_info.get('authors', [])
                book_title_found = volume_info.get('title', '').lower()
                
                # ì €ìëª…ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                author_match = False
                if author:
                    author_lower = author.lower()
                    for book_author in book_authors:
                        if author_lower in book_author.lower() or book_author.lower() in author_lower:
                            author_match = True
                            break
                else:
                    author_match = True  # ì €ì ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë“  ê²°ê³¼ í—ˆìš©
                
                # ì œëª©ë„ ë¹„ìŠ·í•œì§€ í™•ì¸
                title_match = book_title.lower() in book_title_found or book_title_found in book_title.lower()
                
                if author_match and title_match:
                    best_book = book
                    print(f"  âœ… ë§¤ì¹­ëœ ì±… ë°œê²¬: {volume_info.get('title')} - {', '.join(book_authors)}")
                    break
            
            if not best_book:
                # ë§¤ì¹­ë˜ëŠ” ê²Œ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
                print("  âš ï¸ ì •í™•í•œ ë§¤ì¹­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                best_book = results['items'][0]
            
            book = best_book
            volume_info = book.get('volumeInfo', {})
            
            # ì €ì¥ ê²½ë¡œ
            if output_dir is None:
                try:
                    from utils.file_utils import get_standard_safe_title
                except ImportError:
                    from src.utils.file_utils import get_standard_safe_title
                safe_title_str = get_standard_safe_title(book_title)
                output_dir = Path("assets/images") / safe_title_str
            else:
                output_dir = Path(output_dir)
            
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (skip_imageê°€ Falseì¸ ê²½ìš°ë§Œ)
            image_url = None
            output_path = None
            if not skip_image:
                # ì´ë¯¸ì§€ ë§í¬ ì°¾ê¸°
                image_links = volume_info.get('imageLinks', {})
                if not image_links:
                    print("  âš ï¸ í‘œì§€ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ
                    image_url = image_links.get('large') or image_links.get('medium') or image_links.get('small') or image_links.get('thumbnail')
                    
                    if image_url:
                        try:
                            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                            response = requests.get(image_url, timeout=10)
                            response.raise_for_status()
                            
                            output_path = output_dir / "cover.jpg"
                            
                            # íŒŒì¼ ì €ì¥
                            with open(output_path, 'wb') as f:
                                f.write(response.content)
                            
                            print(f"  âœ… í‘œì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
                        except Exception as e:
                            print(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                            image_url = None
                    else:
                        print("  âš ï¸ ì´ë¯¸ì§€ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # skip_image=Trueì¸ ê²½ìš°ì—ë„ image_urlì€ book_infoì— í¬í•¨í•˜ê¸° ìœ„í•´ ê°€ì ¸ì˜¤ê¸°
                image_links = volume_info.get('imageLinks', {})
                if image_links:
                    image_url = image_links.get('large') or image_links.get('medium') or image_links.get('small') or image_links.get('thumbnail')
                print("  â„¹ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œëŠ” ê±´ë„ˆë›°ê³  ì±… ì •ë³´ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
            
            # ì±… ì •ë³´ ì €ì¥ (ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ í•­ìƒ ì €ì¥)
            book_info = {
                'title': volume_info.get('title', book_title),
                'authors': volume_info.get('authors', [author] if author else []),
                'publisher': volume_info.get('publisher', ''),
                'publishedDate': volume_info.get('publishedDate', ''),
                'description': volume_info.get('description', ''),
                'pageCount': volume_info.get('pageCount', 0),
                'categories': volume_info.get('categories', []),
                'language': volume_info.get('language', 'ko'),
                'google_books_id': book.get('id', ''),
                'image_url': image_url if image_url else ''
            }
            
            book_info_path = output_dir / "book_info.json"
            with open(book_info_path, 'w', encoding='utf-8') as f:
                json.dump(book_info, f, ensure_ascii=False, indent=2)
            
            print(f"  âœ… ì±… ì •ë³´ ì €ì¥ ì™„ë£Œ: {book_info_path}")
            
            return str(output_path) if output_path else None
            
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            return None
    
    @retry_with_backoff(retries=3, backoff_in_seconds=2.0)
    def download_mood_images_unsplash(self, keywords: List[str], num_images: int = 100, output_dir: Path = None) -> List[str]:
        """
        Unsplash APIë¡œ ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        
        Args:
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            num_images: ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.unsplash_access_key:
            print("âš ï¸ Unsplash API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        downloaded = []
        # ê° í‚¤ì›Œë“œì—ì„œ ê°€ì ¸ì˜¬ ì´ë¯¸ì§€ ìˆ˜ (ë‹¤ì–‘ì„±ì„ ìœ„í•´ ì œí•œ)
        # í‚¤ì›Œë“œê°€ ë§ìœ¼ë©´ ì ê²Œ, ì ìœ¼ë©´ ë§ì´ ê°€ì ¸ì˜´ (ìµœì†Œ 2ê°œ, ìµœëŒ€ 5ê°œ)
        max_per_keyword = max(2, min(5, num_images // (len(keywords) or 1)))
        
        # í‚¤ì›Œë“œ ìˆœì„œ ì„ê¸° (ë§¤ë²ˆ ê°™ì€ í‚¤ì›Œë“œë§Œ ì‚¬ìš©ë˜ì§€ ì•Šë„ë¡)
        shuffled_keywords = keywords.copy()
        random.shuffle(shuffled_keywords)
        
        # ë‹¤ìš´ë¡œë“œ ì‘ì—… ë¦¬ìŠ¤íŠ¸
        download_tasks = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            for keyword in shuffled_keywords:
                if len(downloaded) + len(download_tasks) >= num_images:
                    break
                
                try:
                    print(f"  ğŸ” ê²€ìƒ‰: {keyword}")
                    
                    # Unsplash API ê²€ìƒ‰
                    url = "https://api.unsplash.com/search/photos"
                    headers = {
                        "Authorization": f"Client-ID {self.unsplash_access_key}"
                    }
                    # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ëœë¤í•˜ê²Œ í˜ì´ì§€ ì„ íƒ (1~3í˜ì´ì§€)
                    page = random.randint(1, 3)
                    
                    # ê° í‚¤ì›Œë“œì—ì„œ ìµœëŒ€ max_per_keywordê°œë§Œ ê°€ì ¸ì˜¤ê¸°
                    remaining = num_images - (len(downloaded) + len(download_tasks))
                    params = {
                        "query": keyword,
                        "page": page,
                        "per_page": min(max_per_keyword, remaining, 15),
                        "orientation": "landscape"
                    }
                    
                    data = self._make_request(url, headers=headers, params=params)
                    results = data.get('results', [])
                    
                    if not results:
                        print(f"    âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                        continue
                    
                    for photo in results:
                        if len(downloaded) + len(download_tasks) >= num_images:
                            break
                        
                        # ê³ í™”ì§ˆ ì´ë¯¸ì§€ URL
                        image_url = photo['urls'].get('regular') or photo['urls'].get('full')
                        
                        if not image_url:
                            continue
                        
                        # ì €ì¥ ê²½ë¡œ ì„¤ì •
                        filename = f"mood_{len(downloaded) + len(download_tasks) + 1:02d}_{keyword.replace(' ', '_')}.jpg"
                        output_path = output_dir / filename
                        
                        # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‘ì—… ì¶”ê°€
                        future = executor.submit(self._download_single_image, image_url, output_path)
                        download_tasks.append((future, filename))
                        
                        time.sleep(0.1)  # API rate limit ë°©ì§€ (ìµœì†Œí•œì˜ ì§€ì—°)
                    
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
                    continue
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future, filename in download_tasks:
                try:
                    result = future.result()
                    if result:
                        downloaded.append(result)
                        print(f"    âœ… {filename}")
                except Exception as e:
                    print(f"    âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
        
        return downloaded
    
    @retry_with_backoff(retries=3, backoff_in_seconds=2.0)
    def download_mood_images_pexels(self, keywords: List[str], num_images: int = 100, output_dir: Path = None) -> List[str]:
        """
        Pexels APIë¡œ ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        
        Args:
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            num_images: ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.pexels:
            print("âš ï¸ Pexels APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        downloaded = []
        # í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ (ë‹¤ì–‘ì„± í™•ë³´)
        max_per_keyword = max(2, min(5, num_images // (len(keywords) or 1)))
        
        # í‚¤ì›Œë“œ ìˆœì„œ ì„ê¸°
        shuffled_keywords = keywords.copy()
        random.shuffle(shuffled_keywords)
        
        download_tasks = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            for keyword in shuffled_keywords:
                if len(downloaded) + len(download_tasks) >= num_images:
                    break
                
                try:
                    print(f"  ğŸ” ê²€ìƒ‰: {keyword}")
                    
                    # Pexels API ê²€ìƒ‰
                    try:
                        remaining = num_images - (len(downloaded) + len(download_tasks))
                        # _search_pexels ë‚´ë¶€ì—ì„œ ì´ë¯¸ í˜ì´ì§€ ëœë¤í™” ì²˜ë¦¬ë¨
                        search_results = self._search_pexels(keyword, page=1, results_per_page=min(max_per_keyword, remaining))
                    except Exception as e:
                        print(f"    âŒ Pexels ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                        continue
                    
                    if not search_results.get('photos'):
                        print(f"    âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                        continue
                    
                    for photo in search_results['photos']:
                        if len(downloaded) + len(download_tasks) >= num_images:
                            break
                        
                        # ê³ í™”ì§ˆ ì´ë¯¸ì§€ URL
                        image_url = photo.get('src', {}).get('large') or photo.get('src', {}).get('original')
                        
                        if not image_url:
                            continue
                        
                        # ì €ì¥ ê²½ë¡œ ì„¤ì •
                        filename = f"mood_{len(downloaded) + len(download_tasks) + 1:02d}_{keyword.replace(' ', '_')}.jpg"
                        output_path = output_dir / filename
                        
                        # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‘ì—… ì¶”ê°€
                        future = executor.submit(self._download_single_image, image_url, output_path)
                        download_tasks.append((future, filename))
                        
                        time.sleep(0.1)  # API rate limit ë°©ì§€
                    
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
                    continue
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future, filename in download_tasks:
                try:
                    result = future.result()
                    if result:
                        downloaded.append(result)
                        print(f"    âœ… {filename}")
                except Exception as e:
                    print(f"    âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
        
        return downloaded
    
    @retry_with_backoff(retries=3, backoff_in_seconds=2.0)
    def download_mood_images_pixabay(self, keywords: List[str], num_images: int = 100, output_dir: Path = None) -> List[str]:
        """
        Pixabay APIë¡œ ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        
        Args:
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            num_images: ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.pixabay_api_key:
            print("âš ï¸ Pixabay API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        downloaded = []
        # í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
        max_per_keyword = max(2, min(5, num_images // (len(keywords) or 1)))
        
        # í‚¤ì›Œë“œ ìˆœì„œ ì„ê¸°
        shuffled_keywords = keywords.copy()
        random.shuffle(shuffled_keywords)
        
        base_url = "https://pixabay.com/api/"
        download_tasks = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            for keyword in shuffled_keywords:
                if len(downloaded) + len(download_tasks) >= num_images:
                    break
                
                try:
                    print(f"  ğŸ” ê²€ìƒ‰: {keyword}")
                    
                    # Pixabay API ê²€ìƒ‰
                    # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ëœë¤í•˜ê²Œ í˜ì´ì§€ ì„ íƒ
                    page = random.randint(1, 3)
                    
                    params = {
                        'key': self.pixabay_api_key,
                        'q': keyword,
                        'image_type': 'photo',
                        'orientation': 'horizontal',
                        'safesearch': 'true',
                        'page': page,
                        'per_page': min(max_per_keyword, num_images - (len(downloaded) + len(download_tasks)))
                    }
                    
                    data = self._make_request(base_url, params=params)
                    hits = data.get('hits', [])
                    
                    if not hits:
                        print(f"    âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                        continue
                    
                    for hit in hits:
                        if len(downloaded) + len(download_tasks) >= num_images:
                            break
                        
                        # ê³ í™”ì§ˆ ì´ë¯¸ì§€ URL (largeImageURL ìš°ì„ , ì—†ìœ¼ë©´ webformatURL)
                        image_url = hit.get('largeImageURL') or hit.get('webformatURL')
                        
                        if not image_url:
                            continue
                        
                        # ì €ì¥ ê²½ë¡œ ì„¤ì •
                        filename = f"mood_{len(downloaded) + len(download_tasks) + 1:02d}_{keyword.replace(' ', '_')}.jpg"
                        output_path = output_dir / filename
                        
                        # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‘ì—… ì¶”ê°€
                        future = executor.submit(self._download_single_image, image_url, output_path)
                        download_tasks.append((future, filename))
                        
                        time.sleep(0.1)  # API rate limit ë°©ì§€
                    
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
                    continue
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future, filename in download_tasks:
                try:
                    result = future.result()
                    if result:
                        downloaded.append(result)
                        print(f"    âœ… {filename}")
                except Exception as e:
                    print(f"    âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
        
        return downloaded
    
    def download_all(self, book_title: str, author: str = None, keywords: List[str] = None, num_mood_images: int = 100, skip_cover: bool = False) -> Dict:
        """
        ì±… í‘œì§€ì™€ ë¬´ë“œ ì´ë¯¸ì§€ ëª¨ë‘ ë‹¤ìš´ë¡œë“œ
        
        Args:
            book_title: ì±… ì œëª©
            author: ì €ì ì´ë¦„
            keywords: ë¬´ë“œ ì´ë¯¸ì§€ ê²€ìƒ‰ í‚¤ì›Œë“œ (Noneì´ë©´ ìë™ ìƒì„±)
            num_mood_images: ë¬´ë“œ ì´ë¯¸ì§€ ê°œìˆ˜
            
        Returns:
            ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("=" * 60)
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        print("=" * 60)
        print()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        try:
            from utils.file_utils import get_standard_safe_title
        except ImportError:
            from src.utils.file_utils import get_standard_safe_title
        safe_title_str = get_standard_safe_title(book_title)
        output_dir = Path("assets/images") / safe_title_str
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ì±… í‘œì§€ ë‹¤ìš´ë¡œë“œ ë° book_info.json ìƒì„± (ì„ íƒì‚¬í•­)
        # âš ï¸ ì£¼ì˜: ì±… í‘œì§€ëŠ” ì €ì‘ê¶Œì´ ìˆì–´ ì˜ìƒì— ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # í‘œì§€ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ë‹¤ìš´ë¡œë“œí•˜ë©°, ì‹¤ì œ ì˜ìƒì—ëŠ” ì €ì‘ê¶Œ ì—†ëŠ” ë¬´ë“œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # skip_cover=Trueì—¬ë„ book_info.jsonì€ ìƒì„±í•©ë‹ˆë‹¤.
        cover_path = None
        if skip_cover:
            print("â„¹ï¸ ì±… í‘œì§€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œëŠ” ê±´ë„ˆë›°ì§€ë§Œ, ì±… ì •ë³´(book_info.json)ëŠ” ìƒì„±í•©ë‹ˆë‹¤.")
            self.download_book_cover(book_title, author, output_dir, skip_image=True)
            print()
        else:
            print("âš ï¸ ì±… í‘œì§€ ì´ë¯¸ì§€ëŠ” ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì˜ìƒì— ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   í‘œì§€ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
            cover_path = self.download_book_cover(book_title, author, output_dir, skip_image=False)
            print()
        
        # 2. í‚¤ì›Œë“œ ìƒì„± (ì—†ìœ¼ë©´) - AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±… ë‚´ìš© ê¸°ë°˜ í‚¤ì›Œë“œ ìƒì„±
        if keywords is None:
            print("ğŸ“ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±… ë‚´ìš© ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì¤‘...")
            keywords = self.generate_keywords_with_ai(book_title, author, output_dir)
            print(f"   âœ… ìƒì„±ëœ í‚¤ì›Œë“œ: {', '.join(keywords[:10])}")
            print()
        
        print(f"ğŸ¨ ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... (í‚¤ì›Œë“œ: {', '.join(keywords)})")
        print()
        
        # 3. ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (Pexels â†’ Pixabay â†’ Unsplash ìˆœì„œ)
        # ê¸°ì¡´ ì´ë¯¸ì§€ í™•ì¸
        existing_images = list(output_dir.glob("mood_*.jpg"))
        existing_count = len(existing_images)
        
        if existing_count >= num_mood_images:
            print(f"âœ… ê¸°ì¡´ ì´ë¯¸ì§€ ë°œê²¬: {existing_count}ê°œ (ëª©í‘œ: {num_mood_images}ê°œ)")
            print(f"   ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            print()
            return {
                'cover_path': str(cover_path) if cover_path else None,
                'mood_images': [str(img) for img in existing_images[:num_mood_images]],
                'total_mood_images': existing_count
            }
        
        print(f"ğŸ“Š ê¸°ì¡´ ì´ë¯¸ì§€: {existing_count}ê°œ, ì¶”ê°€ë¡œ {num_mood_images - existing_count}ê°œ í•„ìš”")
        print()
        
        # 100ê°œ ì´ë¯¸ì§€ë¥¼ í™•ì‹¤íˆ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ í‚¤ì›Œë“œì—ì„œ ì¶©ë¶„íˆ ìˆ˜ì§‘
        mood_images = existing_images.copy()  # ê¸°ì¡´ ì´ë¯¸ì§€ í¬í•¨
        target_count = num_mood_images
        
        # Pexelsì—ì„œ ë‹¤ìš´ë¡œë“œ (1ìˆœìœ„)
        if len(mood_images) < target_count and self.pexels:
            remaining = target_count - len(mood_images)
            print(f"  ğŸ“¸ Pexelsì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... (ëª©í‘œ: {remaining}ê°œ)")
            additional = self.download_mood_images_pexels(keywords, remaining, output_dir)
            mood_images.extend(additional)
            print(f"  âœ… Pexels: {len(additional)}ê°œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        # Pixabayì—ì„œ ì¶”ê°€ ë‹¤ìš´ë¡œë“œ (2ìˆœìœ„)
        if len(mood_images) < target_count and self.pixabay_api_key:
            remaining = target_count - len(mood_images)
            print(f"  ğŸ“¸ Pixabayì—ì„œ ì¶”ê°€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... (ëª©í‘œ: {remaining}ê°œ)")
            additional = self.download_mood_images_pixabay(keywords, remaining, output_dir)
            mood_images.extend(additional)
            print(f"  âœ… Pixabay: {len(additional)}ê°œ ì¶”ê°€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        # Unsplashì—ì„œ ì¶”ê°€ ë‹¤ìš´ë¡œë“œ (3ìˆœìœ„)
        if len(mood_images) < target_count and self.unsplash_access_key:
            remaining = target_count - len(mood_images)
            print(f"  ğŸ“¸ Unsplashì—ì„œ ì¶”ê°€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... (ëª©í‘œ: {remaining}ê°œ)")
            additional = self.download_mood_images_unsplash(keywords, remaining, output_dir)
            mood_images.extend(additional)
            print(f"  âœ… Unsplash: {len(additional)}ê°œ ì¶”ê°€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        # ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ í‚¤ì›Œë“œë¥¼ ìˆœí™˜í•˜ë©° ì¶”ê°€ ë‹¤ìš´ë¡œë“œ
        if len(mood_images) < target_count:
            remaining = target_count - len(mood_images)
            print(f"  ğŸ”„ ì¶”ê°€ í‚¤ì›Œë“œë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... (ëª©í‘œ: {remaining}ê°œ)")
            
            # í‚¤ì›Œë“œ ìˆœì„œ ì„ê¸°
            shuffled_keywords = keywords.copy()
            random.shuffle(shuffled_keywords)
            
            # í‚¤ì›Œë“œë¥¼ ìˆœí™˜í•˜ë©° ì¶”ê°€ ë‹¤ìš´ë¡œë“œ
            keyword_cycle = 0
            while len(mood_images) < target_count and keyword_cycle < len(keywords) * 2:
                for keyword in shuffled_keywords:
                    if len(mood_images) >= target_count:
                        break
                    remaining = target_count - len(mood_images)
                    if remaining <= 0:
                        break
                    
                    # Pexelsì—ì„œ ì¶”ê°€ ì‹œë„ (1ìˆœìœ„)
                    if len(mood_images) < target_count and self.pexels:
                        remaining = target_count - len(mood_images)
                        try:
                            additional = self.download_mood_images_pexels([keyword], min(remaining, 3), output_dir)
                            mood_images.extend(additional)
                        except:
                            pass
                    
                    # Pixabayì—ì„œ ì¶”ê°€ ì‹œë„ (2ìˆœìœ„)
                    if len(mood_images) < target_count and self.pixabay_api_key:
                        remaining = target_count - len(mood_images)
                        try:
                            additional = self.download_mood_images_pixabay([keyword], min(remaining, 3), output_dir)
                            mood_images.extend(additional)
                        except:
                            pass
                    
                    # Unsplashì—ì„œ ì¶”ê°€ ì‹œë„ (3ìˆœìœ„)
                    if len(mood_images) < target_count and self.unsplash_access_key:
                        remaining = target_count - len(mood_images)
                        try:
                            additional = self.download_mood_images_unsplash([keyword], min(remaining, 3), output_dir)
                            mood_images.extend(additional)
                        except:
                            pass
                
                keyword_cycle += 1
                if len(mood_images) >= target_count:
                    break
        
        print()
        print("=" * 60)
        print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        print("=" * 60)
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        print(f"ğŸ“š í‘œì§€: {'âœ…' if cover_path else 'âŒ'}")
        print(f"ğŸ¨ ë¬´ë“œ ì´ë¯¸ì§€: {len(mood_images)}ê°œ")
        print()
        
        # mood_imagesê°€ Path ê°ì²´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        mood_images_str = [str(img) if isinstance(img, Path) else img for img in mood_images]
        
        return {
            'cover_path': str(cover_path) if cover_path else None,
            'mood_images': mood_images_str,
            'output_dir': str(output_dir),
            'total_mood_images': len(mood_images_str)
        }
    
    def _generate_keywords(self, book_title: str, author: str = None) -> List[str]:
        """
        ì±…ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œ ìƒì„± (ì €ì‘ê¶Œ ì—†ëŠ” ì´ë¯¸ì§€ ê²€ìƒ‰ìš©)
        - ê´€ë ¨ ì˜í™”, ì‘ê°€, ì±… í…Œë§ˆ ë“±
        """
        keywords = []
        author_lower = author.lower() if author else ""
        title_lower = book_title.lower() if book_title else ""
        
        # ì‘ê°€ ê´€ë ¨ í‚¤ì›Œë“œ
        if author:
            # ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤ ê´€ë ¨
            if any(n in author_lower for n in ["ë¬´ë¼ì¹´ë¯¸", "í•˜ë£¨í‚¤", "murakami", "haruki"]):
                keywords.extend([
                    "japanese literature", "tokyo cityscape", "japanese culture",
                    "norwegian wood movie", "japanese novel", "murakami books",
                    "surrealism art", "jazz bar atmosphere", "well in forest"
                ])
            # ì˜¤ë² ë¼ëŠ” ë‚¨ì / í”„ë ˆë“œë¦­ ë°°í¬ë§Œ ê´€ë ¨
            elif any(n in author_lower or n in title_lower for n in ["ì˜¤ë² ", "ë°°í¬ë§Œ", "backman", "ove"]):
                keywords.extend([
                    "swedish small town", "old neighborhood houses", "saab car vintage",
                    "grumpy old man", "lonely figure park bench", "neighborhood community",
                    "winter in sweden", "melancholic atmosphere", "warm interior cottage",
                    "cat in neighborhood", "toolbox and tools", "blue overalls"
                ])
            # ì¼ë°˜ì ì¸ ì‘ê°€ëª… ì¶”ê°€
            keywords.append(author_lower.replace(" ", ""))
        
        # ì±… ì œëª© í…Œë§ˆ ê´€ë ¨ í‚¤ì›Œë“œ
        if any(n in title_lower for n in ["ë…¸ë¥´ì›¨ì´", "norwegian", "ìƒì‹¤", "loss"]):
            keywords.extend([
                "norway forest", "norwegian landscape", "forest nature",
                "scandinavian nature", "1960s japan", "tokyo 1960s",
                "loss and grief", "japanese youth 1960s", "tokyo university"
            ])
        
        # ì‹œê°ì  ë‹¤ì–‘ì„±ì„ ìœ„í•œ ë²”ìš© í…Œë§ˆ í‚¤ì›Œë“œ (ì¶”ê°€)
        keywords.extend([
            "dramatic lighting", "cinematic landscape", "moody atmosphere",
            "vintage photography", "storytelling visual", "emotional scene",
            "historical setting", "urban decay", "peaceful countryside",
            "abstract theme", "texture background", "soft bokeh",
            "golden hour nature", "minimalist composition", "symbolic object"
        ])
        
        # ì¼ë°˜ì ì¸ ë¬¸í•™ í‚¤ì›Œë“œ (ì´ë¯¸ì§€ ê²€ìƒ‰ íš¨ìœ¨ì´ ì¢‹ì€ ê²ƒë“¤)
        keywords.extend([
            "classic novel vibe",
            "vintage aesthetics",
            "literary atmosphere"
        ])
        
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 30ê°œ ë°˜í™˜ (ê¸°ì¡´ 10ê°œì—ì„œ ìƒí–¥)
        unique_keywords = []
        seen = set()
        for kw in keywords:
            kw_clean = kw.lower().strip()
            if kw_clean and kw_clean not in seen:
                seen.add(kw_clean)
                unique_keywords.append(kw_clean)
        
        return unique_keywords[:30]
    
    def generate_keywords_with_ai(self, book_title: str, author: str = None, image_dir: Path = None) -> List[str]:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±… ë‚´ìš© ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        - ì±…ì˜ ë‚´ìš©, ì£¼ì œ, ë°°ê²½, ê°ì •, ì£¼ìš” ì¥ë©´ ë“±ì„ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ìƒì„±
        """
        try:
            from utils.file_utils import get_standard_safe_title
        except ImportError:
            from src.utils.file_utils import get_standard_safe_title
        
        safe_title_str = get_standard_safe_title(book_title)
        
        # ì±… ì •ë³´ ë¡œë“œ ì‹œë„
        book_info = None
        if image_dir:
            book_info_path = image_dir / "book_info.json"
            if book_info_path.exists():
                try:
                    with open(book_info_path, 'r', encoding='utf-8') as f:
                        book_info = json.load(f)
                except:
                    pass
        
        # Summary íŒŒì¼ ë¡œë“œ ì‹œë„ (ë” ì •í™•í•œ í‚¤ì›Œë“œ ìƒì„±ì„ ìœ„í•´)
        summary_text = None
        # .txtì™€ .md ëª¨ë‘ ì§€ì›
        summary_paths = [
            Path("assets/summaries") / f"{safe_title_str}_summary_kr.md",
            Path("assets/summaries") / f"{safe_title_str}_summary_en.md",
            # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ê²½ë¡œë“¤
            Path("assets/summaries") / f"{safe_title_str}_summary_ko.md",
            Path("assets/summaries") / f"{safe_title_str}_summary_ko.txt",
            Path("assets/summaries") / f"{safe_title_str}_summary_en.txt"
        ]
        
        for sp in summary_paths:
            if sp.exists():
                try:
                    with open(sp, 'r', encoding='utf-8') as f:
                        summary_text = f.read()[:2000]  # ì²˜ìŒ 2000ìë§Œ ì‚¬ìš©
                    break
                except:
                    continue
        
        prompt = f"""Role: You are an expert visual director and historian.
Task: Generate 60 specific English image search keywords for the book "{book_title}" by "{author}".

Instructions:
1. **Analyze Setting & Mood**: Determine the specific time period and geographical location.
2. **Visual Authenticity**: Generate keywords that strictly reflect the setting.
3. **CRITICAL - Geographical Accuracy**:
   - Strictly follow the story's setting. Do NOT use "Korea" unless the book is set there.
4. **Visual Diversity & Metaphor**: 
   - Beyond literal descriptions, include metaphorical and abstract visual concepts that represent the book's themes.
   - Use a mix of: Wide shots, Extreme-Close-ups (textures), and Medium shots.
   - Request varied lighting: (e.g., golden hour, moody shadows, harsh contrast, soft ethereal light).

Content to Analyze:
"""
        
        # Summary ë‚´ìš© ì¶”ê°€ (ê°€ì¥ ì¤‘ìš”)
        if summary_text:
            prompt += f"\n[Book Summary]\n{summary_text}\n"
        
        if book_info:
            if book_info.get('description'):
                prompt += f"\n[Book Description]\n{book_info['description'][:800]}\n"
            if book_info.get('categories'):
                prompt += f"[Categories]\n{', '.join(book_info['categories'])}\n"
        
        prompt += """
Keywords Categories (Provide 10-12 per category):
1. **Atmosphere & Mood**: (e.g., melancholy, ottoman miniature style, noir, dystopian fog, ethereal light)
2. **Setting & Architecture**: (e.g., hagia sophia, 16th century istanbul streets, 1960s tokyo alley, snowy forest)
3. **Objects & Symbols (Metaphoric)**: (e.g., broken hourglass, red caftan, vintage ink pot, wilting rose, heavy chains)
4. **Textures & Close-ups**: (e.g., old parchment texture, rain on window, dust motes in light, cracked soil, silk fabric)
5. **Characters/Scenes**: (e.g., silhouette in doorway, ottoman scribes, japanese students 1960s, lonely figure in coat)

Constraints:
- Keywords must be in **ENGLISH**.
- **NO** text overlays or typography keywords.
- **NO** generic terms like "book", "reading", "illustration".
- **Strictly exclude** modern elements if the book is historical.
- **Strictly exclude** Korean elements for non-Korean stories.

Format:
- Return ONLY a list of keywords separated by commas.
- No numbering or explanations.
"""



        try:
            # Claude API ìš°ì„  ì‚¬ìš©
            if ANTHROPIC_AVAILABLE and self.claude_api_key:
                client = anthropic.Anthropic(api_key=self.claude_api_key)
                response = client.messages.create(
                    model="claude-3-opus-20240229",
                    max_tokens=1000,
                    messages=[{
                        "role": "user",
                        "content": prompt
                    }]
                )
                keywords_text = response.content[0].text
            # OpenAI API ì‚¬ìš©
            elif OPENAI_AVAILABLE and self.openai_api_key:
                openai.api_key = self.openai_api_key
                response = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant that generates image search keywords based on book content."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000
                )
                keywords_text = response.choices[0].message.content
            else:
                print("   âš ï¸ AI API í‚¤ê°€ ì—†ì–´ ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._generate_keywords(book_title, author)
            
            # í‚¤ì›Œë“œ íŒŒì‹± ë° í•„í„°ë§
            keywords = []
            # ê¸ˆì§€ëœ ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ ëª©ë¡
            banned_keywords = {
                'aesthetic', 'beautiful', 'nice', 'pretty', 'art', 'design', 'style',
                'book', 'reading', 'literature', 'novel', 'story', 'fiction',
                'image', 'photo', 'picture', 'illustration', 'graphic', 'visual',
                'bookstore', 'bookshop', 'library'
            }
            
            # ì‰¼í‘œ(,)ì™€ ì¤„ë°”ê¿ˆ(\n)ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ì—¬ í‚¤ì›Œë“œ ë¶„ë¦¬
            raw_keywords = []
            for part in keywords_text.split(','):
                for line in part.split('\n'):
                    raw_keywords.append(line.strip())
            
            for line in raw_keywords:
                # ë²ˆí˜¸ë‚˜ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                if line and not line.startswith('#') and not line.startswith('-'):
                    # ë²ˆí˜¸ ì œê±° (1. 2. ë“±)
                    line = line.lstrip('0123456789. -')
                    # ë”°ì˜´í‘œ ì œê±°
                    line = line.strip('"\'')
                    # ë‹¨ì¼ ë¬¸ìë‚˜ ë„ˆë¬´ ì§§ì€ í‚¤ì›Œë“œ ì œì™¸
                    words = line.split()
                    if words and len(words) >= 1 and len(words) <= 5:
                        # ê° ë‹¨ì–´ê°€ ìµœì†Œ 2ê¸€ì ì´ìƒì´ì–´ì•¼ í•¨ (ë‹¨, 'saab' ê°™ì€ ì§§ì€ ìœ íš¨ ë‹¨ì–´ í—ˆìš©)
                        if all(len(w) >= 2 for w in words):
                            keyword = ' '.join(words).lower()
                            # ê¸ˆì§€ëœ í‚¤ì›Œë“œ í•„í„°ë§
                            keyword_words = set(keyword.split())
                            if not keyword_words.intersection(banned_keywords):
                                keywords.append(keyword)
            
            if not keywords:
                print("   âš ï¸ AI í‚¤ì›Œë“œ íŒŒì‹± ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._generate_keywords(book_title, author)
            
            # ê¸°ë³¸ í‚¤ì›Œë“œì™€ ë³‘í•© (ì¤‘ë³µ ì œê±°)
            basic_keywords = self._generate_keywords(book_title, author)
            all_keywords = keywords + basic_keywords
            
            # ì¤‘ë³µ ì œê±° ë° ê¸ˆì§€ í‚¤ì›Œë“œ ì¬í•„í„°ë§
            seen = set()
            unique_keywords = []
            # ì¶”ê°€ ê¸ˆì§€ í‚¤ì›Œë“œ (ì „ì²´ í‚¤ì›Œë“œ ë¬¸ìì—´ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸)
            additional_banned = ['bookstore', 'bookshop', 'japanese bookstore', 'japanese bookshop']
            
            for kw in all_keywords:
                kw_clean = kw.lower().strip()
                kw_words = set(kw_clean.split())
                
                # ê¸ˆì§€ëœ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                if kw_clean and kw_clean not in seen and not kw_words.intersection(banned_keywords):
                    # ì¶”ê°€ ê¸ˆì§€ í‚¤ì›Œë“œ ì²´í¬ (ì „ì²´ ë¬¸ìì—´ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸)
                    if not any(banned in kw_clean for banned in additional_banned):
                        seen.add(kw_clean)
                        unique_keywords.append(kw_clean)
            
            print(f"   ğŸ“ í•„í„°ë§ëœ í‚¤ì›Œë“œ: {len(unique_keywords)}ê°œ (ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ ì œì™¸)")
            # 100ê°œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ ì¶©ë¶„í•œ í‚¤ì›Œë“œ ë°˜í™˜
            return unique_keywords[:50]  # ìµœëŒ€ 50ê°œ í‚¤ì›Œë“œ
            
        except Exception as e:
            print(f"   âš ï¸ AI í‚¤ì›Œë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            print("   ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._generate_keywords(book_title, author)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì±… í‘œì§€ ë° ë¬´ë“œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--title', type=str, required=True, help='ì±… ì œëª©')
    parser.add_argument('--author', type=str, help='ì €ì ì´ë¦„')
    parser.add_argument('--keywords', type=str, nargs='+', help='ë¬´ë“œ ì´ë¯¸ì§€ ê²€ìƒ‰ í‚¤ì›Œë“œ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)')
    parser.add_argument('--num-mood', type=int, default=100, help='ë¬´ë“œ ì´ë¯¸ì§€ ê°œìˆ˜ (ê¸°ë³¸ê°’: 100)')
    parser.add_argument('--skip-cover', action='store_true', help='í‘œì§€ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    downloader = ImageDownloader()
    result = downloader.download_all(
        book_title=args.title,
        author=args.author,
        keywords=args.keywords,
        num_mood_images=args.num_mood,
        skip_cover=args.skip_cover
    )
    
    if result['cover_path']:
        print(f"âœ… í‘œì§€: {result['cover_path']}")
    if result['mood_images']:
        print(f"âœ… ë¬´ë“œ ì´ë¯¸ì§€: {len(result['mood_images'])}ê°œ")


if __name__ == "__main__":
    main()

