"""
CSVì˜ ëª¨ë“  ì±…ì— ëŒ€í•´ URL íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
"""

import csv
import sys
from pathlib import Path
from typing import List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

# collect_urls_for_notebooklm ëª¨ë“ˆ import
import importlib.util
spec = importlib.util.spec_from_file_location(
    "collect_urls_for_notebooklm",
    project_root / "scripts" / "collect_urls_for_notebooklm.py"
)
collect_urls_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(collect_urls_module)
NotebookLMURLCollector = collect_urls_module.NotebookLMURLCollector

def load_books_from_csv(csv_path: str) -> List[Tuple[str, str]]:
    """CSVì—ì„œ ì±… ëª©ë¡ ë¡œë“œ"""
    books = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            title = row['title'].strip()
            author = row['author'].strip() if row.get('author') else None
            
            # ë¹ˆ ì œëª© ì œì™¸
            if not title:
                continue
            
            books.append((title, author))
    
    return books

def check_existing_url_file(book_title: str) -> bool:
    """URL íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    from utils.file_utils import safe_title
    safe_title_str = safe_title(book_title)
    url_file = project_root / "assets" / "urls" / f"{safe_title_str}_notebooklm.md"
    return url_file.exists()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CSV ê¸°ë°˜ URL íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸')
    parser.add_argument('--skip-existing', action='store_true', help='ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--limit', type=int, help='ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ë‹¤ì‹œ ìƒì„±')
    parser.add_argument('--auto', action='store_true', help='ìë™ ì‹¤í–‰ (í™•ì¸ ì—†ì´ ì§„í–‰)')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“š CSV ê¸°ë°˜ URL íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸")
    print("=" * 80)
    print()
    
    # ê²½ë¡œ ì„¤ì •
    csv_path = project_root / "data" / "ildangbaek_books.csv"
    urls_dir = project_root / "assets" / "urls"
    urls_dir.mkdir(parents=True, exist_ok=True)
    
    # ì±… ëª©ë¡ ë¡œë“œ
    print("ğŸ“– ì±… ëª©ë¡ ë¡œë“œ ì¤‘...")
    books = load_books_from_csv(str(csv_path))
    if args.limit:
        books = books[:args.limit]
    print(f"   âœ… {len(books)}ê°œì˜ ì±… ë°œê²¬")
    
    # ê¸°ì¡´ íŒŒì¼ í™•ì¸
    if args.skip_existing:
        existing_count = 0
        filtered_books = []
        for title, author in books:
            if check_existing_url_file(title):
                existing_count += 1
            else:
                filtered_books.append((title, author))
        books = filtered_books
        print(f"   â­ï¸ {existing_count}ê°œëŠ” ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ê±´ë„ˆëœ€")
        print(f"   ğŸ“ {len(books)}ê°œ ì²˜ë¦¬ ì˜ˆì •")
    
    print(f"\nğŸ“Š ì´ ì‘ì—…ëŸ‰: {len(books)}ê°œ")
    print()
    
    # ì‚¬ìš©ì í™•ì¸ (--auto í”Œë˜ê·¸ê°€ ì—†ì„ ë•Œë§Œ)
    if not args.auto and len(books) > 10:
        try:
            response = input(f"{len(books)}ê°œì˜ ì±…ì— ëŒ€í•´ URL íŒŒì¼ì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if response != 'y':
                print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
        except (EOFError, KeyboardInterrupt):
            print("\nâŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
    
    collector = NotebookLMURLCollector()
    
    # í†µê³„
    success_count = 0
    fail_count = 0
    skip_count = 0
    
    # ì±… URL ìˆ˜ì§‘
    print("\n" + "=" * 80)
    print("ğŸ“š URL íŒŒì¼ ìƒì„± ì‹œì‘")
    print("=" * 80)
    print()
    
    for i, (title, author) in enumerate(books, 1):
        print(f"\n[{i}/{len(books)}] {title}" + (f" - {author}" if author else ""))
        print("-" * 80)
        
        # ê¸°ì¡´ íŒŒì¼ í™•ì¸ (--forceê°€ ì•„ë‹ ë•Œ)
        if not args.force and check_existing_url_file(title):
            print("   â­ï¸ ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ ê±´ë„ˆëœ€ (--force ì˜µì…˜ìœ¼ë¡œ ê°•ì œ ìƒì„± ê°€ëŠ¥)")
            skip_count += 1
            continue
        
        try:
            ko_urls, en_urls = collector.search_urls_bilingual(
                book_title=title,
                author=author,
                total_results=30,
                en_title=None
            )
            
            # URL íŒŒì¼ ì €ì¥
            collector.save_urls_bilingual(
                book_title=title,
                ko_urls=ko_urls,
                en_urls=en_urls,
                author=author
            )
            
            if ko_urls or en_urls:
                success_count += 1
                print(f"   âœ… ì™„ë£Œ: í•œê¸€ {len(ko_urls)}ê°œ + ì˜ì–´ {len(en_urls)}ê°œ = ì´ {len(ko_urls) + len(en_urls)}ê°œ")
            else:
                fail_count += 1
                print(f"   âš ï¸ URLì„ ì°¾ì§€ ëª»í–ˆì§€ë§Œ íŒŒì¼ì€ ìƒì„±ë¨")
            
            # ìš”ì²­ ê°„ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
            time.sleep(2)
            
        except Exception as e:
            fail_count += 1
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š ì‘ì—… ì™„ë£Œ ìš”ì•½")
    print("=" * 80)
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"â­ï¸ ê±´ë„ˆëœ€: {skip_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"ğŸ“ ì´ ì²˜ë¦¬: {len(books)}ê°œ")
    print()

if __name__ == "__main__":
    import time
    main()
