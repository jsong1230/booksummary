"""
ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ì¼ë‹¹ë°± ì±… ëª©ë¡ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
"""

import requests
from bs4 import BeautifulSoup
import csv
import re
from pathlib import Path
from typing import List, Dict, Optional
import time

def parse_namuwiki_books(url: str) -> List[Dict]:
    """ë‚˜ë¬´ìœ„í‚¤ í˜ì´ì§€ì—ì„œ ì±… ëª©ë¡ íŒŒì‹±"""
    print(f"ğŸ“š ë‚˜ë¬´ìœ„í‚¤ í˜ì´ì§€ì—ì„œ ì±… ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
    print(f"URL: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        books = []
        seen_books = set()  # ì¤‘ë³µ ì²´í¬ìš©
        
        # ë‚˜ë¬´ìœ„í‚¤ í…Œì´ë¸”ì—ì„œ ì±… ì •ë³´ ì¶”ì¶œ
        tables = soup.find_all('table')
        print(f"í…Œì´ë¸” {len(tables)}ê°œ ë°œê²¬")
        
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 3:  # íšŒì°¨, ì‘í’ˆ, ì‘ê°€ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                    try:
                        # íšŒì°¨ (ì²« ë²ˆì§¸ ì…€)
                        episode = cells[0].get_text(strip=True)
                        # ì‘í’ˆ (ë‘ ë²ˆì§¸ ì…€)
                        title = cells[1].get_text(strip=True)
                        # ì‘ê°€ (ì„¸ ë²ˆì§¸ ì…€)
                        author = cells[2].get_text(strip=True)
                        
                        # ìœ íš¨í•œ ì±… ì •ë³´ì¸ì§€ í™•ì¸
                        if title and author and title != 'ì‘í’ˆ' and author != 'ì‘ê°€':
                            # íšŒì°¨ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "1í™”", "1íšŒ" ë“±)
                            episode_num = re.search(r'(\d+)', episode)
                            episode_num = int(episode_num.group(1)) if episode_num else 0
                            
                            # ì¤‘ë³µ ì²´í¬
                            book_key = (title.lower(), author.lower())
                            if book_key not in seen_books:
                                seen_books.add(book_key)
                                books.append({
                                    'title': title,
                                    'author': author,
                                    'episode': episode_num,
                                    'episode_text': episode
                                })
                    except Exception as e:
                        continue
        
        # í…Œì´ë¸”ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ì°¾ê¸°
        if not books:
            print("í…Œì´ë¸”ì—ì„œ ì°¾ì§€ ëª»í•´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ê²€ìƒ‰ ì¤‘...")
            all_text = soup.get_text()
            lines = all_text.split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # ë‹¤ì–‘í•œ íŒ¨í„´ ì‹œë„
                patterns = [
                    r'(\d+)í™”\s*(.+?)\s*[-â€“]\s*(.+)',  # "1í™” ì±…ì œëª© - ì €ì"
                    r'(\d+)íšŒ\s*(.+?)\s*[-â€“]\s*(.+)',  # "1íšŒ ì±…ì œëª© - ì €ì"
                    r'(\d+)\.\s*(.+?)\s*[-â€“]\s*(.+)',  # "1. ì±…ì œëª© - ì €ì"
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, line)
                    if match:
                        num, title, author = match.groups()
                        episode_num = int(num)
                        
                        # ìœ íš¨ì„± ì²´í¬
                        if episode_num <= 200 and len(title) > 1 and len(author) > 1:
                            book_key = (title.strip().lower(), author.strip().lower())
                            if book_key not in seen_books:
                                seen_books.add(book_key)
                                books.append({
                                    'title': title.strip(),
                                    'author': author.strip(),
                                    'episode': episode_num,
                                    'episode_text': f"{episode_num}í™”"
                                })
                                break
        
        # ì—í”¼ì†Œë“œ ë²ˆí˜¸ìˆœìœ¼ë¡œ ì •ë ¬
        books.sort(key=lambda x: x['episode'])
        
        print(f"âœ… {len(books)}ê°œì˜ ì±…ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return books
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return []


def update_csv_with_books(books: List[Dict], csv_path: str = "data/ildangbaek_books.csv"):
    """CSV íŒŒì¼ì— ì±… ëª©ë¡ ì¶”ê°€"""
    csv_file = Path(csv_path)
    
    # ê¸°ì¡´ ì±… ëª©ë¡ ë¡œë“œ
    existing_books = []
    existing_titles = set()
    
    if csv_file.exists():
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                existing_books.append(row)
                existing_titles.add(row.get('title', '').strip().lower())
    
    # ìƒˆ ì±… ì¶”ê°€
    added_count = 0
    fieldnames = ['title', 'author', 'category', 'season', 'episode', 
                 'source', 'status', 'video_created', 'youtube_uploaded', 
                 'notes', 'added_at']
    
    for book in books:
        title = book['title']
        author = book['author']
        
        # ì¤‘ë³µ ì²´í¬ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        if title.lower() not in existing_titles:
            # ì—í”¼ì†Œë“œ ì •ë³´ ì¶”ê°€
            episode_str = str(book.get('episode', '')) if book.get('episode') else ''
            
            existing_books.append({
                'title': title,
                'author': author,
                'category': 'ildangbaek',
                'season': '',
                'episode': episode_str,
                'source': 'ë‚˜ë¬´ìœ„í‚¤',
                'status': 'not_processed',
                'video_created': '',
                'youtube_uploaded': '',
                'notes': '',
                'added_at': ''
            })
            existing_titles.add(title.lower())
            added_count += 1
            print(f"  âœ“ ì¶”ê°€: {title} - {author}")
        else:
            print(f"  âŠ˜ ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {title}")
    
    # CSV ì €ì¥
    with open(csv_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for book in existing_books:
            row = {field: book.get(field, '') for field in fieldnames}
            writer.writerow(row)
    
    print(f"\nâœ… CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ: {added_count}ê°œ ì¶”ê°€, ì´ {len(existing_books)}ê°œ")
    return added_count


def main():
    url = 'https://namu.wiki/w/ì¼ë‹¹ë°±%20:%20ì¼ìƒë™ì•ˆ%20ì½ì–´ì•¼%20í• %20ë°±ê¶Œì˜%20ì±…'
    
    print("=" * 60)
    print("ğŸ“š ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ì¼ë‹¹ë°± ì±… ëª©ë¡ ìˆ˜ì§‘")
    print("=" * 60)
    print()
    
    # ì±… ëª©ë¡ íŒŒì‹±
    books = parse_namuwiki_books(url)
    
    if not books:
        print("\nâš ï¸ ì±… ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("í˜ì´ì§€ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“– ì°¾ì€ ì±… ëª©ë¡ (ì²˜ìŒ 10ê°œ):")
    for book in books[:10]:
        print(f"  {book['episode']}í™”. {book['title']} - {book['author']}")
    
    if len(books) > 10:
        print(f"  ... ì™¸ {len(books) - 10}ê°œ")
    
    print()
    
    # CSV ì—…ë°ì´íŠ¸
    added_count = update_csv_with_books(books)
    
    print()
    print("=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
